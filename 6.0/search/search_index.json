{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dashjoin Open Source &amp; Cloud Native Low Code Development Platform","text":"<p>For anyone who is planning a development project, faces a tight schedule, needs to present results quickly, or has limited development resources available. Dashjoin taps into and integrates your existing data sources and allows you to intuitively browse, search, edit, and visualize your integrated information. Add business logic to enable users and automation to act on the information. Unlike other Low Code Development Platforms, Dashjoin offers a free open source version with a commercial PaaS and bases on a unique, linked-data inspired approach to scalable data integration.</p> <p>Download: https://download.dashjoin.com/</p> <p>Playground: https://playground.dashjoin.com</p> <p>Live demo: https://cyber.run.dashjoin.com/</p> <p>Webpage: https://dashjoin.com/</p> <p>Blog: https://medium.com/@dashjoin</p> <p>Training course slides: https://download.dashjoin.com/training/platform.pdf</p> <p>Video tutorials:</p> <p></p> <p>Features</p> <ol> <li>Universal DB Frontend: Connect to any SQL or NoSQL database, browse, search, and edit its contents. Extend the schema on the fly.</li> <li>Query Editor: Automatically collect schema information that powers an intuitive graphical query editor.</li> <li>Layout Designer: Graphically customize the layout for different types found in the database. Leverage the query editor to include meaningful charts.</li> <li>Data Integration and Federation: Visually map external data sources to your model. Load the data into a warehouse or federate the source into a virtual linked-data graph.</li> <li>Processes: Seamlessly start and integrate REST services from the application and monitor progress.</li> <li>Cloud Deployment: Deploy the apps in your private cloud or book our PaaS service. All apps scale horizontally and support state of the art cloud stacks.</li> <li>Everything JSON: Dashjoin leverages popular JSON standards like JSON Schema and JSONata and for all aspects of the system</li> <li>Artificial Intelligence: Seamlessly incorporate large language models, image classification, translation, and entity reconciliation services in your App</li> <li>Open Source: Join the Dashjoin community and avoid vendor lock-in.</li> </ol>"},{"location":"administration/","title":"Administration","text":"<p>This section describes administration and operating procedures for the Dashjoin platform.</p>"},{"location":"administration/#configuration-changes","title":"Configuration Changes","text":"<p>A system is defined by the following configurations: Dashboards, layout pages, user roles, registered databases, and functions. These settings are stored in the configuration database. For the open source version, this data is kept on the file system in the model folder. In the docker container, this folder is located under /deployments/model. For locally installed systems, this folder can be found under USER_HOME/.dashjoin/model.</p>"},{"location":"administration/#configuring-openid","title":"Configuring OpenID","text":"<p>The Dashjoin platform can be setup to delegate identity management to an OpenID provider such as Microsoft Azure AD (now Entra ID), Okta, Auth0 or Keycloak, or social identity providers like Google, Github etc.</p>"},{"location":"administration/#registering-the-dashjoin-application","title":"Registering the Dashjoin Application","text":"<p>The first step is to register the Dashjoin application in your OpenID management console. This example explains the process for Azure AD. Note that you will have to have a redirect URL such as \"https://dashjoin-app.example.com/login\" available.</p>"},{"location":"administration/#configuring-the-openid-provider-in-dashjoin","title":"Configuring the OpenID Provider in Dashjoin","text":"<p>The Dashjoin login page can be configured via a configuration file named <code>/assets/logincfg.json</code>.</p> <p>The default config is:</p> <pre><code>{\n    \"signInTabText\": \"My Dashjoin\",          // text on the login page\n    \"emailLoginEnabled\": true,               // users can login with an email address or a local user (e.g. admin) - this setting can also be enabled by adding \"?admin\" to the login URL\n    \"passwordResetEnabled\": true,            // if emailLoginEnabled, the system offers the option to reset the user's password\n    \"registrationEnabled\": true,             // if emailLoginEnabled, users can register with an email address\n    \"guestLoginEnabled\": false,              // allows login with user guest@dashjoin.com (this user must be assigned a suitable role in the tenant user page), if this is the only login option, users are automatically logged in as guests\n    \"providers\": \"google\",                   // space-separated list of identity providers like twitter, github, facebook, and google - currently, only google is supported\n    \"backgroundImage\": \"assets/loginbg.jpg\", // URL of the background image to display\n    \"openIdConfigs\": [],                     // OpenID provider configurations such as O365, Keycloak, etc.\n    \"defaultLocale\": \"en\",                   // default I18N locale to use, choose \"browser\" to select the browser's preferred locale,\n    \"locales\": [\"en\"]                        // languages supported by the platform\n    \"i18n\": ...                              // texts and translations for the login screen and cookie banner (see I18N section for more information)\n    \"autoLogin\": ...                         // auto login settings (see section for details)\n}\n</code></pre> <p>The information you gathered from registering your application in the previous step can be added in the openIdConfigs array as shown in the  following Azure AD example:</p> <pre><code>{\n    ...\n    \"openIdConfigs\": [\n        { \n            \"domain\": \"dashjoin.com\", \n            \"name\": \"Dashjoin Example.com\", \n            \"logo\": \"/favicon.ico\", \n            \"config\": { \n                \"issuer\": \"https://login.microsoftonline.com/.../v2.0\", \n                \"clientId\": \"...\", \n                \"redirectUri\": \"https://dashjoin-app.example.com/\", \n                \"scope\": \"openid profile email\", \n                \"requestAccessToken\": false, \n                \"strictDiscoveryDocumentValidation\": false \n            } \n        }\n    ]\n}\n</code></pre> <p>This config fields are defined as follows:</p> <ul> <li>Domain: the domain the application is running on</li> <li>Name: Application name in the IDM</li> <li>Logo: Absolute or relative URL to the IDM logo to be displayed on teh login screen</li> <li>Issuer: URL / UUID of the IDM issuing authorizations</li> <li>Client ID: ID of the registered application in the IDM</li> <li>Redirect URI: URL of the Dashjoin application Important: previously this required a link to /login, this does not work anymore. Use the root URL</li> <li>Scopes: scopes are used by an application during authentication to authorize access to a user's details</li> <li>Request Access Token: obtain an Access Token, an ID Token, and optionally a Refresh Token</li> <li>Strict Discovery Document Validation: ensure that all of the endpoints provided via the ID Provider discovery document share the same base URL as the issuer parameter</li> </ul> <p>You can configure multiple OpenID providers:</p> <p></p>"},{"location":"administration/#creating-and-assigning-application-roles","title":"Creating and Assigning Application Roles","text":"<ul> <li>After the application is registered within the IDM and the IDM made known to the application, you need to define the roles an IDM user has within the application. On Azure AD, this is the \"App roles\" dialog. Note that these roles must match the role names defined in the Dashjoin platform. The IDM must be configured to emit the groups as role claims. On Azure AD, this is done in the \"Token configuration\" dialog.</li> </ul>"},{"location":"administration/#adding-the-open-id-config-to-the-platform","title":"Adding the Open ID Config to the Platform","text":"<ul> <li>Option 1: </li> </ul> <p>The login config can be stored in the app as <code>/assets/logincfg.json</code></p> <p>This is the easiest and usually preferred method.</p> <p>But note that all app developers with write rights can make changes to this file.</p> <p>As the login config is highly relevant to security, make sure to validate its content and verify who has made changes.</p> <p>If this is not acceptable, you can also use the next option.</p> <ul> <li>Option 2:</li> </ul> <p>Alternatively, you can store the file in the installed Dashjoin platform, outside of the app.</p> <p>The Open ID configuration must be stored as  <pre><code>META-INF/resources/assets/logincfg.json\n</code></pre> relative to the current working directory of the platform.</p> <p>Note that the current working directory depends on the OS and the way the platform is installed / started.</p> <p>The next sections list the locations on different operating systems.</p>"},{"location":"administration/#multifactor-authentication-mfa","title":"Multifactor authentication (MFA)","text":"<p>To use MFA, configure an OpenID provider or a social identity provider that has MFA enabled.</p> <p>Optionally auto login can be used to reduce the number of clicks for the user to log in.</p>"},{"location":"administration/#use-auto-login-to-openid-or-a-social-identity-provider","title":"Use auto login to OpenID or a social identity provider","text":"<p>Important to know:  Auto login does not automatically log in the user, but forwards to the social or OpenID login dialog automatically for a seamless user experience.</p> <p>This is useful if you use an OpenID provider for the organization (i.e. Okta or AzureAD or Keycloak) or a social provider (like Google) and do not want the users to use the integrated identity mechanisms.</p> <p>Settings:</p> <pre><code>  \"autoLogin\": {\n    \"timeout\": &lt;timeout in milliseconds&gt;,\n    \"target\": &lt;optional target, defaults to first configured OpenID&gt;\n  }\n</code></pre> <p>Examples:</p> <p><pre><code>  \"autoLogin\": { \"timeout\": 2000 }\n</code></pre> Automatically forwards to the first configured OpenID provider after 2 seconds.</p> <p><pre><code>  \"autoLogin\": { \"timeout\": 5000, \"target\": {\"key: 1} }\n</code></pre> Automatically forwards to the second OpenID provider after 5 seconds.</p> <p><pre><code>  \"autoLogin\": { \"timeout\": 0, \"target\": {\"provider\": \"google\"} }\n</code></pre> Automatically forwards to Google social identity login.</p>"},{"location":"administration/#installed-dashjoin-application","title":"Installed Dashjoin application","text":"<ul> <li> <p>On Windows, the default location is <pre><code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\Dashjoin\\META-INF\\resources\\assets\\logincfg.json\n</code></pre></p> </li> <li> <p>On Linux and MacOS, store the file relative to the location Dashjoin is launched (current working directory). I.e. if the platform is launched from <code>/home/dashjoin</code>, store the config at <pre><code>/home/dashjoin/META-INF/resources/assets/logincfg.json\n</code></pre></p> </li> <li> <p>On MacOS, you need to launch the application manually from a terminal, otherwise the working directory is <code>/</code> which does not allow to store the config. The executable of the application is by default located at <pre><code>/Applications/Dashjoin.app/Contents/MacOS/Dashjoin\n</code></pre></p> </li> </ul>"},{"location":"administration/#dashjoin-container","title":"Dashjoin container","text":"<p>The current working directory in the container is <code>/deployments</code>. Use the Docker -v option to mount logincfg.json to <code>/deployments/META-INF/resources/assets/logincfg.json</code></p> <p>Command Line Example: <pre><code>docker run --rm -p 8080:8080 -v /my/path/to/logincfg.json:/deployments/META-INF/resources/assets/logincfg.json:ro dashjoin/platform\n</code></pre></p> <ul> <li>Dashjoin PaaS Cloud</li> </ul> <p>please send an email to request the change.</p>"},{"location":"administration/#minimalistic-logincfgjson-customization-example","title":"Minimalistic logincfg.json customization example","text":"<p>The following example disables all OpenID providers, disables password reset, and disables user registration.</p> <p>Note: all settings not specified will use their defaults (see above).</p> <pre><code>{\n    \"emailLoginEnabled\": true\n}\n</code></pre> <p>With this config the login dialog will look similar to this:</p> <p></p>"},{"location":"administration/#query-expression-performance","title":"Query / Expression Performance","text":"<p>When hooking up large databases, you might have to perform some performance tuning in order for the platform to scale. The query and expression performance page (/config/dj-query-performance) is linked from the main database page and helps you with this task. It shows recent query statistics in a table. The columns are defined as follows:</p> <ul> <li>query: shows the JSONata expression or the query that was run along with the database prefixed</li> <li>type: </li> <li>jsonata: JSONata expression evaluation</li> <li>key: determining possible foreign key autocomplete values</li> <li>search: the toolbar search </li> <li>query: the query editor, tables or charts</li> <li>all: the all records table view</li> <li>read: read from an instance page</li> <li>update: update from an instance page </li> <li>create: create from a table page or the upload feature</li> <li>delete: delete from an instance page or the upload feature</li> <li>lastRun: the time the query was last run</li> <li>count: how often was the query run</li> <li>errorCount: of these, how often did an error occur (e.g. a timeout)</li> <li>lastError: the last error message</li> <li>totalTimeMs: the runtime in milliseconds all query runs took combined</li> <li>lastTimeoutMs: optional timeout set for the last run</li> <li>lastLimit: optional limit set for the last run (does not include limits in the query)</li> <li>averageTimeMs: the average time a query evaluation took in milliseconds</li> </ul> <p>The table helps you to identify queries with long runtimes. Possible remedies are:</p>"},{"location":"administration/#creating-database-indices","title":"Creating Database Indices","text":"<p>All key columns should be indexed in the database in order to avoid full table sweeps when a record is accessed by its key.</p>"},{"location":"administration/#specific-search-queries","title":"Specific Search Queries","text":"<p>By default, Dashjoin will perform searches on all database tables which can be a very costly operation. If a database contains more data, you can either opt out of it being searched, or you can associate a query from the catalog to be used. For instance, you might want employees to be searchable by firstname or lastname, but other tables are not relevant for searches. In this case, you can define the following query:</p> <pre><code>select ID, NAME \nfrom EMP \nwhere NAME like concat(${search}, '%')\n</code></pre> <p>You can also use union queries to search over multiple tables. Note that in this case, the query needs to project table, id, match:</p> <pre><code>select 'EMP', ID, NAME from EMP where NAME=${search}\nunion \nselect 'PRJ', ID, NAME from PRJ where NAME=${search}\n</code></pre> <p>Note that the query must have a single parameter \"search\" in order to be used this way. The platform will run this query by replacing the search parameter with the contents of the search field.</p>"},{"location":"administration/#including-excluding-tables-and-databases-from-searches","title":"Including / Excluding Tables and Databases from Searches","text":"<p>Besides custom queries, you can also include or exclude tables from searches using the system configuration page (/config/dj-config).</p>"},{"location":"administration/#prioritizing-results","title":"Prioritizing Results","text":"<p>Using the configuration setting \"prioritize-table-in-search\", you can instruct the system which tables are to be searched first. Results from these tables will appear further up in the search results.</p>"},{"location":"administration/#global-timeout-settings","title":"Global Timeout Settings","text":"<p>Finally, the system configuration page allows setting some global contraints that prevent \"rogue\" queries to deteriorate the overall system and database performance. Please see the descriptions on the system configuration page (/config/dj-config) for more details.</p>"},{"location":"administration/#ui-customizations","title":"UI Customizations","text":"<p>The system configuration page (/config/dj-config) allows defining some UI settings that are applied globally to all UI pages. The settings allow controlling the following aspects of the UI:</p> <ul> <li>homepage: Application home page that is displayed when home is pressed and after login</li> <li>on-login: Expression to be evaluated upon login - it typically sets session variables via setVariable</li> <li>sidenav-open: Side navigation is open initially (changes applied after next login)</li> <li>dark-theme    : Theme settings (see https://marmelab.com/react-admin/AppTheme.html#writing-a-custom-theme) - example: to change the primary color to blue, set the key palette.primary.main to #0000FF</li> <li>sidenav-width-px: Width of the side navigation bar (changes applied after next login) - if the width is set to 0, the open / close button in the toolbar is also hidden</li> <li>theme: Theme settings (see https://marmelab.com/react-admin/AppTheme.html#writing-a-custom-theme) - example: to change the primary color to blue, set the key palette.primary.main to #0000FF (note that the toolbar uses the secondary color)</li> <li>allow-dark-mode: Show the dark mode icon in the toolbar</li> <li>logo-url: URL of the logo to display in the toolbar</li> </ul> <p>Note that these customizations can be overwritten or applied to roles also. If you'd like to change the homepage for role authenticated only, navigate to /config/dj-role/authenticated and in the properties field, enter \"homepage\" and your desired page, e.g. /page/AuthenticatedHome.</p> <p>The customizations can also be applied to an individual OpenID user only via the tenant users table. If you'd like to change the homepage for user joe@example.org, naviage to /config/tenantusers/joe%40example.org and again use the properties field.</p>"},{"location":"administration/#adding-static-assets-to-the-app","title":"Adding static assets to the app","text":"<p>Static assets like images, logos, movies, and other files required by your application can be placed in the <code>/assets</code>folder.</p> <p>The assets are accessible in the running application as <code>http(s)://&lt;app url&gt;/assets</code></p> <p>By definition, access to static assets does not require login, so they are always readable / publically accessible. Do not place any confidential data in the assets folder.</p> <p>When working with version control tools (i.e. git), assets can be maintained along with all other app resources under revision control.</p>"},{"location":"administration/#tracking-user-logins","title":"Tracking User Logins","text":"<p>The platform tracks user logins in the table user within the config database. The table is written every time a user logs into the system. You can deactivate this feature by changing the on-login expression.</p> <p>Alternatively, you may be able to retrieve this information at your identity management platform. The platform logs user login events in the system log. You can grep the log for messages like this one:</p> <pre><code>2024-03-20 14:15:32,163 INFO  [com.das.ser.ten.TenantService] (executor-thread-12) Login profile uid=admin email=null roles=[admin] username=admin\n</code></pre>"},{"location":"ai-ml-integration/","title":"AI &amp; ML Integration","text":"<p>The Artificial Intelligence and Machine Learning features of the Dashjoin Platform is delivered as a set of Docker containers that package models and external runtime components as well as JSONata functions that make these features usable within any part of an application.</p> <p>The previous developer reference section already lists some of the AI &amp; ML capabilities, however, this section explains the features in more detail and provides a comprehensive overview.</p>"},{"location":"ai-ml-integration/#jsonata-notebooks","title":"JSONata Notebooks","text":"<p>Applying AI &amp; ML functionality usually requires some degree of experimentation.  The JSONata Notebooks provide this flexibility. A notebook is the combination of a page with a single notebook widget. The platform ships with a default notebook available at /page/Notebook. Note that you can create as many notebook pages as you like.</p> <p>A Notebook consists of a sequence of code blocks that can be run individually via the run icon or by pressing CTRL ENTER. The result of the call is also stored in the notebook and displayed below the code block.</p> <p>The default way of displaying data is JSON. You can display the data as a value, table, on a map, or as a chart using the following syntax:</p> <pre><code>{\n  \"widget\": \"display\",\n  \"data\": {\n    \"img\": \"https://dashjoin.com/img/fav.png\",\n    \"width\": \"32\"\n  }\n}```\n\n```json\n{\n  \"widget\": \"table\",\n  \"data\": $query(\"northwind\", \"group\")\n}\n</code></pre> <pre><code>{\n  \"widget\": \"map\",\n  \"data\": $adHocQuery(\"northwind\", \"select distinct CITY from EMPLOYEES\").\"EMPLOYEES.CITY\"\n}\n</code></pre> <pre><code>{\n  \"widget\": \"chart\",\n  \"chart\": \"bar\",\n  \"data\": $query(\"northwind\", \"group\")\n}\n</code></pre> <p>If a code block starts with a variable assignment ($variable := ...), the variable can be used in other code blocks as $variable.</p> <p>It is possible to upload one or more files into the notebook. This creates new code block, where the variable $upload is set to a map of file name to file content. This variable can be used in other code blocks. Assume you upload a file.txt, then the contents of the file is avaiable as $upload.file_txt. Note that dot is replaced with underscore to avoid having to escape the field name.</p> <p>The code block and its result is saved to the browser session, which is lost if the browser is closed. You can save the current state of the notebook with the save button. This writes the code blocks to the notebook's page and makes the notebook available to other users.</p>"},{"location":"ai-ml-integration/#optical-character-recognition","title":"Optical Character Recognition","text":"<p>The optical character recognition (OCR) functionality is available in the dashjoin/ai-image Docker container. It exposes a REST API on port 8080 where you provide an image URL such as this picture: </p> <p></p> <p>To start the container, run the following command (we use the host port 8083 to avoid  clashing with the platform port):</p> <pre><code>docker run -p 8083:8080 dashjoin/ai-image\n</code></pre> <p>The URL is passed in a GET request https://.../image-ocr?url=... and returns the extracted text:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-ocr?url=https://d207ibygpg2z1x.cloudfront.net/image/upload/v1540973697/articles_upload/content/ibttqvywe6gihhcu1zzf.jpg\")\n)\n</code></pre> <pre><code>\"HEY YOU YES YOU\\n\\nYOU CANDO IT\\n\"\n</code></pre>"},{"location":"ai-ml-integration/#image-classification","title":"Image Classification","text":"<p>The image classification functionality is also available in the dashjoin/ai-image Docker container. It exposes a REST API where you provide an image URL such as this picture of a bird (https://mein-vogelhaus.com/wp-content/uploads/2020/04/Einheimische-Vogelarten-Stieglitz.jpg).</p> <p></p> <p>The URL is passed in a GET request https://.../image-classify?url=... and returns an array of classifications and probabilities:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-classify?url=https://mein-vogelhaus.com/wp-content/uploads/2020/04/Einheimische-Vogelarten-Stieglitz.jpg\")\n).{\"type\": $[1], \"prob\": $[2]}\n</code></pre> <pre><code>[\n  {\n    \"type\": \"goldfinch\",\n    \"prob\": 0.9761154055595398\n  },\n  {\n    \"type\": \"bulbul\",\n    \"prob\": 0.017567412927746773\n  },\n  {\n    \"type\": \"coucal\",\n    \"prob\": 0.0015972057590261102\n  }\n]\n</code></pre>"},{"location":"ai-ml-integration/#face-recognition","title":"Face Recognition","text":"<p>The optical character recognition (OCR) functionality is also available in the dashjoin/ai-image Docker container. It exposes a REST API where you provide an image URL such as this picture:</p> <p></p> <p>The URL is passed in a GET request https://.../image-face?url=... and returns the extracted text along with the coordinates of the face within the image:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-face?url=https://media-cldnry.s-nbcnews.com/image/upload/newscms/2020_02/1521975/kristen-welker-today-191221-main-01.jpg\")\n)\n</code></pre> <pre><code>[\n  {\n    \"faceid\": \"Kristen Welker\",\n    \"top\": 206,\n    \"left\": 705,\n    \"bottom\": 527,\n    \"right\": 1026\n  }\n]\n</code></pre>"},{"location":"ai-ml-integration/#text-translation","title":"Text Translation","text":"<p>The translation services base on a large language model and are available via REST API in the dashjoin/ai-translation container. You can start the container using the following command (the REST service runs on port 8080, we use 8084 to avoid port collisions):</p> <pre><code>docker run -p 8084:8080 dashjoin/ai-translation\n</code></pre> <p>The OpenAPI specification can be accessed at  http://.../docs. It offers a number of services, which the most important ones being \"translate\" and \"language_detection\".  Translate takes the following parameters:</p> <ul> <li>target_lang: the code of the language, the text is supposed to be translated to</li> <li>text: an array of strings with the original text to be translated</li> <li>source_lang: code of the language, text is written in</li> <li>beam_size: can be used to trade-off translation time and search accuracy</li> <li>perform_sentence_splitting: determines whether the sentences are split into a string array</li> </ul> <pre><code>$openJson(\"http://.../translate?target_lang=de&amp;text=This%20is%20an%20awesome%20translation%20service\")\n</code></pre> <pre><code>{\n  \"target_lang\": \"de\",\n  \"source_lang\": null,\n  \"detected_langs\": [\n    \"en\"\n  ],\n  \"translated\": [\n    \"Das ist ein toller \u00dcbersetzungsdienst\"\n  ],\n  \"translation_time\": 3.5702028274536133\n}\n</code></pre> <p>Language detection takes a single text parameter with the sample text and works as follows:</p> <pre><code>$openJson(\"http://.../language_detection?text=example\")\n</code></pre> <pre><code>\"en\"\n</code></pre>"},{"location":"ai-ml-integration/#dashjoin-ai-assistant-large-language-model","title":"Dashjoin AI Assistant / Large Language Model","text":"<p>The Dashjoin AI Assistant makes it easy to integrate state of the art semantic large language model and text embedding technology into your low code application. The functionality is available via an easy to use administration UI as well as an end-user chat widget. Furthermore, you can access the features conveniently via JSONata. Please refer to the documentation of the aichat widget in the developer reference for information about how the chat widget can be configured. The API section below also shows examples of how to call the REST services directly.</p> <p>Dashjoin AI Assistant is available via the docker image dashjoin/ai-llm-kb and offers a range of powerful features around large language models (LLMs):</p> <ul> <li>access APIs such as OpenAPI or Mistral in a uniform and secure way</li> <li>run LLMs locally and expose them via the same API</li> <li>Builtin and convenient retrieval augmented generation (RAG)</li> <li>Powerful Jupyter development environment for deploying custom AI code based on LlamaIndex</li> <li>Auto-deployment of custom AI code from a Dashjoin app</li> <li>Seamless integration of Dashjoin functions as LLM tools for integrating local structured data into the reasoning process</li> </ul>"},{"location":"ai-ml-integration/#configuration","title":"Configuration","text":"<p>The following environment variables can be used to configure the container:</p> <ul> <li>DJAI_OPENAI_API_BASE: URL of the LLM API (default https://api.mistral.ai/v1)</li> <li>DJAI_OPENAI_API_KEY: API key for Mistral or OpenAI if these services are used</li> <li>DJAI_OPENAI_MODEL: LLM model used (default open-mistral-7b)</li> <li>DJAI_OPENAI_EMBEDDING_MODEL: embedding model used (defaukt mistral-embed)</li> <li>DJAI_AUTH_SECRET: Basic authentication header required to use the container API (default is \"Basic YWRtaW46ZGpkamRq\" which is base64 encoded authentication header for user admin and password djdjdj)</li> <li>DJAI_UI_PASSWORD: Password for the admin user when connecting to the container's admin UI (default djdjdj)</li> <li>DJAI_LLM_MODE: llm used (possible values are: ollama, llama-cpp, sagemaker, openai, openailike, azopenai, gemini, default openailike)</li> <li>DJAI_EMBEDDING_MODE: embedding mode (possible values are: ollama, huggingface, openai, sagemaker, azopenai, gemini, default openailike)</li> <li>DJAI_OLLAMA_URL: URL of the ollama service</li> <li>DJAI_DATA_QDRANT_PATH: path of the vector database (default dashjoin/data/default/qdrant)</li> <li> <p>DJAI_DATA_PATH: path to local data (default dashjoin/data/default)</p> </li> <li> <p>DASHJOIN_DEVMODE: if set to 1, Jupyter and automatic reload of code changes is active</p> </li> <li>JUPYTER_TOKEN: password of the Juyper development environment</li> <li>DASHJOIN_APPURL: GIT URL of the Dashjoin app to be activated in the container</li> <li>DASHJOIN_APPURL_BRANCH: optional GIT branch to use</li> </ul>"},{"location":"ai-ml-integration/#running-ai-assistant","title":"Running AI Assistant","text":"<p>This section shows some minimal configuration examples (relying on defaults wherever possible).</p> <p>Run the container in production without app:</p> <pre><code>docker run \n  -p 8001:8001 \n  -e DJAI_OPENAI_API_KEY=your_mistral_key \n  dashjoin/ai-llm-kb\n</code></pre> <p>Run the container in production with app:</p> <pre><code>docker run \n  -p 8001:8001 \n  -e DJAI_OPENAI_API_KEY=your_mistral_key \n  -e DASHJOIN_APPURL=https://github.com/dashjoin/dashjoin-demo \n  dashjoin/ai-llm-kb\n</code></pre> <p>Run the container to develop an app. We export the Jupyter port 8080 to 8002 outside the container:</p> <pre><code>docker run \n  -p 8001:8001 \n  -p 8002:8080 \n  -e JUPYTER_TOKEN=djdjdj \n  -e DASHJOIN_DEVMODE=1 \n  -e DJAI_OPENAI_API_KEY=your_mistral_key \n  -e DASHJOIN_APPURL=https://github.com/dashjoin/dashjoin-demo \n  dashjoin/ai-llm-kb\n</code></pre>"},{"location":"ai-ml-integration/#admin-ui","title":"Admin UI","text":"<p>The admin UI allows adding files to and deleting them from the vector database. You can also test chatting with the LLM (Chat) and retrieval augmented generation (Query KB).</p> <p>Large Language Model Chat: The large language model chat exposes the generative language capabilities of the underlying model. The model is trained using a large collection of documents and books. It is able to summarize text, answer questions you pose, and much more. In the admin UI, use the mode \"LLM Chat\" to work in this mode.</p> <p>Retrieval Augmented Generation (RAG): RAG allows inserting knowledge around a specific use case into the large language model - even if was not trained on these documents. You can upload your documents using the admin UI. The LLM is then able to answer your questions about these documents. In the admin UI, select the button \"Query KB\" to use this mode.</p> <p>Choosing \"Search in KB\", only performs a semantic search on the uploaded documents without involving the LLM to answer your query.</p>"},{"location":"ai-ml-integration/#api","title":"API","text":"<p>The API of both the vector database and the large language model are available via the following OpenAPI Definition.</p> <p>In order to access the API, we recommend registering a credential set with the service's username and password. The following examples assume you have setup these credentials under the name \"ai\".</p> <p>List all document added to the vector database:</p> <pre><code>$curl(\"GET\", \"https://aikb.run.dashjoin.com/v1/ingest/list\", null, {\"Authorization\": \"ai\"})\n</code></pre> <p>Invoke LLM chat:</p> <pre><code>$curl(\"POST\", \"https://aikb.run.dashjoin.com/v1/completions\", {\n  \"include_sources\": false,\n  \"prompt\": \"How do you fry an egg?\",\n  \"stream\": false,\n  \"system_prompt\": \"You are a rapper. Always answer with a rap.\",\n  \"use_context\": false\n}, {\"Authorization\": \"ai\"})\n</code></pre> <p>Invoke RAG:</p> <pre><code>$curl(\"POST\", \"https://aikb.run.dashjoin.com/v1/completions\", {\n  \"include_sources\": true,\n  \"prompt\": \"wie muss die firewall bei SAP systemen konfiguriert werden?\",\n  \"stream\": false,\n  \"system_prompt\": \"You can only answer questions about the provided context. If you know the answer but it is not based in the provided context, don't provide the answer, just state the answer is not in the context provided. Answer in German.\",\n  \"use_context\": true\n}, {\"Authorization\": \"ai\"})\n</code></pre> <p>Upload a Document:</p> <pre><code>$curl(\n  \"POST\", \n  \"https://aikb.run.dashjoin.com/v1/ingest/file\",\n  {\n    \"file\": base64 encoded data URL\n  },\n  {\n    \"Content-Type\": \"multipart/form-data\",\n    \"Authorization\": \"ai\"\n  }\n)\n</code></pre> <p>The base64 encoded data URL can easily be generated by using this button and input widget:</p> <pre><code>{\n  \"widget\": \"button\",\n  \"schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"file\": {\n        \"widget\": \"binary file with metadata\"\n      }\n    },\n    \"print\": \"$curl('POST', 'https://aikb.run.dashjoin.com/v1/ingest/file', form, {'Content-Type': 'multipart/form-data', 'Authorization': 'ai'})\"\n  }\n}\n</code></pre> <p>The ingest call returns the following result. Every files gets split into a number of documents:</p> <pre><code>{\n  \"object\": \"list\",\n  \"model\": \"private-gpt\",\n  \"data\": [\n    {\n      \"object\": \"ingest.document\",\n      \"doc_id\": \"c202d5e6-7b69-4869-81cc-dd574ee8ee11\",\n      \"doc_metadata\": {\n        \"file_name\": \"Sales Report Q3 2023.pdf\",\n        \"page_label\": \"2\"\n      }\n    }\n  ]\n}\n</code></pre> <p>You can create a database to keep track of files, owners, and the related document ids.  A possible schema would be a table called doc with fields id, owner, and filename. This allows your app to define collections of documents that are associated to specific users:</p> <pre><code>$res := $curl(... ingest);\n$email := email;\n\n$res.data.{\n  'id', doc_id,\n  'owner': $email,\n  'filename': doc_metadata.file_name\n}.$create('database', 'doc', $)\n</code></pre> <p>To use a user's documents, you can retrieve the doc ids from the database and pass them to the LLM as follows:</p> <pre><code>$curl('POST', 'https://aikb.run.dashjoin.com/v1/completions', {\n  \"include_sources\": false,\n  \"prompt\": \"A question that can only be answered with information contained in an uploaded file\",\n  \"stream\": false,\n  \"use_context\": true,\n  \"context_filter\": {\n    \"docs_ids\": [$all('sqlite', 'PART', {'OWNER': email}).ID]\n  }\n},\n{'Authorization': 'ai'}\n)\n</code></pre>"},{"location":"ai-ml-integration/#getting-access-to-ai-assistant","title":"Getting Access to AI Assistant","text":"<p>AI Assistant is available for demo purposes in the playground app. You can book a private instance along with your Dashjoin tenant. Please refer to the website  to access the shop page. Note that the services all comply with european GDPR regulations. Please contact us if you are interested in deploying your own copy using GPU resources in your datacenter.</p>"},{"location":"ai-ml-integration/#extending-ai-assistant","title":"Extending AI Assistant","text":"<p>You can package AI functionality into your Dashjoin app and deploy it to Dashjoin AI Assistant.</p>"},{"location":"ai-ml-integration/#adding-custom-ai-to-an-app","title":"Adding Custom AI to an App","text":"<p>Within your app, create a folder \"aikb/dashjoin/aikb\" with a Python hook \"app.py\". This hook is called upon startup where initializations can be performed and custom REST endpoints can be added. Consider the following example:</p> <pre><code>import logging\nfrom fastapi import FastAPI\nfrom private_gpt.settings.settings import Settings\nfrom private_gpt.ui.ui import PrivateGptUi\nfrom dashjoin.aikb.app_router import app_router\n\nlogger = logging.getLogger(__name__)\n\ndef initializeApp(app: FastAPI, settings: Settings, ui: PrivateGptUi):\n    logger.info(\"Dashjoin App - initializing\")\n    app.include_router(app_router)\n</code></pre> <p>This example simply registers this custom REST service:</p> <pre><code>from fastapi import APIRouter, Depends, Request\nfrom private_gpt.server.utils.auth import authenticated\n\n# Expose the App's REST service\napp_router = APIRouter(prefix=\"/app/v1\", dependencies=[Depends(authenticated)])\n\n# Simple REST API that returns an info object\n@app_router.get(\"/info\", description=\"App Version Info\", tags=[\"Custom App API\"])\ndef info() -&gt; object:\n    return {\n        \"name\": \"Custom App\",\n        \"version\": \"1.0\"\n    }\n</code></pre> <p>The new service is available right after the files are added. You can view the OpenAPI definition and test it using this curl command:</p> <pre><code>curl -u admin:djdjdj -X 'GET' \\\n  'http://localhost:8001/app/v1/info' \\\n  -H 'accept: application/json'\n</code></pre>"},{"location":"ai-ml-integration/#adding-llamaindex-ai-code","title":"Adding LlamaIndex AI Code","text":"<p>The LlamaIndex AI library is already installed on the system. You can add your custom code in your REST service. Consider this minimal OpenAI chat example:</p> <pre><code>import os\nfrom llama_index.llms.openai import OpenAI\n\n...\n\n# set the OpenAI key\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\n# instantiate the OpenAI llm\nllm = OpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n\n# expose it via REST\n@app_router.get(\"/prompt\", description=\"Simple prompt completion\")\ndef complete(prompt: str) -&gt; str:\n    return str(llm.complete(prompt))\n</code></pre>"},{"location":"ai-ml-integration/#using-jupyter-notebooks","title":"Using Jupyter Notebooks","text":"<p>The most convenient way to experiment with Python and AI are Jupyter Notebooks that allow you to interactively run code snippets. Dashjoin AI Assistant ships with a built-in Jupyter server. Assuming you started the container with the command shown above, simply point your browser to http://localhost:8002 and log in. Create a new notebook and enter the following example:</p> <pre><code>import os\nimport requests\nfrom llama_index.core.agent import ReActAgent\nfrom llama_index.core.tools import FunctionTool\nfrom llama_index.llms.openai import OpenAI\nfrom requests.auth import HTTPBasicAuth\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\nllm = OpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n\ndef get_employee_by_last_name(lastname: str) -&gt; object:\n    \"\"\"Looks up an employee by last name\"\"\"\n    return requests.post(\n        \"http://your-dashjoin-platform-address:8080/rest/function/tool\",\n        json={ \"lastname\": lastname },\n        auth=HTTPBasicAuth(\"admin\", \"djdjdj\")\n    )\n\ntool = FunctionTool.from_defaults(\n    get_employee_by_last_name\n)\n\nagent = ReActAgent.from_tools(\n    [tool],\n    llm=llm,\n    verbose=True,\n)\n\nagent.chat(\"what is the first name of our employee 'fuller'?\")\n</code></pre> <p>This code answer's the question \"what is the first name of our employee 'fuller'?\" by using the LLM and equipping it with a tool to fulfill the task. The tool textually describes what it can do in order to advertise its capabilities to the LLM. The tool makes a REST call back to the Dashjoin Platform and runs a JSONata invoke function called \"tool\". It is defined as:</p> <pre><code>{\n    \"ID\": \"tool\",\n    \"djClassName\": \"org.dashjoin.function.Invoke\",\n    \"expression\": \"$all('northwind', 'EMPLOYEES', {'LAST_NAME': lastname})\"\n}\n</code></pre> <p>Running the Notebook shows the following trace:</p> <pre><code>&gt; Running step 0a830c4e-e2c9-479b-b020-bdd027df3ad3. Step input: what is the first name of our employee 'fuller'?\nThought: The current language of the user is English. I need to use a tool to help me answer the question.\nAction: get_employee_by_last_name\nAction Input: {'lastname': 'Fuller'}\nObservation: &lt;Response [200]&gt;\n&gt; Running step 31fa0f53-a975-4861-9fd2-89078616a27e. Step input: None\nThought: I can answer without using any more tools. I'll use the user's language to answer\nAnswer: The first name of the employee with the last name 'Fuller' is 'Andrew'.\n</code></pre>"},{"location":"ai-ml-integration/#adding-llm-tool-calls-to-the-app","title":"Adding LLM Tool Calls to the App","text":"<p>Once we get everything working in Jupyter, we can either parameterize the Notebook and call it via REST (see next section) or we can convert it to a regular REST endpoint as shown below:</p> <pre><code>import os\nimport requests\nfrom requests.auth import HTTPBasicAuth\nfrom fastapi import APIRouter, Depends, Request\nfrom private_gpt.server.utils.auth import authenticated\nfrom llama_index.llms.openai import OpenAI\nfrom llama_index.core.agent import ReActAgent\nfrom llama_index.core.tools import FunctionTool\n\napp_router = APIRouter(prefix=\"/app/v1\", dependencies=[Depends(authenticated)])\n\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n\nllm = OpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n\ndef get_employee_by_last_name(lastname: str) -&gt; object:\n    \"\"\"Looks up an employee by last name and returns the information as a JSON object\"\"\"\n    return requests.post(\n        \"http://host.docker.internal:8080/rest/function/tool\",\n        json={ \"lastname\": lastname },\n        auth=HTTPBasicAuth(\"admin\", \"djdjdj\")\n    )\n\ntool = FunctionTool.from_defaults(\n    get_employee_by_last_name\n)\n\nagent = ReActAgent.from_tools(\n    [tool],\n    llm=llm,\n    verbose=True,\n)\n\n@app_router.get(\"/tool\", description=\"Find employees using LLM and tool\")\ndef complete(lastname: str) -&gt; str:\n    return str(agent.chat(\"what is the first name of our employee '\"+lastname+\"'?\"))\n</code></pre>"},{"location":"ai-ml-integration/#installing-python-libraries","title":"Installing Python Libraries","text":"<p>Python offers a wide ecosystem of libraries. In case you would like to use a library that is not already included in Dashjoin AI Assistant, you can install it using Jupyter by running this command:</p> <pre><code>!pip install missing-lib\n</code></pre> <p>You can add the Notebook to your app and make sure it is run upon container initialization by adding this line to your app.py startup hook:</p> <pre><code>from dashjoin.aikb.util import executeNotebook\n\n...\n\nexecuteNotebook(\"dashjoin/aikb/install.ipynb\")\n</code></pre>"},{"location":"ai-ml-integration/#calling-jupyter-notebooks-over-rest","title":"Calling Jupyter Notebooks over REST","text":"<p>The tools example aboce showed how code can be developed and tested in Jupyter and how it is then moved to Python. Using the executeNotebook function, you can even expose the Notebook directly as a REST service:</p> <pre><code>from dashjoin.aikb.util import executeNotebook\n\n# REST APIfication of a Jupyter Notebook\n@app_router.post(\"/nb\", name=\"Jupyter Notebook as a Service\", description=\"Jupyter Notebook as Service\", tags=[\"Custom App API\"])\ndef notebook(args: NotebookArgs) -&gt; object:\n    import os\n    os.environ[\"DJ_INPUT_ARGS\"] = args.model_dump_json()\n    return executeNotebook(\"app/aikb/dashjoin/aikb/nb.ipynb\")\n</code></pre> <p>In the Notebook, you can access the REST parameters as follows:</p> <pre><code>import os\nargs = os.environ.get(\"DJ_INPUT_ARGS\")\nprint(args)\n</code></pre> <p>The executeNotebook code must be placed in util.py:</p> <pre><code>import logging\n\nlogger = logging.getLogger(__name__)\n\ndef executeNotebook(nb: str):\n    \"\"\"\n    Executes the given Jupyter Notebook and returns the result\n    \"\"\"\n    import nbformat\n    from nbconvert.preprocessors import ExecutePreprocessor\n    import json\n\n    with open(nb) as ff:\n        nb_in = nbformat.read(ff, nbformat.NO_CONVERT)\n\n    ep = ExecutePreprocessor(timeout=600) #, kernel_name='python3')\n\n    logger.info(\"Notebook execution\", nb)\n    nb_out = ep.preprocess(nb_in)\n    logger.info(\"Notebook executed\", nb)\n    print(json.dumps(nb_out, indent=2))\n    return nb_out\n</code></pre>"},{"location":"ai-ml-integration/#committing-changes-to-the-app","title":"Committing Changes to the App","text":"<p>Jupyter comes with a full fledged GIT client. Therefore, you can commit your Python and Jupyter code to the Dashjoin App's GIT repository directly.</p>"},{"location":"ai-ml-integration/#entity-reconciliation","title":"Entity Reconciliation","text":"<p>When integrating data from different sources, entity reconciliation describes the process of aligning different identifiers for the same entity that are used across the various sources.</p> <p>There are various approaches that can be applied. In this section, we describe the reconcileEntity JSONata function. It uses the Wikidata search API in order to reconcile a text with a standardized Wikidata ID. Wikidata is the database equivalent of Wikipedia, i.e. it is a crowd-sourced database of entites that can also be found in wikipedia. Consequently this function should not be used if the texts are very specific or if the texts are unsuitable to be sent to a 3rd party service.</p> <p>The function takes three parameters:</p> <ul> <li>entity: the entity string</li> <li>entity-language: the optional language of the entity string (default is en)</li> <li>limit: the number of ranked search results (default is 1)</li> </ul> <p>Consider the reconciliation results for \"Apple\". The term is ambiguous since it can refer to Apple the fruit and Apple, the tech company.</p> <pre><code>$reconcileEntity(\"Apple\", \"en\", 2)\n</code></pre> <pre><code>[\n  {\n    \"id\": \"Q89\",\n    \"label\": \"apple\",\n    \"description\": \"fruit of the apple tree\"\n  },\n  {\n    \"id\": \"Q312\",\n    \"label\": \"Apple\",\n    \"description\": \"American multinational technology company\"\n  }\n]\n</code></pre> <p>Note that the most likely match comes first. If the call is repeated with \"Apple Inc.\", the Wikidata ID Q312 is the first result.</p>"},{"location":"ai-ml-integration/#entity-classification","title":"Entity Classification","text":"<p>When examining an unknown datasource, it is useful to generate a classification of the values found in a column. This functionality is offered by the classifyEntities function.</p> <p>This function extends reconcileEntity by also querying the Wikidata categories. Given a list of entities, this function retrieves the Wikidata types and returns all types that are common for all entities. This function has the following parameters:</p> <ul> <li>entities: the list of entity strings</li> <li>entity-language: the optional language of the entity string (default is en)</li> <li>limit: the number of ranked search results (default is 1)</li> <li>subclass-depth: this number indicates whether superclasses of Wikidata classes should be included (default is 1). Given depth 1, \"Gone with the wind\" would be classified as a movie. A movie is also a piece of art. Therefore, piece of art would be another potential classification tested with the other entities.</li> </ul> <p>Consider this example. This call tries to find a common classification for \"Unicef\" and \"Apple\". The search limit must be set to 2 in order to get Apple the company and the fruit. Both of these are classified as organizations.</p> <pre><code>$classifyEntities([\"Apple\", \"Unicef\"], null, 2, 0)\n</code></pre> <pre><code>[\n  \"organization\"\n]\n</code></pre> <p>If the call is repeated with IBM instead of Unicef, the results are business, enterprise, public company, and technology company.</p>"},{"location":"ai-ml-integration/#text-distance-and-soundex-similarity","title":"Text Distance and Soundex Similarity","text":"<p>When matching entities, text similarity and distance metrics can also be useful. Consider an example where many different sources include company names. When matching these names, typical problems arise from simple typos and different spellings (\"Apple\" vs. \"Apple Inc.\").</p> <p>Similarity and distance metrics can be useful in these circumstances. Given two sets of strings, the synonym function allows applying these metrics. It returns a list of matches that can be used as a synonym lookup table. Hence the name. It takes the following parameters:</p> <ul> <li>algorithms: A map of algorithm name to limit determining whether to include a term / variant pair. The algorithm names can be chosen from this list. Alternatively, you can use \"SoundexSimilarity\"</li> <li>terms: A list of names to test against all variants</li> <li>variants: A list of names to test against all terms</li> <li>ignoreCase: ignore case when computing the distance (defaults to false)</li> <li>ignoreEquality: include term / variant pairs that are equal in the result</li> </ul> <p>The soundex similarity is higher for a pair of strings that sound similar in the english language:</p> <pre><code>$synonym({\"SoundexSimilarity\":2}, [\"roast\"], [\"ghost\", \"boast\", \"hello\"])\n</code></pre> <pre><code>[\n  {\n    \"synonym\": \"ghost\",\n    \"term\": \"roast\",\n    \"algotithm\": \"SoundexSimilarity\",\n    \"value\": 3\n  },\n  {\n    \"synonym\": \"boast\",\n    \"term\": \"roast\",\n    \"algotithm\": \"SoundexSimilarity\",\n    \"value\": 3\n  }\n]\n</code></pre> <p>Note that the pair \"roast\" and \"hello\" do not sound alike and, therefore, is not included.</p> <p>The Levenshtein Distance calculates the minimal number of edits that is required to transform one string into the other. The smaller this number, the more similar the strings are. This is a good metric to match strings despite typos. Compared to apple, apples is included with a limit of 1, appl is too different and is not included.</p> <pre><code>$synonym({\"LevenshteinDistance\": 1}, [\"apple\"], [\"apples\", \"appl\"])\n</code></pre> <pre><code>[\n  {\n    \"synonym\": \"apples\",\n    \"term\": \"apple\",\n    \"algotithm\": \"LevenshteinDistance\",\n    \"value\": 1\n  },\n  {\n    \"synonym\": \"appl\",\n    \"term\": \"apple\",\n    \"algotithm\": \"LevenshteinDistance\",\n    \"value\": 1\n  }\n]\n</code></pre>"},{"location":"ai-ml-integration/#document-to-text","title":"Document to Text","text":"<p>In order to include PDF and Word documents into your AI / ML and Low Code processes, it is crucial to be able to convert these assets into plain text. This functionality is available in the Dasjoin NLP container. You can run it as follows:</p> <pre><code>docker run -p 8081:8081 dashjoin/nlp\n</code></pre> <p>The container offers a conversion service that can be called as follows:</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:8081/function/run/doc2text' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '\"https://pdfobject.com/pdf/sample.pdf\"'\n</code></pre> <p>This example passes a URL to a PDF document. In turn, the extracted text is returned.</p> <p>If the document is not available directly via a public URL, you can obtain it via some other means and pass it via a data URL as follows:</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:8081/function/run/doc2text' \\\n  -H 'accept: application/json' \\\n  -H 'Content-Type: application/json' \\\n  -d '\"data:application/pdf;base64,PGh0bWw+PHA+bXkgdGl0bGU8L3A+PC9odG1sPg==\"'\n</code></pre> <p>Note that the data URL has the prefix: data:application/pdf;base64, The following data is a base 64 encoded HTML page.</p> <p>In order to send a document from your upload folder, you can use the following JSONata code:</p> <pre><code>$curl(\"POST\", \"http://localhost:8081/function/run/doc2text\", \"data:application/pdf;base64,\" &amp; $openText(\"file:upload/test.html\", \"BASE_64\"))\n</code></pre> <p>The document is loaded via the openText function using base64 encoding. The data URL prefix is appended and fed into the curl command.</p>"},{"location":"api/","title":"API","text":"<p>This section is comprised of two parts. First, we look at the API that ships with the Dashjoin platform. Second, we highlight how you can build APIs as part of your app.</p>"},{"location":"api/#platform-api","title":"Platform API","text":"<p>The Dashjoin architecture features an Angular Single Page Application (SPA) that is driven by RESTful APIs. The APIs support the OpenAPI standard. The OpenAPI description is available at https://demo.my.dashjoin.com/openapi. Dashjoin also ships the Swagger GUI at https://demo.my.dashjoin.com/swagger-ui. Please note that the API is subject to change.</p>"},{"location":"api/#authentication","title":"Authentication","text":"<p>The API requires any request using a local admin user to be authenticated with HTTP basic authentication:</p> <pre><code>curl -u admin:djdjdj http://localhost:8080/rest/manage/version\n</code></pre> <p>In order to login using an OpenID user, you need to specify a bearer token as follows:</p> <pre><code>curl -H \"Authorization: Bearer ...\" https://demo.my.dashjoin.com/rest/manage/version\n</code></pre> <p>The easiest way to obtain a bearer token is to login using a browser and copying the token via the browser development tools. Depending on your OpenID provider, a bearer token can also be obtained via a seperate login call.</p> <p>In addition to the API, it is possible to create custom function and database microservices and use them via the RestJson function and RemoteDatabase clients. For more information, please refer to the dashjoin-sdk module documentation.</p>"},{"location":"api/#jsonapi","title":"JSON:API","text":"<p>Dashjoin supports JSON:API for read operations.  JSON:API describes how clients should request or edit data from a server, and how the server should respond to said requests. The endpoint is available under /rest/jsonapi.</p>"},{"location":"api/#odata","title":"OData","text":"<p>Dashjoin also supports OData for read operations.  OData (Open Data Protocol) is an ISO/IEC approved, OASIS standard that defines a set of best practices for building and consuming RESTful APIs. The endpoint is available under /rest/odata.</p>"},{"location":"api/#pdf-export","title":"PDF Export","text":"<p>Any platform page can be exported to PDF using the puppeteer framework. For your convenience, we deployed a cloud function to do this for any installation available on the web. Please note that your credentials and the PDF content are sent via this third party if you use this function:</p> <pre><code>curl -X POST https://europe-west1-djfire-1946d.cloudfunctions.net/exportPdf --output cloudfunction.pdf -H \"Content-Type:application/json\" -d '{\n    \"url\": \"https://demo.my.dashjoin.com/#/page/html-Dashboard2\",\n    \"username\": \"...\",\n    \"password\": \"...\",\n    \"pdfOptions\": {\n        \"format\": \"a4\",\n        \"landscape\": true\n    },\n    \"toggleNavBar\": true\n}'\n</code></pre> <p>Alternatively, you can use a bearer token in the \"authentication\" field instead of user name and password.</p>"},{"location":"api/#app-api","title":"App API","text":"<p>Apart from building user interfaces, the Dashjoin platform can also be used to develop, document, and deploy APIs based on the OpenAPI standard. The platform provides generic APIs to read and write tables, run queries, and execute functions. In this context, generic means that a new function \"myfunction\" does not show up in the API definition. Its name can rather can be used as parameter in the execute function API. Using the App API concept, this pattern can be changed and \"myfunction\" can be exposed as an individual API. This makes it easier for developers to document APIs and expose them to clients.</p>"},{"location":"api/#documenting-an-existing-app","title":"Documenting an Existing App","text":"<p>In the first use case, we assume that there already is an existing Dashjoin App. It works using the UI and the developer would now like to expose parts of this app via OpenAPI.</p> <p>Consider the following example. The app contains a simple invoke function that computes \"{\"result\": x+y}\" and this function should be exposed as an OpenAPI REST service.</p> <p>First, you need to create an OpenAPI skeleton description and place it into the app's upload folder, e.g. at upload/openapi.yaml:</p> <pre><code>openapi: \"3.0.3\"\ninfo:\n  version: \"1\"\n  title: \"test\"\nx-dashjoin:\n  functions:\n  - add\nsecurity:\n- Basic_Auth: []\ncomponents:\n  securitySchemes:\n    Basic_Auth:\n      type: \"http\"\n      scheme: \"basic\"\n</code></pre> <p>This specification is written in YAML and contains some basic metadata about the API version and description. It also specifies that clients can connect using HTTP basic authentication. Please note that you can author these specifications using this online editor. The SwaggerHub offering also allows you to save the specs in the cloud. See the dashjoin repository and the raw YAML spec.</p> <p>In the \"x-dashjoin\" section, we specify that the function \"add\" is to be added to the API. Normally, the API path, schema, response types, etc. would have to be added. In our case, the Dashjoin platform generates that into this template.</p> <p>Once this file is saved, follow these steps:</p> <ul> <li>Connect the template with the platform, by adding \"url\": \"file:upload/openapi.yaml\" to the \"openapi\" system configuration setting (/#/config/dj-config/openapi)</li> <li>Open the platform Swagger-UI (/swagger-ui/)</li> <li>In the text field at the top, change \"/openapi\" to \"/rest/manage/openapi\"</li> <li>Authorize using your credentials</li> <li>Test the service by sending this JSON payload: {\"x\":1, \"y\": 2}</li> </ul> <p>Apart from functions, you can also publish queries and schemas. Queries work just like functions. Schemas can be derived from tables known to the system. To include these in the App API, you can use these keywords in the OpenAPI template:</p> <pre><code>x-dashjoin:\n  functions:\n  - add\n  queries:\n  - group\n  schemas:\n  - dj/northwind/US_STATES\n</code></pre> <p>Unfortunately, it might not be clear to clients, that the request is expected to be an object containing the keys x and y. In order to make this clear, we can either provide a more description JSON Schema for the request object or we can provide a descriptive example. You can add the following fragment to the OpenAPI description:</p> <pre><code>paths:\n  /rest/function/add:\n    post:\n      operationId: \"add\"\n      requestBody:\n        content:\n          application/json:\n            schema:\n              example:\n                x: 1\n                y: 2\n</code></pre> <p>This YAML tree structure will be merged with the one generated by the Dashjoin platform. Specifically, the example key will be merged providing clear documentation on how to call the service.</p> <p>The OpenAPI specification can be accessed without credentials. If credentials are provided (e.g. via curl http://admin:djdjdj@localhost:8080/rest/manage/openapi), the platform also generates result set metadata for the queries. For instance, if the group query in the Dashjoin Demo App is included, the following OpenAPI path response is generated:</p> <pre><code>  responses:\n    \"200\":\n      content:\n        application/json:\n          schema:\n            type: \"array\"\n            items:\n              type: \"object\"\n              properties:\n                COUNTRY:\n                  type: \"string\"\n                  x-dbType: \"CHARACTER VARYING\"\n                Number of Customers:\n                  x-dbType: \"BIGINT\"\n      description: \"group response\"\n</code></pre>"},{"location":"api/#implementing-an-existing-openapi-specification","title":"Implementing an existing OpenAPI Specification","text":"<p>The second use case highlights a scenario where we work in an API centric fashion. This means that the OpenAPI spec is designed first instead of being generated from existing code.</p> <p>As an example, we will implement the Petstore example that is featured in the Swagger Editor. Simply select \"Save as YAML\" and place the file in \"upload/petstore.yaml\". Then, change the openapi config (/#/config/dj-config/openapi) to \"url\": \"file:upload/petstore.yaml\".</p>"},{"location":"api/#creating-tables","title":"Creating Tables","text":"<p>The Petstore API defines several data structures such as Pet, User, etc. Not all of them necessarily need to be mapped to tables. The Address structure for example, merely defines a complex column in the table customer. Since OpenAPI schemas usually contain nested types and arrays, we should choose a database that supports these datatypes. For this example, we'll use a Postgres DB that is registered under the name \"postgres\".</p> <p>The platform offers an API that allows creating a table directly from the OpenAPI spec. Note that the first property is assumed to be the primary key. We'll create the Pet table using this curl command:</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:8080/rest/manage/createTable/postgres' \\\n  -H 'accept: */*' \\\n  -H 'Authorization: Basic YWRtaW46ZGpkamRq' \\\n  -H 'Content-Type: text/plain' \\\n  -d 'Pet'\n</code></pre> <p>Once you update the database to trigger the table scan, the Pet table shows up. Note that nested types and arrays get converted to jsonb columns.</p>"},{"location":"api/#creating-function-stubs","title":"Creating Function Stubs","text":"<p>Next, we'll create function stubs from the OpenAPI spec. This functionality is also available on the platform API:</p> <pre><code>curl http://admin:djdjdj@localhost:8080/rest/manage/createStubs\n</code></pre> <p>This creates an invoke function that simply echos the input for each operation in the spec. The name of the function is the  value of the OpenAPI operationId.</p>"},{"location":"api/#testing-a-stub","title":"Testing a Stub","text":"<p>Before we can test a generated function stub, we need to change the value of the server field. This field provides options for the  APIs to be tested from the Swagger UI. We set this value to:</p> <pre><code>servers:\n  - url: /rest/app\n</code></pre> <p>The endpoint /rest/app is a generic API handler that delegates incoming calls to the appropriate function.</p> <p>The Petstore example comes with open authentication and API key authentication. For simplicity, we'll add basic authentication:</p> <pre><code>  securitySchemes:\n    Basic_Auth:\n      type: \"http\"\n      scheme: \"basic\"\n</code></pre> <p>We'll implement the addPet and getPetById calls. So you'll have to allow basic authentication with these calls by adding:</p> <pre><code>  /pet/{petId}:\n      ...\n      security:\n        - Basic_Auth: []\n        - api_key: []\n        - petstore_auth:\n            - write:pets\n            - read:pets\n</code></pre> <pre><code>  /pet:\n    put:\n      ...\n    post:\n      ...\n      security:\n        - Basic_Auth: []\n        - petstore_auth:\n            - write:pets\n            - read:pets\n</code></pre> <p>Now you can reload the Swagger UI with the OpenAPI spec at /rest/manage/openapi, login using basic authentication, and test the find pet by ID call with petId 123. The resulting JSON is:</p> <pre><code>{\n  \"parameters\": {\n    \"petId\": \"123\"\n  },\n  \"body\": null\n}\n</code></pre> <p>Likewise, the result of the addPet call - using the sample parameters provided - is:</p> <pre><code>{\n  \"parameters\": null,\n  \"body\": {\n    \"id\": 10,\n    \"name\": \"doggie\",\n    \"category\": {\n      \"id\": 1,\n      \"name\": \"Dogs\"\n    },\n    \"photoUrls\": [\n      \"string\"\n    ],\n    \"tags\": [\n      {\n        \"id\": 0,\n        \"name\": \"string\"\n      }\n    ],\n    \"status\": \"available\"\n  }\n}\n</code></pre> <p>You can see that the generic API handler always passes an object to the function. This object contains the keys parameters and body. Parameters contains all path, query, cookie, and header parameters defined. The body optionally contains the JSON payload.</p>"},{"location":"api/#implementing-the-functions","title":"Implementing the Functions","text":"<p>Using the JSONata functions, we can now implement the functions. AddPet can be handled with this expression:</p> <pre><code>(\n  $echo($);\n  $create(\"postgres\", \"Pet\", body);\n  body;\n)\n</code></pre> <p>First we echo the object passed to the function so we can trace the call on the log. Since the structure of the body matches the JSON schema that was used to generate the table, we can pass it one to one. Finally, we return the body since that is expected by the OpenAPI specification.</p> <p>The find pet by ID call is also very simple:</p> <pre><code>$read(\"postgres\", \"Pet\", parameters.petId)\n</code></pre>"},{"location":"api/#contributing-to-an-existing-openapi-specification","title":"Contributing to an existing OpenAPI Specification","text":"<p>The third use case extends both the first and second use case. We assume you're working in an API centric fashion, however,  parts of the spec should be derived from existing systems. Typically, there's a strong correlation between schemas and existing databases, so we'll extend the petstore example with a schema generated from the northwind sample database.</p> <p>First, we'll need to indicate that a certain table should be added to the OpenAPI spec:</p> <pre><code>x-dashjoin:\n  schemas:\n  - dj/northwind/US_STATES\n</code></pre> <p>This makes the schema for US_STATES appear in the spec. Note that the schema is marked with the flag x-generated=true. Currently, the extended spec is only available via the platform. Therefore, we can export it using another API call:</p> <pre><code>http://admin:djdjdj@localhost:8080/rest/manage/saveapi\n</code></pre> <p>Since we configured the OpenAPI spec to be read from a file URL, the system updates the file to include the new schema, making it available for other tooling. In case the database schema is updated, e.g. another column is added, this process can be repeated. The x-generated flag makes sure that updates on the database are reflected, despite the schema already being present in the file.</p>"},{"location":"api/#swaggerhub-integration","title":"SwaggerHub Integration","text":"<p>SwaggerHub is a popular tool for authoring and managing your APIs. Consequently, instead of using a file URL, we allow using a SwaggerHub URL. In order to have the platform authenticate against the SwaggerHub API, you must generated an API key and provide it in the openapi system configuration:</p> <pre><code>{\n    \"ID\": \"openapi\",\n    \"map\": {\n        \"url\": \"https://api.swaggerhub.com/apis/[ORG-NAME]/[API-NAME]/[VERSION]/swagger.yaml\",\n        \"apiKey\": \"...\"\n    }\n}\n</code></pre> <p>In this case the save operation adds generated fragments to this specific API version.</p>"},{"location":"concepts/","title":"Concepts","text":"<p>Before we dive into the user guide for the platform, this section explains a couple of key concepts.</p>"},{"location":"concepts/#data-model","title":"Data Model","text":"<p>The Dashjoin low code platform sits on top of one or more databases. These databases can be empty, ready to store application data, or they can contain an existing schema and data, possibly under the control of other software and systems. Dashjoin connects to these databases and maps the data using coordinates for each data record:</p>"},{"location":"concepts/#record-coordinates","title":"Record Coordinates","text":"<ol> <li>Dashjoin: The first coordinate is the ID of the Dashjoin installation that accesses the database.</li> <li>Database: The unique name of the database containing the record.</li> <li>Table: The table name (unique within the database) of the table containing the record.</li> <li>Record key(s): The unique ID of the record within its table. This might be a list of keys if we are dealing with composite keys, for instance in a relational database.</li> </ol> <p>These coordinates (DJ, DB, TABLE, PK) translate to RESTful URLs:</p> <ul> <li>Visualizing a record: <code>https://dashjoin.host.name/#/DB/TABLE/PK</code></li> <li>API access to the record: <code>https://dashjoin.host.name/rest/database/crud/DB/TABLE/PK</code></li> </ul>"},{"location":"concepts/#tables-and-columns","title":"Tables and Columns","text":"<p>Dashjoin organizes data in tables and columns. Columns can be of simple types such as strings, integers, etc., but they can also be complex JSON documents. Therefore, Dashjoin is able to connect to multiple kinds of databases. Each of these drivers aligns the database specific nomenclature to the common data model. Therefore a document database's collections become tables, the documents become records and the document fields become columns.</p>"},{"location":"concepts/#primary-and-foreign-keys","title":"Primary and Foreign Keys","text":"<p>Each table usually defines one or more primary key columns that uniquely define each record in the table. In addition, there can be foreign keys in a table that reference another table. This information is crucial for Dashjoin, since it is used to automatically display hyperlinks between records.</p> <p>Usually the key information is extracted from the databases by the drivers. However, some databases do not allow for expressing foreign key information. In this case, the information can be added to the Dashjoin metadata by the user. This mechanism even allows setting foreign key relationships between databases and even from one Dashjoin system to another. This does not enable you to run a federated query like you would within a single SQL database. However, Dashjoin uses this metadata to hyperlink records between databases and logical Dashjoin installations.</p>"},{"location":"concepts/#table-and-instance-layout-and-navigation","title":"Table and Instance Layout and Navigation","text":"<p>The Dashjoin user interface concept is inspired by the Semantic MediaWiki. The database is thought of as a large linked data cloud. Dashjoin user interface pages can be one of the following types:</p> <ol> <li>Record page: Assume the user navigates to the page /DB/TABLE/PK. The system displays a page that corresponds to this record.</li> <li>Table page: Assume the user navigates to the page /DB/TABLE. The system displays a page that corresponds to this concept / table.</li> <li>Dashboard page: Assume the user navigates to the page /page/Page. The system displays this page which has no direct related context in the database.</li> </ol> <p>Unless the low code developer specifies otherwise, table and record pages are displayed as follows:</p>"},{"location":"concepts/#default-table-layout","title":"Default Table Layout","text":"<p>Table pages show</p> <ul> <li>a pageable and sortable data table</li> <li>a form to create a new record</li> <li>if you are in the admin role, controls to edit the table schema and metadata</li> </ul> <p>Within the data table, any primary or foreign key field links to the corresponding record page,</p>"},{"location":"concepts/#default-record-layout","title":"Default Record Layout","text":"<p>Record pages show</p> <ul> <li>a form to edit the record</li> <li>a delete button</li> <li>a link back to the table page</li> <li>links to any related record (this can either a foreign key field of the record or records in other tables containing foreign key references to this record's primary key)</li> </ul> <p>The default layout allows the user to easily navigate the data regardless of which specific database it is located in.</p>"},{"location":"concepts/#widgets-and-custom-layouts","title":"Widgets and Custom Layouts","text":"<p>For each table, the default table and instance layout can be adapted. A layout is a hierarchy of widgets. Widgets that contain other widgets are called containers. Every widget has a couple of properties. The chart widget for example, defines which query to visualize.</p>"},{"location":"concepts/#schema-metadata","title":"Schema Metadata","text":"<p>We already mentioned that a developer can define foreign key relationships, even if the underlying database does not support this concept. Dashjoin allows a number of information to be entered about databases, tables, and columns. This data is usually called metadata. Dashjoin stores this metadata in the built-in configuration database, but this database behaves just like any other database. Therefore, each database and table are records and their pages behave just like any other page in the system.</p>"},{"location":"concepts/#interacting-with-the-system","title":"Interacting with the System","text":"<p>So far, we mostly looked at the way Dashjoin organizes and especially how it visualizes information. This section describes how an application interacts and changes the underlying systems in other ways.</p>"},{"location":"concepts/#create-read-update-delete-crud","title":"Create, Read, Update, Delete (CRUD)","text":"<p>A database driver usually exposes CRUD operations to the platform. These operations are used to display data but also to make changes from the forms displayed in the default layout. Note that, unless configured otherwise, the form shows an edit element for all columns.</p>"},{"location":"concepts/#running-queries","title":"Running Queries","text":"<p>Besides simple read and browse operations, the underlying databases usually have the ability to run powerful queries. Dashjoin allows the developer to design such queries and save them in the query catalog consumption. These queries usually drive table and chart displays on customized layout pages and dashboards. Note that queries can also be used to run delete or update operations nd that they can also be parameterized.</p>"},{"location":"concepts/#executing-functions","title":"Executing Functions","text":"<p>Apart from changing data in databases, Dashjoin can call functions on the backend. You can think of a function as a small pre-built and configurable service. Examples for function types are sending email or making a REST call. These can be instantiated in a system as \"sendGmail\" and \"getStockPrice\" by using the function type and providing the required configuration. These functions can then be used by active page elements such as buttons.</p>"},{"location":"concepts/#evaluating-expressions","title":"Evaluating Expressions","text":"<p>Expressions are small programs that can be used to configure widgets on a page. The display widget for instance can display texts on the UI. The text to display is computed by an expression. This expression can for instance call the stock market function on the backend, and do some additional JSON transformation on the results before displaying the data.</p> <p>You can think of the expressions being the glue between widgets on the top and queries, CRUD and functions on the backend:</p> Widget Expression CRUDFunctionQuery"},{"location":"concepts/#expressions","title":"Expressions","text":"<p>Expressions are small programs that can be used to:</p> <ul> <li>configure widgets on a page (the most common case)</li> <li>save an expression with an Invoke function</li> <li>attach triggers to database tables</li> </ul> <p>This section describes the expression language's syntax and semantics are well as the built-in Dashjoin keywords.</p>"},{"location":"concepts/#jsonata","title":"JSONata","text":"<p>Expressions use the well established JSON query and transformation language JSONata. The JSONata exerciser shows three sections:</p> <ul> <li>the context data (this usually is the record you are browsing on the user interface)</li> <li>the expression</li> <li>the expression result</li> </ul> <p>The JSONata documentation explains the language, the operators, as well as which built-ins are available.</p>"},{"location":"concepts/#javascript","title":"JavaScript","text":"<p>Expressions in widgets, that are evaluated in the browser can alternatively be written in JavaScript. Consider the following rules for this scenario:</p> <ul> <li>Use // JavaScript or //JavaScript in the first line of your expression to switch to the JavaScript runtime</li> <li>Your expression implicitly is run within an async function. Therefore, if you would like the function to return a value to the widget, you must use a return statement at the end.</li> <li>All Dashjoin functions that are available in the JSONata runtime, are also available in JavaScript. Please refer to the developer reference for details. Omit the dollar sign to call them. The only exception is the delete function which is available as _delete. </li> <li>Any backend function (e.g. read to get a value from the database), must be called with the await keyword.</li> <li>The context data (as described in detail in the next section) is available via the variable \"context\".</li> </ul> <p>Consider this example:</p> <pre><code>// Javascript\nconst v = await all(\"config\", \"page\")\nreturn \"user \" + context.email + \" has \" + v.length + \" pages\"\n</code></pre> <p>The first line contains the case insensitive marker.  The second line loads all dashboards from the config database by awaiting the call to the all function. Finally, the result is returned to the widget (a display widget for instance). It appends a text that includes the number of pages (v.length) and the user's email (context.email).</p>"},{"location":"concepts/#jsonata-javascript-in-widgets","title":"JSONata / JavaScript in Widgets","text":"<p>Expressions are provided as widget parameters via the layout editor. The result is used depending on the widget and the expression field. The if parameter, for instance, expects a Boolean value in order to determine whether to show the widget or not. The display widget simply displays the expression result. Consult the widget reference for information about your use case.</p> <p>Every time an expression is evaluated (e.g. by pressing a button or in order to render a display widget), a context is passed to this expression for processing. This section describes what this context looks like under different circumstances.</p>"},{"location":"concepts/#record-page-context","title":"Record Page Context","text":"<p>If expressions are run on a record page, the context is structured as follows:</p> <pre><code>{\n  database: the database the record is in\n  table: the table the record is in\n  pk1, ..., pk4: the (composite) key(s) of the record\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  href: the current URL\n  width: screen width in pixels\n  theme: current theme (light / dark)\n  value: the current record\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below) \n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#table-page-context","title":"Table Page Context","text":"<p>On table pages, the context looks like this:</p> <pre><code>{\n  database: the database the record is in\n  table: the table the record is in\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  locale: the user's locale\n  href: the current URL\n  value: schema information of the current table in JSON Schema format\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below)\n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#dashboard-page-context","title":"Dashboard Page Context","text":"<p>Dashboard pages provide the following context:</p> <pre><code>{\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  locale: the user's locale\n  href: the current URL\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below) \n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#session-variable-context","title":"Session Variable Context","text":"<p>The user interface can store variables per browser tab. Note that these variables are lost once the tab is closed or the user logs out of Dashjoin. A variable can be set from any expression using the \"setVariable\" JSONata function. Therefore, calling setVariable(\"x\", 1) will cause the expression context to be:</p> <pre><code>{\n  ...\n  \"variable\": {\n    \"x\": 1\n  }\n}\n</code></pre>"},{"location":"concepts/#form-context","title":"Form Context","text":"<p>Several widgets allow adding form elements (see section \"Form Widgets\" in the next chapter). If a number form element with name \"y\" has the value 2 and the form is submitted, the context is:</p> <pre><code>{\n  ...\n  \"form\": {\n    \"y\": 2\n  }\n}\n</code></pre>"},{"location":"concepts/#action-table-context","title":"Action Table Context","text":"<p>The action table allows selecting rows from a table. If a table action us run, these rows are added to the context as follows:</p> <pre><code>{\n  ...\n  \"selected\": [\n    selected row 1,\n    ...\n    selected row n\n  ]\n}\n</code></pre>"},{"location":"concepts/#html-and-markdown-context","title":"HTML and Markdown Context","text":"<p>The markdown and HTML widgets allow using string template syntax like <code>${a.b}</code> to include values from the context. These widgets allow adding the result of a custom expression to the context which is then passed as:</p> <pre><code>{\n  ...\n  \"context\": result of the expression in the map / markdown widgets\n}\n</code></pre>"},{"location":"concepts/#jsonata-in-invoke-functions","title":"JSONata in Invoke Functions","text":"<p>The Invoke function allows you to wrap an expression as a function. The context is passed as the function parameter and the result is returned to the function caller. Consider the following example of a Invoke function \"geturl\":</p> <pre><code>{\n  \"ID\": \"geturl\",\n  \"djClassName\": \"org.dashjoin.function.Invoke\",\n  \"expression\": \"$openJson($).parse.some.value\"\n}\n</code></pre> <p>This function opens JSON from a URL, performs some computation with the file contents and returns the result. The URL is passed via the context and is referenced via dollar being the parameter of openJson.</p> <p>Now we can call this function as follows:</p> <pre><code>$call(\"geturl\", \"http://example.org/test.json\")\n</code></pre> <p>In this case dollar evaluates to the string \"http://example.org/test.json\".</p>"},{"location":"concepts/#jsonata-in-triggers","title":"JSONata in Triggers","text":"<p>Triggers allow evaluating expression before or after a write operation on a table.</p> <p>In this case, the context is defined as follows:</p> <pre><code>{\n  user: name of the user on whose behalf the trigger is called\n  command: create, update or delete\n  database: CRUD on this DB\n  table: CRUD on this table\n  search: primary keys of the record, set for delete and update\n  object: object to create or fields to update, set for update and create\n}\n</code></pre> <p>The expression is defined with the table.</p> <p>The result is ignored, unless the trigger function returns the following result:</p> <pre><code>{\n  \"setObject\": the object for the create or update call will be replaced by this object\n}\n</code></pre> <p>This mechanism allows setting default column values or removing keys for columns that should not be changed. You can also use the djVersion function to change the trigger behaviour based on the user role.</p> <p>In order to abort the update, create, or delete operation, you can use the \"error\" function.</p>"},{"location":"contribute/","title":"Contribute","text":"<p>We welcome contributions. If you are interested in contributing to Dashjoin, let us know! You'll get to know an open-minded and motivated team working together to build the next generation platform.</p> <ul> <li>Join our Slack and say hello</li> <li>Follow us on Twitter</li> <li>Submit your ideas by opening an issue with the enhancement label</li> <li>Help out by fixing \"a good first issue\"</li> </ul>"},{"location":"developer-reference/","title":"Developer Reference","text":""},{"location":"developer-reference/#widget-reference","title":"Widget Reference","text":"<p>The following sections describe the platform widgets and which configuration options are available for them. You can create custom widgets and use them just like platform widgets. Please refer to the section Development / Production. Note that all widgets have the title option:</p> <ul> <li>title: when the widget is a direct child of the page container, the widget is placed in a card with this title</li> </ul> <p>Apart from title, all widgets support the following options:</p> <ul> <li>roles: show container only if user is in one of these roles</li> <li>if: show the widget if the expression is true</li> <li>style: CSS widget styles (e.g. width and height of the widget)</li> </ul> <p>These can be edited using Dashjoin Studio. Some widgets, like the container, expose them via the layout editor as well.</p> <p>Widgets can be grouped into the following three categories.</p>"},{"location":"developer-reference/#container-widgets","title":"Container Widgets","text":"<p>Container widgets can contain other widgets. All container widgets have features that control under which conditions content is shown or hidden. Please note that these features are enforced on the client and thus can be manipulated by malicious users. Specifically, do not rely on these features to implement security and data privacy. You can safely restrict access on the server side by applying access control to functions, databases, tables, and queries.</p>"},{"location":"developer-reference/#card","title":"card","text":"<p>Layout card with a title and nested widgets:</p> <ul> <li>text: card title</li> <li>roles: show container only if user is in one of these roles</li> </ul>"},{"location":"developer-reference/#container","title":"container","text":"<p>Container with a plain layout</p> <ul> <li>roles: show container only if user is in one of these roles</li> <li>if: show the widget if the expression is true</li> <li>redrawInterval: redraw interval (seconds). Periodically refreshes the container and all contained content.</li> <li>foreach: expression that evaluates to an array of objects. The first child of the container is rendered for each object, with the \"value\" context set to the respective array item (Dashjoin Studio only)</li> <li>layout: if foreach is used, use \"horizontal\" or \"vertical\" layout (Dashjoin Studio only)</li> </ul>"},{"location":"developer-reference/#expansion","title":"expansion","text":"<p>Collapsible container with nested widgets</p> <ul> <li>text: card title</li> <li>roles: show container only if user is in one of these roles</li> <li>expression: optional expression to compute whether the widget's initial expansion state</li> </ul>"},{"location":"developer-reference/#page","title":"page","text":"<p>The page widget is implicitly present at the root on any platform page. It cannot be edited via the layout editor, but changes can be made in Dashjoin Studio.</p> <ul> <li>onRender: expression that is evaluated when the page renders in the browser. This is useful if you need to initialize variables that are used in expressions of other widgets. Note that variables are stored per browser tab whereas the login session applies to the entire browser. Therefore, variables should be set using onRender instead of on-login.</li> </ul>"},{"location":"developer-reference/#stepper","title":"stepper","text":"<p>The stepper widget allows stepping through its children. It displays the step number and title along with the child at the current step position. Note that the widget does not display back and next buttons. The stepper child widgets are responsible for advancing the current page via the JSONata functions stepBack, stepForward, and setActiveStep.</p>"},{"location":"developer-reference/#tabs","title":"tabs","text":"<p>The tabs widget displays its children in a container which allows selecting the current tab on top. The child titles are used as a label. Only the active tab is shown.</p> <ul> <li>foreach: expression that evaluates to an array of objects. The first child of the container is rendered for each object, with the \"value\" context set to the respective array item (Dashjoin Studio only)</li> </ul>"},{"location":"developer-reference/#form-widgets","title":"Form Widgets","text":"<p>Like containers, form widgets allow adding input elements. Every input widget must use a unique name which is in turn used as the key in the resulting JSON structure. Inputs can be of the following type:</p> <ul> <li>boolean: displays an on/off toggle and returns a boolean value</li> <li>string; a regular text box that returns a string</li> <li>number: a number input returning a number</li> <li>auto complete: an input field with auto-complete options (which are generated by a JSONata expression)</li> <li>select: like auto complete, but uses a select widget instead of a text field</li> <li>multi select: like select but allows multiple selections, returns an array</li> <li>key value: allows entering any key value pairs, returns an object</li> <li>password: like string but hides the input</li> <li>textarea: like string but uses a multi-line input</li> <li>date: like string but uses a date picker</li> <li>time: like string but uses a time picker</li> <li>datetime: like string but uses a datetime picker</li> <li>file: like string but uses the content of an uploaded file are the value</li> <li>binary file: like file, but uses base64 encoding</li> <li>file with metadata: like file but includes file metadata</li> <li>binary file with metadata: like binary file but includes file metadata</li> <li>voice: like string, but offers a speech to text input option (language option is available via Dashjoin Studio)</li> <li>qrcode: like string, but offers a QR Code scanner</li> </ul> <p>Further options include: * an optional title for the input element * a description which shows up as a tooltip * an optional expression to compute select options (must return an array of strings or an array of objects containing name and value) * CSS options (e.g. width: 500px) * Read only flag (input is inactive) * Required flag * An optional format validation</p> <p>Not all form options can be edited in the form edit dialog. If you would like to create a form for nested objects and arrays, you can add the JSON schema to the form in Dashjoin Studio. This example displays a form to enter an object with a field emails which is an array of strings: </p> <pre><code>            {\n                \"print\": \"form\",\n                \"widget\": \"button\",\n                \"schema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"emails\": {\n                            \"type\": \"array\",\n                            \"items\": {\n                                \"type\": \"string\"\n                            }\n                        }\n                    }\n                }\n            }\n</code></pre> <p>If you choose one of the file upload widgets, you can add the attribute multiple: true via Dashjoin Studio. This allows you to upload multiple files at once. Note that the return value changes from a single value to an array if you do so.</p> <p>In addition to the attribute multiple, you can specify capture: user or capture: environment. This setting allows taking and uploading a foto using the inward or outward camera. Setting accept: video/* takes a video instead of a photo.</p>"},{"location":"developer-reference/#button","title":"button","text":"<p>Runs / evaluates an expression when clicked.</p> <ul> <li>text: text shown for the run button (default is \"Run\")</li> <li>print: evaluates this expression when clicked</li> <li>expression: optional expression - the form fields are initialized with the result of this expression</li> <li>schemaExpression: optional JSONata expression that computes a JSON Schema driving the input form (this option is only available in Dashjoin Studio). Note that forms drawn using schemaExpression do not use the layout editor. You can arrange input elements using the \"order\" field explained in this example.</li> <li>deleteConfirmation: optional confirmation message before performing the action (this option is only available in Dashjoin Studio - you can prompt the user via JSONata as follows):</li> <li>icon: icon to show left of the text (this option is only available in Dashjoin Studio)</li> </ul> <pre><code>$prompt('Are you sure?' ? perform action : 'cancelled')\n</code></pre> <p>The form content (if a form is present), is added to the context using the key \"form\". This widget is a container. Any form elements are defined by adding an \"Input\" widget for each form field.</p>"},{"location":"developer-reference/#create","title":"create","text":"<p>Creates new database records:</p> <ul> <li>text: text shown for the create button (default is \"Create\")</li> <li>database: optional database to create the record in (defaults to the database of the table you are currently displaying)</li> <li>table: optional table to create the record in (defaults to the table you are currently displaying)</li> </ul>"},{"location":"developer-reference/#edit","title":"edit","text":"<p>allows editing a database record. Note that the form layout can be customized in the layout editor. Please also refer to the FAQ for information on how to further customize the input form.</p> <ul> <li>deleteConfirmation: optional confirmation message before deleting the record (this option is only available in Dashjoin Studio - edits on database tables can be undone within five seconds)</li> <li>editRedirect: redirect after save (Dashjoin Studio only) - table: back to table view (default), record: stay on record page, page/Dashboard, db/table, db/table/id: navigate to fixed page</li> <li>deleteRedirect: redirect after delete (Dashjoin Studio only) - table: back to table view (default), record: stay on record page, page/Dashboard, db/table, db/table/id: navigate to fixed page</li> <li>mutationMode: determines how the edit is processed (Dashjoin Studio only) - undoable (default): edit is applied after some seconds in which the user can undo the change, pessimistic: wait until the edit is written</li> </ul>"},{"location":"developer-reference/#variable","title":"variable","text":"<p>Displays a form that allows setting session variables. If a variable \"x\" is defined and set, it can be referenced in other widgets using \"variable.x\". A variable can be set via a URL query parameter. Appending ?a=1&amp;b=test to the URL will set variable.a to \"1\" and variable.b to \"test\". Note that only string variables can be set this way, so you might have to use $number(variable.a) when using the variable.</p> <ul> <li>text: text shown for the apply button (default is \"Apply\")</li> </ul> <p>This widget is a container. Any form elements are defined by adding an \"Input\" widget for each form field.</p>"},{"location":"developer-reference/#regular-widgets","title":"Regular Widgets","text":""},{"location":"developer-reference/#actiontable","title":"actionTable","text":"<p>The Action table widget works like the table widget. In addition, it allows selecting several rows in the table. If rows are selected, action buttons become visible. The actions are configured via a set of key value pairs. The key specifies the action button's label, the value contains the expression that is run if the button is pressed.</p> <ul> <li>expression: allows configuring the widget data via JSONata which must evaluate to an array of objects. Note that the table is able to display links, images, and lists thereof. Please refer to the display widget for information on how the JSON data must be structured. If omitted, the widget uses $query(database, query, arguments)</li> <li>properties: a set of key value pairs. For every key, an action button with the key used as its label is displayed. When the button is pressed, the JSONata expression specified in the value is run  </li> <li>perPage: default number of rows to display</li> <li>columns: columns to display. Use this option if you need certain fields to be included in the selection value but don't want those values to be included in the table. Note that this option is only available in Dashjoin Studio</li> <li>hideTablePagination: if true, hide table pagination (Dashjoin Studio only)</li> <li>hideTableActions: if true, hide export and filter buttons on the table (Dashjoin Studio only)</li> </ul>"},{"location":"developer-reference/#aichat","title":"aichat","text":"<p>Chatbot widget for interacting with large language models.</p> <ul> <li>url: LLM Service URL or function name</li> <li>name: Chatbot name</li> <li>tagline: Chatbot tagline</li> <li>logo: Logo URL</li> <li>system_prompt: AI system prompt</li> </ul>"},{"location":"developer-reference/#analytics","title":"analytics","text":"<p>Like chart and table, but allows exposing query filters to the user. The query can be based on a table or a base query. The widget configuration allows defining projection, aggregation, and filters in the widget configuration (i.e. without having to rely on the query catalog).</p> <ul> <li>database: database to run the query on</li> <li>table: the table to query and filter</li> <li>chart: chart type or table</li> <li>style: see chart widget</li> <li>columns: a list of columns to project / aggregate from the table or query</li> <li>filter: a list of filters to expose to the user</li> <li>hideTablePagination: if true, hide table pagination (Dashjoin Studio only)</li> <li>hideTableActions: if true, hide export and filter buttons on the table (Dashjoin Studio only)</li> </ul> <p>The following settings are available in Dashjoin Studio only:</p> <ul> <li>query: optionally base the widget on this query instead of a single table</li> <li>arguments: optional expression resulting in query arguments</li> </ul>"},{"location":"developer-reference/#chart","title":"chart","text":"<p>Chart for visualizing query results.</p> <ul> <li>database: database to run the query on</li> <li>query: query to run; the query is expected to project the following column structure:<ul> <li>label followed by a value column: in this case, a chart with a single series is shown. The first column is used as the series axis label and the second column is used as the value range</li> <li>two label columns followed by a value column: in this case, a chart with a multiple series is shown. The first column identifies which series the row belongs to. From there, the process described above is repeated</li> </ul> </li> <li>arguments: optional expression resulting in query arguments</li> <li>chart: chart type</li> <li>style: key value pairs that construct chart option object - for instance, scales.y.min = 0 makes sure the y-axis starts at 0. By default, the chart limits the number of data points to 1000. This can be overridden by setting \"limit\" to the desired value</li> <li>graph: specifies whether the query is a graph query</li> <li>expression: allows configuring the widget via JSONata. If omitted, the widget uses $query(database, query, arguments)</li> </ul> <p>Examples: * chart-stacked-bar * chart-timeline</p>"},{"location":"developer-reference/#datagrid","title":"datagrid","text":"<p>Allows editing records from a grid.</p> <ul> <li>expression: Expression that returns a table (list of objects) that populates the grid onchange: Expression to run when a value is changed. The expression gets passed \"id\", which is the primary key of the row and \"updatedRow\" which is the new row value object. ondelete: Expression to run when a row is deleted. The expression gets passed \"id\", which is the primary key of the row oncreate: Expression to run when a row is created. columns: Optional array of column description objects. The object can use the fields described here. Defaults to an editable column with the name and type found in the data.  idColumn: Optional name of the column that serves as the primary key. Note that the primary key column is removed from the display and cannot be edited. Any column name containing the substring \"id\" is used as the default.</li> </ul> <p>Consider this example to edit the northwind employee table. Note that the oncreate expression must create a unique primary key (select max + 1) and also provide default values for the values required by the database constraints:</p> <pre><code>{\n  \"widget\": \"datagrid\",\n  \"expression\": \"$all('northwind', 'EMPLOYEES')\",\n  \"onchange\": \"$update('northwind', 'EMPLOYEES', id, updatedRow)\",\n  \"ondelete\": \"$delete('northwind', 'EMPLOYEES', id)\",\n  \"oncreate\": \"$create('northwind', 'EMPLOYEES', {'EMPLOYEE_ID': $adHocQuery('northwind', 'select max(EMPLOYEE_ID)+1 as X from EMPLOYEES').X, 'LAST_NAME': ' ', 'FIRST_NAME': ' '})\",\n  \"idColumn\": \"EMPLOYEE_ID\",\n}\n</code></pre>"},{"location":"developer-reference/#diagram","title":"diagram","text":"<p>Allows displaying and editing data as a graph of nodes and edges.</p> <p>Nodes are represented by the following JSON structure:</p> <pre><code>{\n  id: node id\n  database: database name\n  table: table name\n  position?: {\n    x: coordindate\n    y: coordindate\n  },\n  data?: {\n    label: display label\n  }\n}\n</code></pre> <p>Edges are represented by the following JSON structure:</p> <pre><code>{\n  source: id of the edge source node\n  target: id of the edge target node\n}\n</code></pre> <ul> <li>nodes: JSONata that generates a list of nodes</li> <li>edges: JSONata that generates a list of edges</li> <li>moveNode: optional JSONata to persist new coordinates (e.g. $update(\"northwind\", \"EMPLOYEES\", node.id, {\"Y\": node.position.y}))</li> <li>addNode: optional JSONata to persist new node that was added via SHIFT click (e.g. ($x := {\"id\": node.name, \"x\": node.position.x, \"y\": node.position.y}; $create(\"db\", \"table\", $x); $x) )</li> <li>removeNode: optional JSONata to remove node in the DB (passed via node.id)</li> <li>addEdge: optional JSONata to create a relationship (passed via edge.source, edge.target)</li> <li>removeEdge: optional JSONata to remove a relationship (passed via edge.source, edge.target)</li> </ul>"},{"location":"developer-reference/#display","title":"display","text":"<p>Displays the result of an expression:</p> <ul> <li>display: expression to display</li> <li>icons: if display evaluates to an object, icons maps the object keys to material icons</li> <li>hideTablePagination: if true, hide table pagination (Dashjoin Studio only)</li> <li>hideTableActions: if true, hide export and filter buttons on the table (Dashjoin Studio only)</li> </ul> <p>Depending on the result of the evaluation, one of the following cases applies:</p> <ul> <li>a single result value is displayed as is</li> <li>an object is displayed as a key-value list</li> <li>if the object has exactly the keys \"database\", \"table\", and \"pk1\", the result is displayed as a link to the record identified by these values</li> <li>if the object has exactly the keys \"database\", \"table\", \"pk1\", and \"page\", the result is displayed as a link to the record identified by these values and uses the specified page to visualize the record</li> <li>an array of objects is displayed as a table</li> <li>if the object has exactly the key \"img\" (with optional width and height), the result is displayed as an HTML image with the value of the img field being used as the image src attribute</li> <li>if the object has exactly the key \"href\" or the keys \"href\" and \"label\", the object is displayed as a hyperlink (note that absolute or relative links to another page in the app are specified without the \"slash hash\" part of the URL - for instance, the href \"Info\" or \"/page/Info\" links to the Info page)</li> <li>if the object has exactly the key \"qrcode\", the string is displayed as a QR code</li> </ul> <p>Example: <pre><code>  \"display\": {\n    \"item one\": \"this item's value\",\n    \"item two\": \"another value\",\n    \"item three\": \"last value\",\n  },\n  \"icons\": {\n    \"item one\": \"traffic\",\n    \"item two\": \"turn_left\"\n  }\n</code></pre></p> <p></p> <p>Item one will be displayed with the \"traffic\" icon, item two with the \"turn_left\" icon. When no item is specified for a key, the default item is used. In the above example, \"item three\" will display the default icon.</p> <p>When icons is \"*\": \"icon\", all icons will be mapped to that same specified icon.</p>"},{"location":"developer-reference/#editrelated","title":"editRelated","text":"<p>Allows editing related records of a database record:</p> <ul> <li>prop: foreign key column on the related table</li> <li>columns: columns\u00a0to\u00a0display\u00a0in\u00a0the\u00a0editRelated\u00a0table\u00a0display. Note that this option is only available in Dashjoin Studio</li> </ul>"},{"location":"developer-reference/#graph","title":"graph","text":"<p>Displays data as a directed graph</p> <ul> <li>nodes: expression to generate nodes, this can either be the result of an OpenCypher query or a list of nodes</li> <li>_3d: if true, displays the graph in 3D, 2D otherwise</li> </ul> <p>To add a single starting node, you can simply use the following expression for \"nodes\":</p> <pre><code>{\n  \"database\": \"northwind\",\n  \"table\": \"EMPLOYEES\",\n  \"pk\": [1]\n}\n</code></pre> <p>To add all employees, you can select all employee IDs and convert them into resource objects as shown above:</p> <pre><code>$all(\"northwind\", \"EMPLOYEES\").EMPLOYEE_ID.{\n  \"database\": \"northwind\",\n  \"table\": \"EMPLOYEES\",\n  \"pk\": [$]\n}\n</code></pre> <p>Alternatively, you can use an OpenCypher query:</p> <pre><code>$adHocQueryGraph(\"*\", \"MATCH (e:EMPLOYEES) return e\").e\n</code></pre> <p>The previous examples only added nodes to the canvas. You can use OpenCypher to pre-select a path:</p> <pre><code>$adHocQueryGraph(\"*\", \"MATCH path=(e:EMPLOYEES) -[REPORTS_TO]-&gt; (x) return path\").path\n</code></pre>"},{"location":"developer-reference/#html","title":"html","text":"<p>Displays custom HTML</p> <ul> <li>html: HTML to display</li> <li>context: an expression that allows setting additional context variables that can be referenced via <code>${context.VARIABLE}</code></li> <li>script: JavaScript function definitions the can be called from HTML onClick or other event handlers</li> </ul> <p>As in the Markdown widget, hyperlinks to other pages in the app have to include the \"slash hash\" part of the URL.</p> <p>Please note that if you are displaying multiple HTML widgets on a page, these widgets share (and subsequently overwrite) the contents of context. If you only display the context in the widget, this is no problem. If you use context from an event handled (e.g. onClick), you have the use the following workaround that uses a session varable. This allows you to choose different variables for each widget:</p> <pre><code>{\n  \"html\": \"&lt;button onClick='go()'&gt;\",\n  \"script\": \"function go(){ console.log(JSON.parse(sessionStorage.variable).x) }\",\n  \"context\": \"$setVariable('x', 'my value')\",\n  \"widget\": \"html\"\n}\n</code></pre>"},{"location":"developer-reference/#icon","title":"icon","text":"<p>Displays a hyperlink icon with tooltip</p> <ul> <li>href: optional link target</li> <li>icon: icon to display (see https://material.io/resources/icons/?style=baseline)</li> <li>tooltip: icon tooltip</li> <li>roles: show container only if user is in one of these roles</li> </ul>"},{"location":"developer-reference/#links","title":"links","text":"<p>Displays links to related records</p>"},{"location":"developer-reference/#map","title":"map","text":"<p>Displays a map for a given location. </p> <ul> <li>display: expression that results in a location - this value is resolved using the q query parameter of the Open Streetmap API service. The expected result structure is explained below</li> <li>css: CSS code to apply to the map</li> <li>card: determines if the map is shown on a card (paper background)</li> </ul> <p>The map can be fed with the following data:</p> <pre><code>{\n  center: {lat, lon}   // map center\n  zoom: number         // zoom level where globe=1 and street=15\n  points: [            // array of marker points\n    {\n      address: string  // address where marker is placed or marker coordinates\n      location: {lat, lon}\n      color: string    // marker color\n      radius: number   // marker radius\n      tooltip: any     // additional info to be displayed in tooltip or popup\n      popup: any       // any JSON is displayed like in the display widget\n    }\n  ]\n}\n</code></pre> <p>Note that most information is optional. The platform chooses good defaults. For instance, you can display a single address with a link to a record page as follows:</p> <pre><code>{\n  \"points\": [\n    {\n      \"address\": \"London\",\n      \"popup\": {\n        \"database\": \"northwind\",\n        \"table\": \"CUSTOMERS\",\n        \"pk\": [ \"AROUT\" ]\n      }\n    }\n  ]\n}\n</code></pre> <p>If you would just like to show a marker at London, you can simply pass the string:</p> <pre><code>\"London\"\n</code></pre>"},{"location":"developer-reference/#markdown","title":"markdown","text":"<p>Displays markdown</p> <ul> <li>markdown: markdown to display</li> <li>context: an expression that allows setting additional context variables that can be referenced via <code>${context.VARIABLE}</code></li> <li>card: determines if the markdown is shown on a card (paper background)</li> </ul> <p>Note that the HTML generated by the markdown engine is sanitized in order to avoid XSS vulnerabilities. Specifically, if you are using HTML tags, style attributes are filtered. A common task is to add margins to images. You can achieve this by adding a class attribute to the element and setting the value to a predefined material class like mat-elevation-z8. Alternatively, the markdown widget defines the styles margin1 to margin5 which set the element margin to 1em to 5em.</p> <p>As in the HTML widget, hyperlinks to other pages in the app have to include the \"slash hash\" part of the URL.</p>"},{"location":"developer-reference/#mdxeditor","title":"mdxeditor","text":"<p>This component offers a full fledged WYSIWYG markdown editor that can be extended with custom menus to call any JSONata or JavaScript expressions.</p> <ul> <li>markdown: markdown to display</li> <li>context: an expression that allows setting additional context variables that can be referenced via <code>${context.VARIABLE}</code></li> <li>card: determines if the editor is shown on a card (paper background)</li> <li>expression: an optional expression to compute the structure of additional menus that call expresions defined using \"properties\". Please see the example below.</li> <li>properties: a set of key value pairs composing the widget's expression library. The keys are the expression names, the values are the actual expression to be called</li> </ul> <p>Consider the following example. The markdown and context work just like the markdown widget above. This widget allows the user to edit the text and call expressions via the custom menu.</p> <pre><code>{\n  \"widget\": \"mdxeditor\"\n  \"markdown\": \"# Hello ${user} ${context}\",\n  \"context\": \"'my context expression'\",\n  \"properties\": {\n    \"alert\": \"$alert('selection: ' &amp; selection &amp; '. markdown: ' &amp; markdown)\",\n    \"log\": \"$log($)\",\n    \"sleep\": \"($progress({'message': 'working'});$sleep(1000))\"\n  },\n  \"expression\": \"{... see below}\",\n}\n</code></pre> <p>The widget defines three expressions:</p> <ul> <li>alert: shows that we can use the context fields markdown and selection to access the entire document (with the user's changes) or the text selected in the editor</li> <li>log: simply logs th entire expression context in the console</li> <li>sleep: an example for how to provide feedback for operations with a longer runtime</li> </ul> <p>The menu structure is defined by an expression the yields the following JSON:</p> <pre><code>{\n  \"menu\": [\n    {\n      \"type\": \"select\",\n      \"title\": \"tooltip\",\n      \"label\": \"longer operation\",\n      \"value\": \"sleep\",\n      \"items\": [{}]\n    },\n    {\n      \"type\": \"select\",\n      \"title\": \"tooltip\",\n      \"label\": \"Label\",\n      \"items\": [\n        {\n          \"label\": \"alert popup\",\n          \"value\": \"alert\"\n        },\n        {\n          \"label\": \"doc to console\",\n          \"value\": \"log\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre> <p>The first menu items displays clickable button in the menu bar that runs expression \"sleep\". The second item displays the menu \"Label\" that has two submenus, calling \"alert\" and \"log\" respectively.</p>"},{"location":"developer-reference/#notebook","title":"notebook","text":"<p>This widget is the JSONata equivalent of a Jupyter notebook. It allows composing and running several expressions. The result of every expression is stored in the browser session. You can also assign variables and use them in other expressions. </p> <p>The widget offers a save function at the bottom. This saves the entire page and the expressions contained within. Please note that the notebook widget should only be used as the sole widget on the page, since saving the notebook will delete other widgets you might place on the page.</p>"},{"location":"developer-reference/#table","title":"table","text":"<p>Displays query results as a table</p> <ul> <li>database: database to run the query on</li> <li>query: query to run</li> <li>arguments: optional expression resulting in query arguments</li> <li>graph: specifies whether the query is a graph query</li> <li>expression: allows configuring the widget data via JSONata which must evaluate to an array of objects. Note that the table is able to display links, images, and lists thereof. Please refer to the display widget for information on how the JSON data must be structured. If omitted, the widget uses $query(database, query, arguments)</li> <li>columns: if no query or expression is specified, this array allows specifying the columns to be projected. Note that this option is only available in Dashjoin Studio</li> <li>perPage: default number of rows to display</li> <li>deleteConfirmation: optional confirmation message before bulk deleting records (this option is only available in Dashjoin Studio - edits on database tables can be undone within five seconds)</li> <li>mode: defines how the table is displayed. 'desktop' shows the normal wide table with all columns (this is the default). 'mobile' shows a narrow list view with up to three column values and an icon. 'auto' uses the other two modes depending on the user's device</li> <li>hideTablePagination: if true, hide table pagination (Dashjoin Studio only)</li> <li>hideTableActions: if true, hide export and filter buttons on the table (Dashjoin Studio only)</li> </ul> <p>The following options are only available in Dashjoin Studio. The define how the narrow table version is populated. The text properties are optional. If omitted, the platform chooses a table column to display in the respective slot. To choose a specific column, specify the column name. To make sure the slot stays empty, please choose a non-existing name.</p> <ul> <li>primaryText: Text to be displayed on the upper left of the list</li> <li>secondaryText: Text to be displayed on the lower left of the list </li> <li>tertiaryText: Text to be displayed on the right of the list</li> <li>leftIcon: Optional name of the column that contains the icon name</li> </ul> <p>Database and table can be omitted on table pages. In this case, the widget displays the equivalent of a select all from the respective table.</p>"},{"location":"developer-reference/#text","title":"text","text":"<p>Displays a simple text</p> <ul> <li>href: optional link target</li> <li>text: text to display</li> <li>icon: optional icon to display in front of the text</li> </ul>"},{"location":"developer-reference/#tree","title":"tree","text":"<p>Displays a tree based on a recursive query</p> <ul> <li>database: database to run the query on</li> <li>query: query that projects a single column with the keys of the current node's children. The primary key of the current node (null for the tree root) is passed as a query argument. The query typically has the form: select id from recursiveTable where fk=parameter</li> <li>expression: allows configuring the widget via JSONata. The result must be a node or an array of nodes. A node has the fields data and an optional field children. The widget displays the contents of data similar to the display widget. If data includes an icon field, the tree is displayed like this.</li> </ul>"},{"location":"developer-reference/#uploadfile","title":"uploadfile","text":"<p>Allows uploading files to the upload directory. Note that WebDAV must be turned on using the WEBDEV_ENABLED environment variable (see Installation - Environment).</p> <ul> <li>allowFolderSelectionRecursive: Recursively get subdirectories</li> <li>preserveFolders: Preserve recursive folder structure at the destination</li> </ul>"},{"location":"developer-reference/#functions","title":"Functions","text":"<p>Apart from changing data in databases, Dashjoin can call functions on the backend. Functions come in two flavors: First, there are functions that simply extend the functionality you can use in expressions. An example would be a simple toUpperCase function that transforms a string to upper case. These functions are introduced further later in the section on expressions. Second, there are configurable functions. These work very much like their counterpart, however, they require additional configuration parameters. An example would be a function to send an email. The actual function call requires you to specify subject, sender, receiver, and the body. But you would not want to have to repeat the email server address and credentials every time. So you can register an instance of email service with specific parameters and call it email-service-1. This section describes the latter configurable functions.</p> <p>Click here for a demo video.</p>"},{"location":"developer-reference/#function-reference","title":"Function Reference","text":"<p>The system supports the following functions. Each section lists the function configuration parameters that are constant any time this function is called as well as the parameters that are specific for each invocation.</p>"},{"location":"developer-reference/#restjson","title":"RestJson","text":"<p>Calls an external REST service. If you need more control over the how the call is performed, please use the JSONata function curl.</p> <p>Configuration</p> <ul> <li>url: the URL of the REST service to call (the URL may contain template variables <code>${var}</code> which are replaced with the respective argument field)</li> <li>username: optional HTTP basic authentication user name</li> <li>password: optional HTTP basic authentication password</li> <li>method: GET or POST</li> <li>headers: HTTP headers</li> <li>contentType: content-type header application/json or url-form-encoded</li> <li>apiKey: if true, use username / password as another header - this feature can be used to pass API keys etc. while not having to show the key in plain text in the header input form. If this value is omitted or false, username and password are converted to a basic authentication header</li> <li>timeoutSeconds: Optional HTTP timeout in seconds</li> </ul> <p>Invocation parameter</p> <ul> <li>object: If object is specified, POSTs the object serialized as JSON. If object is null, GETs the result</li> </ul> <p>Return value</p> <ul> <li>JSON result returned by the service</li> </ul>"},{"location":"developer-reference/#email","title":"Email","text":"<p>Sends an email.</p> <p>Configuration</p> <ul> <li>username: username to log into the email service</li> <li>password: password to log into the email service</li> <li>properties: SMTP server configuration</li> </ul> <p>Invocation parameter</p> <ul> <li>from: email sender in RFC822 syntax</li> <li>to: email recipient in RFC822 syntax</li> <li>subject: email subject line</li> <li>text: email text</li> </ul> <p>Return value</p> <ul> <li>none</li> </ul>"},{"location":"developer-reference/#invoke","title":"Invoke","text":"<p>Allows saving an expression on the server. When run, we evaluate / apply the expression with the data context passed as an argument.</p> <p>Configuration</p> <ul> <li>expression: The expression to save and run when invoked</li> </ul> <p>Invocation parameter</p> <ul> <li>object: the expression evaluation context (see next chapter)</li> </ul> <p>Return value</p> <ul> <li>expression result</li> </ul>"},{"location":"developer-reference/#credentials","title":"Credentials","text":"<p>Allows saving credentials that can be referenced by the JSONata curl function. This is done by specifying the authorization header and setting it to the name of the credential:</p> <pre><code>$curl(\"GET\", \"http://localhost:8080/rest/manage/version\", {}, {\"Authorization\": \"credential name\"})\n</code></pre> <p>This works for both basic authentication and passing an API key via some generic HTTP header.</p> <p>Configuration:</p> <ul> <li>username: credential username</li> <li>password: credential password</li> <li>apiKey: if true, use username / password as another header - this feature can be used to pass API keys etc. while not having to show the key in plain text in the header input form. If this value is omitted or false, username and password are converted to a basic authentication header</li> </ul>"},{"location":"developer-reference/#mapping-functions","title":"Mapping Functions","text":"<p>Mapping functions are specialized functions that have no invocation parameters and outputs. They are used to write data into a database and can be run in a scheduled fashion. All mapping functions perform the following three steps.</p> <p>Click here for a demo video.</p>"},{"location":"developer-reference/#gathering-data","title":"Gathering Data","text":"<p>It is up to the mapping function how this task is achieved. The only requirement is that the function gathers a set of tables. </p>"},{"location":"developer-reference/#the-mapping-step","title":"The Mapping Step","text":"<p>This step is common to all mapping functions and is supported by a specialized mapping editor. The mapping step transforms the gathered set of tables into another set of tables. The mapping step supports the following operations:</p> <ul> <li>remove table: a table from the initial step can be removed / ignored</li> <li>remove column: drops a column from a table</li> <li>rename table: a table from the initial step can be renamed</li> <li>rename column: renames a column in a table</li> <li>add table: a table can be added by providing the name of an initial table</li> <li>add column: a column can be added to a table</li> <li>modify column: sets the column to a new expression (the default simply copies the original value 1:1 using <code>$.columnname</code>; please see the next section for more details on expressions)</li> <li>extract table: if an input table contains a column with array values, extracts the union of these arrays into a new table</li> </ul>"},{"location":"developer-reference/#the-save-step","title":"The Save Step","text":"<p>The save step writes the output of the mapping step into the database. The following modes are supported:</p> <p>Ignore</p> <p>Simply add the data (update in case the record already is in the DB, insert if not). We follow the \"normal\" update semantics meaning that key=null actually deletes the value in the DB, whereas missing keys remain untouched.</p> <p>Database</p> id _dj_source name 1 Joe 2 Mike <p>Extracted Data from ETL \"ignore\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 John 2 Mike 3 ignore Nate <p>Row 1 is updated. Row 2 remains unchanged. Row 3 is added and thus gets marked as having source e.</p> <p>Extracted Data from ETL \"ignore\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 John 2 Mike 3 ignore Nate 4 ignore Jane <p>Row 4 gets added. Row 3 remains even though it is no longer in the extraction result.</p> <p>Refresh</p> <p>All records from the target tables that have the _dj_source column matching the ID of this function are updated. If a key is no longer present in the new data, the record is deleted.</p> <p>Database</p> id _dj_source name 1 Joe 2 Mike <p>Extracted Data from ETL \"refresh\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 John 2 Mike 3 refresh Nate <p>The first run of \"refresh\" has the same effect as \"ignore\".</p> <p>Extracted Data from ETL \"refresh\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 John 2 Mike 4 refresh Jane <p>The third row, which was added by \"refresh\" previously, is deleted and row 4 is added.</p> <p>Delete All</p> <p>All records from the target tables are deleted, if createSchema is true, the tables are also dropped in case columns are no longer needed or previously had another datatype.</p> <p>Database</p> id _dj_source name age 1 Joe 33 2 Mike 44 <p>Extracted Data from ETL \"delete-all\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 delete-all John 3 delete-all Nate <p>The table content is deleted. If create schema is specified, the age column is also deleted. Rows 1 and 3 get added with the respective source.</p> <p>Extracted Data from ETL \"delete-all\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 delete-all John 4 delete-all Jane <p>The table content is deleted and rows 1 and 4 are added.</p> <p>Sync</p> <p>The sync mode works like Ignore. In conjunction with the foreach expression, it can be used to keep the database in sync with a file system or a web download location, by deleting certain entries. This is explained in the next section.</p>"},{"location":"developer-reference/#mapping-function-reference","title":"Mapping Function Reference","text":""},{"location":"developer-reference/#etl","title":"ETL","text":"<p>The ETL function uses an expression as input into the mapping process. The expression result can be a map of table names to an array of rows (JSON objects). If the expression result has a simpler structure (for instance only a single table), the ETL function wraps this in a default table called \"table\".</p> <p>If you want to load a large amount of data, you can use the \"foreach\" expression to specify how to split the loading process into smaller parts. Assume you have a directory with thousands of files to load. The foreach expression can list the files using <code>$ls(\"url\")</code>. The expression then specifies how each file is handled. Its <code>$</code> context is set to each individual URL and the expression and subsequent ETL are called for each URL individually.</p> <p>Note that you can also stream large JSON, XML, or CSV files via the streamJson, streamXml, and streamCsv functions. In this case, these functions split a large file into smaller chunks which are then passed to the mapping expression.</p> <p>The setting \"ETL worker threads\" can be used to achieve parallel writes to the database. This setting is only applicable if a foreach expression is specified. In this case, the setting \"ignore ETL errors and continue process\" specifies that any error that occurs when streaming a large file (e.g. a formatting error towards the end of the file) or when workers map and write the contents to the database (e.g. due a malformatted date string) are ignored and do not stop the other workers.</p>"},{"location":"developer-reference/#etl-sync","title":"ETL Sync","text":"<p>The foreach construct also allows you to conveniently keep the database in sync with a set of files on the file system or the web. Consider the following foreach expression:</p> <pre><code>$ls(\"file:upload\")\n</code></pre> <p>It returns a list of objects describing files in the upload folder. Let's assume those are JSON files, that are mapped to the database using this expression:</p> <pre><code>{\n  \"url\": url,\n  \"modified\": modified,\n  \"content\": $openJson(url)\n}\n</code></pre> <p>Now we can compute the urls and modified timestamps that are in the database:</p> <pre><code>$all(db, table) // please use a native distinct query for large datasets\n</code></pre> <p>The platform offers the etlSync function that computes the set of URLs that must be loaded for the next run and the records that might have been deleted using the URLs and modified pairs:</p> <pre><code>$etlSync($ls(\"file:upload\"), $all(db, table), \"url\")\n</code></pre> <p>The third parameter specifies the name of the database column that contains the source URL. You can use this as the foreach expression. If you choose the mode \"Ignore\", new files will be added, unchanged files will be skipped, and deleted file remain in the database.</p> <p>If you choose mode \"Sync\", deleted and modified files will be removed from the DB first. Note that if you do not have a modified timestamp available, you can also use some sort of version string or etag to notify the system about a change in a source file.</p>"},{"location":"developer-reference/#receive","title":"Receive","text":"<p>The receive function allows handling cases, where the platform is being sent data that is to be processed and saved into a database. This use case is common in IoT scenarios where a stream of sensor data is passed via the REST API. The Receive function can be configured like the ETL function and allows mapping the data into the desired structure. The create schema parameter works like in the ETL case and optionally adapts the underlying schema to accommodate new fields and tables. Receive defines a parameter called sample where a stream data sample can be added. This sample data is used to edit the mapping. Note that Receive always appends the new data like the Ignore mode in the ETL case. The difference is that there is no expression that fetches data. Instead, the data is passed via the API call.</p>"},{"location":"developer-reference/#dashjoin-expression-reference","title":"Dashjoin Expression Reference","text":"<p>In addition to the default JSONata built-in functions (see Function Library), the following Dashjoin functions are added (some internal functions are omitted - you can refer to the platform's info page for a full list):</p> <p>These functions can be classified as frontend and backend functions. Frontend functions run in the browser and can be used to trigger a screen popup or to set a browser session variable. Backend functions typically access backend data. You can mix both kinds in a single JSONata expression tree. </p>"},{"location":"developer-reference/#frontend-expressions","title":"Frontend Expressions","text":"Function Syntax Returns confirm $confirm(message) Opens a confirm dialog. Returns true if confirmation was given, false otherwise setVariable $setVariable(key, value) Sets variable key to value. The key value pair then becomes accessible via the context by other expressions prompt $prompt(message) Prompts the user for an input. Returns the input or undefined if the prompt is cancelled alert $alert(message) Shows a modal alert message dialog $dialog({title, message, inputs, buttons, options}) Shows a model dialog with title and message. The inputs and buttons arrays denote which input fields and buttons are shown. The result of the call is defined as follows. If the dialog is closed, the result is undefined. If a button is pressed, the result is the button id or - if the button is an object with label and type: submit - an object with the inputs. Finally, if options is set to an object with alert: info / warning / error, the dialog message is shows with the respective label. notify $notify(message) Shows the message at the bottom of the screen refresh $refresh() refreshes the screen just (just like hitting the refresh icon in the toolbar) reload $reload() reloads the browser page log $log(value) logs value to the developer console navigate $navigate(url) points the browser to the URL navigate $navigate( {id, options} ) scrolls the page to the DOM element with the id clearCache $clearCache() clears the HTTP cache - can be used in conjunction with expressions that trigger side effects on the backend progress $progress({message?, linear?, value?, variant?}) Shows progress message during long running operations. If the variant is set to determinate, the progress shows the value between 0 and 100. If linear is true, the progress is shown using a linear bar. sleep $sleep(millisecs) Sleep for x milliseconds speak $speak(message, language?) Text to speech stopSpeech $stopSpeech() Stop any text to speech that is still in progress translate $translate(text) Lookup the text in the translation file and return the match for the current locale"},{"location":"developer-reference/#backend-expressions","title":"Backend Expressions","text":"Function Syntax Returns create $create(database, table, object) ID of the new record upsert $upsert(database, table, object) first tries to create the record, if the record already exists, applies an update by retrieving the keys from the object and calling update all $all(database, table) array of all table records all $all(database, table, offset, limit, sort, descending, filter) array of all table records whose columns match the filter key's values read $read(database, table, pk1) The record traverse $traverse(database, table, pk1, fk) Record(s) related to the current record via the property fk. If fk is a simple column name, fk is an outgoing foreign key and the single related record is returned. If fk is a full property ID like dj/database/table/column, then a list of records from that table that have a fk pointing to the current record are returned update $update(database, table, pk1, object) delete $delete(database, table, pk1) call $call(function, argument) Dashjoin function result query $query(database, queryId, arguments) Query result table queryGraph $queryGraph(database, queryId, arguments) Graph query result, specifying the database as * runs an OpenCypher query over all DBs adHocQuery $adHocQuery(database, query, limit?) Runs as ad hoc select / read query search $search(term, limit?, database?, table?) Searches the databases(s) incoming $incoming(database, table, pk1) [{id: ID of the record where the link originates, pk: ID of the pk column, fk: ID of the fk column}, ...] echo $echo(any) Prints the parameter to the log index $index() Generates a unique row index ID djVersion $djVersion() Returns the platform version information djRoles $djRoles() Returns the roles of the current user djUser $djUser() Returns the current user's name isRecursiveTrigger $isRecursiveTrigger() true if the current expression is called from a trigger expression (trigger calls trigger) moveField $moveField(object, 'from', 'to') Moves the object's from key into the to key, where to must be an object or array ls $ls(url, preview-limit) Lists all URLs found at url (the URL can also contain filter wildcards like *.txt). preview limit determines how many results are returned in preview mode (defaults to 10) streamJson $streamJson(url, jsonPointer) Parses JSON at the url and splits it at the json pointer location streamXml $streamXml(url, jsonPointer) Parses XML at the url, converts it to JSON, and splits it at the json pointer location streamCsv $streamCsv(url, options) Parses CSV at the url and splits it at the record boundaries. By default, CSV is parsed as RFC4180. Options can be provided, where the key is a \"with\" method like withDelimiter and the value is the argument. Please see the documentation for more details. streamDb $streamDb(database, table) Streams records from the database table specified curl $curl(method, url, data?, headers?) Full fledged HTTP client. Use header {\"Authorization\": credential} to reference a credential set defined in functions. Use header {\"dj-timeout-seconds\": ...} to define a HTTP timeout. Use header {\"dj-encoding\": ...} to encode in UTF_8 (default), BASE_64, ISO_8859_1. Use header {\"dj-produces\": \"text/plain\"} to return plain text rather than JSON. Use header {\"Content-Type\": \"multipart/form-data\"} to upload files encoded in data URLs in the data object (see Input widget) openJson $openJson(url) Parses JSON at the url openCsv $openCsv(url, options) Parses CSV at the url and converts it to JSON. By default, CSV is parsed as RFC4180. Options can be provided, where the key is a \"with\" method like withDelimiter and the value is the argument. Please see the documentation for more details. openXml $openXml(url, arrays) Parses XML at the url and converts it to JSON. In this process, openXml guesses which XML tags need to be converted to arrays and which become simple fields. This process might produce inconsistent results when the XML tree contains lists with single entries. To avoid this, you can optionally pass a list of tag names that must be arrays. openYaml $openYaml(url) Parses YAML at the url and converts it to JSON openExcel $openExcel(url) Parses Excel at the url and converts it to JSON generateExcel $generateExcel(table or map of sheetname to table) Generates a base64 encoded Excel file which can be downloaded from the browser (see FAQ) generateYaml $generateYaml(data) Converts data to a YAML string generateXml $generateXml(data) Converts data to an XML string generateCsv $generateCsv(data, options) Converts a table to CSV (for options see openCsv) openText $openText(url, encoding) Parses the url and converts it to a string. Possible encodings are: UTF_8 (default), BASE_64, ISO_8859_1 parseJson $parseJson(json) Parses JSON (see openJson) parseCsv $parseCsv(csv, options) Parses CSV and converts it to JSON (see openCsv) parseHtml $parseHtml(html, query, xpath/css?) Parses HTML and selects nodes via CSS or XPath (see https://jsoup.org/cookbook/extracting-data/xpath-syntax) parseXml $parseXml(xml, arrays) Parses XML at converts it to JSON (see openXml) parseYaml $parseYaml(yaml) Parses YAML and converts it to JSON (see openYaml) parseExcel $parseExcel(base64) Parses Excel and converts it to JSON (see openExcel). The parameter must be a base64 encoded data URL (RFC 2397) parseUrl $parseUrl(url) Parses a URL into protocol, host, port, path, query, etc. uuid $uuid() Generates a random UUID exec $exec(executable, arguments, [json, xml, csv, yaml]) runs the script or executable located in the app's bin folder and optionally parses the output to JSON, XML, or CSV erDiagram $erDiagram(database?) Generate an ER diagram for https://dbdiagram.io/d stats $stats(database, table, limit?) Generate statistics for a database table (type, min, max, count, distinct values, etc.) gitStatus $gitStatus() Run git status gitPull $gitPull() Run git pull gitRestore $gitRestore(path) Revert a change gitCommit $gitCommit(message, [paths]) Run git commit and push gitClone $gitClone(url) Run git clone url - only available in the DJ playground saveTable $saveTable(Ignore Refresh reconcileEntity $reconcileEntity(entity, entity-language?, limit?) Uses the wikidata query service to reconcile a string to a wikidata id. The entity is a simple string. The entity language is the language the entity is expressed in (defaults to en). The limit (default 1) determines the number of results returned (see chapter AI &amp; ML) classifyEntities $classifyEntities([entities], entity-language?, limit?, subclass-depth?) Reconciles entities and finds common classifications that all entities are an instance of. The parameters are similar to the reconcileEntity function. The subclass depth (default 1) describes the number of superclasses that are included in the results (see chapter AI &amp; ML) synonym $synonym({algorithm: threshold}, [terms], [variants], ignoreCase?, ignoreEquality?) Allows generating synonym table to match keys despite small typos etc. (see chapter AI &amp; ML) urlExists $urlExists(url) Returns true if the url is reachable, false otherwise wait $wait(object, millisecs) Wait millisecs provided before returning object etl $etl(foreach, expression, database) Run an ETL process programmatically etlSync $etlSync(source, target, url column) Compute the files changed since the last run"},{"location":"development-production/","title":"Development / Production","text":"<p>If you use a Dashjoin system in production, we do not recommend making configuration changes like defining new queries or registering new user roles using the editors on the production system. Instead, you can setup multiple development systems where these changes are developed and tested.</p>"},{"location":"development-production/#dashjoin-studio","title":"Dashjoin Studio","text":"<p>The most convenient way to setup a development system is by using the Dashjoin Studio container. This container includes all the required tools and setup. To start the container, run:</p> <pre><code>docker run -p 3000:3000 -p 8080:8080 -p 8081:8081 -e DJ_ADMIN_PASS=djdjdj dashjoin/studio\n</code></pre> <p>If you would like to work on an existing app that is located on a Git repository, also specify the DASHJOIN_HOME and DASHJOIN_APPURL parameters (see section automatic Git checkout below)</p> <pre><code>docker run -p 3000:3000 -p 8080:8080 -p 8081:8081 -e DJ_ADMIN_PASS=djdjdj -e DASHJOIN_HOME=dashjoin-demo -e DASHJOIN_APPURL=https://github.com/dashjoin/dashjoin-demo dashjoin/studio\n</code></pre> <p>Dashjoin Studio works like the platform container, but offers two additional services. On port 8081, it allows connecting a browser based integrated development environment to the container. On port 3000 an additional web service provides access to the user interface that includes custom widgets you add to the app.</p> <p>To open Dashjoin Studio, navigate to the general information page and follow the Dashjoin Studio link under \"App\". To log in, please use the password you specified for the admin user (djdjdj in our examples). This opens VS Code in your browser. For more information about VS Code, please refer to this documentation.</p> <p>The project that is open in VS Code represents the app you are writing. Adding a query in the query catalog, for example, will create a JSON file in model/dj-query-catalog. If you change the file in VS Code, the change will be visible immediately in the query catalog as well.</p>"},{"location":"development-production/#app-folder-structure","title":"App Folder Structure","text":"<p>The contains the following folders:</p> <ul> <li>assets: any media that should be available via http(s):///assets. To customize the favicon, for instance, add your favicon to assets/public_html/favicon.ico. <li>model</li> <li>dj-config: Contains any system configuration</li> <li>dj-database: All connected databases and any table and record page layouts. If a database JSON file is open in the editor, you can test connecting to it via the \"Connect to this database\" button at the top of the file</li> <li>dj-function: All functions defined on the functions page. Also offers the ability to \"Run this function\". Note that passing parameters to the function is not supported. You can use the JSONata notebook for this.</li> <li>dj-query-catalog: All queries in the catalog. Offers the \"Run this query\" and \"Run this query metadata\" commands. Note that passing query parameters is not supported. You can use the JSONata notebook for this.</li> <li>dj-role: All roles defined in the system</li> <li>page: All app dashboard pages. Offers the \"Open this page in the browser\" button.</li> <li>tenantusers: All tenant users</li> <li>widget: Custom toolbar and sidebar are located here</li> <li>upload: this folder can contain files that can be accessed from JSONata functions like openJson(\"file:upload/...\")</li>"},{"location":"development-production/#source-control","title":"Source Control","text":"<p>If you would like to commit and publish your changes to the production system, you can switch to the source control tab on the left. The usual workflow is to:</p> <ul> <li>review your changes in the diff editor</li> <li>stage your change by adding the file via the + icon</li> <li>entering a message describing your change and committing the change</li> <li>publishing your change to the remote Git repository</li> </ul> <p>For more details, please refer to this guide.</p>"},{"location":"development-production/#developing-a-custom-widget","title":"Developing a Custom Widget","text":"<p>One of the most powerful features of Dashjoin Studio is the ability to write your own widgets. Let's assume we have a database containing chemical molecules. One of the columns contains the SMILES string. We're going to write a widget, that draws a 2D representation of the molecule based off this information.</p>"},{"location":"development-production/#adding-a-3rd-party-library","title":"Adding a 3rd Party Library","text":"<p>The first step is to find a 3rd party library that is suitable for the task. The Dashjoin UI is written in React, therefore, keep this in mind when selecting a library. For this example, we'll use smilesDrawer.</p> <p>In VS Code, open a terminal (on the top left, click the menu, then terminal, and finally new terminal. When prompted where to open the terminal, please select \"Dashjoin Platform UI\") and enter:</p> <pre><code>yarn add smiles-drawer\n</code></pre> <p>Yarn is a JavaScript package manager, that will retrieve the latest version of the library and all other required components. Depending on your internet connection speed, this command might take a while to complete. Now we can start the development webserver that will run on port 3000:</p> <pre><code>yarn rsbuild dev\n</code></pre>"},{"location":"development-production/#adding-a-new-widget","title":"Adding a new Widget","text":"<p>Adding a new widget requires three changes: First, create the file Smiles.tsx in src/widgets:</p> <pre><code>import { Icon } from \"@mui/material\"\nimport { Widget } from \"../model/widget\"\nimport { text, title } from \"../api/Const\"\nimport { useEffect, useRef } from \"react\"\nconst SmilesDrawer = require('smiles-drawer')\n\nexport const Smiles = ({ widget }: { widget: Widget }) =&gt; {\n\n    const imgRef = useRef&lt;HTMLImageElement&gt;(null);\n    const drawer = new SmilesDrawer.SmiDrawer();\n\n    useEffect(() =&gt; {\n        drawer.draw(widget.text ? widget.text : 'C', imgRef.current, 'light');\n    });\n\n    return (\n        &lt;div&gt;\n            &lt;img ref={imgRef} width={300}&gt;&lt;/img&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport const config = {\n    id: 'smiles',\n    title: 'Smiles',\n    description: 'Renders a SMILES string as a 3D molecule',\n    version: 1,\n    icon: &lt;Icon&gt;science&lt;/Icon&gt;,\n    controls: {\n        type: 'autoform',\n        schema: {\n            properties: {\n                title: title,\n                text: text\n            }\n        }\n    }\n}\n</code></pre> <p>This code contains two blocks. The first block is the actual widget. It gets the parameter \"widget\", which is a JSON structure to configure the widget. The rest of the code is taken from the  library's documentation. The key point is in line 13, where widget.text is passed as the parameter to the draw function. This parameter contains the SMILES string passed to the widget.</p> <p>The second part defines how the widget edit dialog looks like. It contains an icon, some description, and a list of controls. In this case, we allow editing the widget title (this is a property shared by all widgets) and the text to contain the SMILES string. You could add other properties. For instance, the width of the generated image is fixed at 300 pixels. This could be replaced with a widget parameter.</p> <p>The demo application contains a version of this widget that computes the SMILES string via JSONata. It uses the \"useExpression\" React hook. This allows reading SMILES data from a DB or a RESTful web service.</p> <p>Now edit the file CustomWidgets.tsx in src and add the following lines:</p> <pre><code>import { config } from \"./widgets/Smiles\";\nimport { Smiles } from \"./widgets/Smiles\";\n\nexport const customWidgets = [\n    {\n        widget: Smiles,\n        config: config\n    }\n]\n</code></pre> <p>Custom widgets is an array. Therefore, you can add other custom widgets as well. Now we're all set. We can create a test page and add the widget with the following parameters in order to see the molecule in all its glory:</p> <pre><code>{\n    \"widget\": \"smiles\",\n    \"title\": \"Glucose\",\n    \"text\": \"OC[C@@H](O1)[C@@H](O)[C@H](O)[C@@H](O)[C@H](O)1\"\n}\n</code></pre> <p>An example is available in the demo app as well.</p>"},{"location":"development-production/#packaging-the-widget-and-deploying-it-to-production","title":"Packaging the Widget and Deploying it to Production","text":"<p>Once you are done with your widget development, you can start the build process via the terminal and deploy the result to your app: <pre><code>yarn build\nyarn deploy\n</code></pre></p> <p>This command will create a folder with the compiled user interface in the folder of your app. You can commit these assets along with the query catalog and the other files in your app. You can view an example in the demo app. If the app is deployed onto a production system, the user interface containing the new widget will be active.</p> <p>Note that this process must be repeated when the platform is updated to a newer version.</p>"},{"location":"development-production/#making-changes-to-the-platform","title":"Making Changes to the Platform","text":"<p>Dashjoin Studio gives you full access to the entire user interface.  Therefore, you can not only add widgets, but also make changes to the core UI. For instance, you can make changes to the login screen or the legal cookie and data privacy disclaimer presented to new users.</p> <p>Any of these changes are picked up by the build and deploy process described in the previous section. Please note however, that changes to the core platform must be re-applied manually once a new version of Dashjoin is released.</p>"},{"location":"development-production/#multi-line-json","title":"Multi Line JSON","text":"<p>Markdown, queries, and JSONata expressions can be hard to read if they are stored in JSON files. You can externalize strings in separate text files which are linked from the JSON data as follows:</p> <p>test.json:</p> <pre><code>{\n  \"ID\": \"test\",\n  \"query-pointer\": \"0.sql\"\n}\n</code></pre> <p>test.0.sql:</p> <pre><code>select * from test\n  where id=4\n</code></pre> <p>These two files are equivalent to:</p> <p>test.json:</p> <pre><code>{\n  \"ID\": \"test\",\n  \"query\": \"select * from test\\n  where id=4\"\n}\n</code></pre> <p>You can use this mechanism anytime when you're editing the files manually. When making changes via the platform, by default, only the query strings of the query catalog are externalized.</p> <p>This is controlled by the \"externalize-config-strings\" setting. If you'd like to also externalize widget markdown for instance, simply add \"page: markdown\" to \"externalize-config-strings\". This specifies the table and the (possibly nested) key containing the string to be externalized.</p> <p>On the production system, there are three ways of deploying an application:</p>"},{"location":"development-production/#upload-to-the-configuration-database","title":"Upload to the Configuration Database","text":"<p>You can upload an entire model folder to the config DB. On the database page, select \"Configuration Database\". Open the \"Database Management\" tab and select \"Upload\". Select the model folder there and either append or replace the contents of the config database.</p>"},{"location":"development-production/#automatic-git-checkout","title":"Automatic Git Checkout","text":"<p>You can specify the DASHJOIN_APPURL environment variable and have it point to your app repository. Upon startup, the system will perform a git clone if the model folder is empty or a git pull if the model has content already. Note that you can specify credentials via the URL (http://user:password@domain.com/). Please refer to the demo application for an example of how to run Dashjoin with the demo application installed. If the git operation fails (e.g. due to incorrect credentials or illegal filenames), the platform will log the error and resume the startup process.</p>"},{"location":"development-production/#private-github-repositories","title":"Private GitHub Repositories","text":"<p>If you would like to launch an App that is stored in a private GitHub repository, you can use a personal access token. You can assign the right to clone the repository to the token and add it to the DASHJOIN_APPURL as follows:</p> <pre><code>https://user:token@github.com/org/project\n</code></pre>"},{"location":"development-production/#manual-app-installation","title":"Manual App Installation","text":"<p>Last but not least, you can also copy the app into the Dashoin working directory using other means before starting the platform.  If you are using containers, you can mount the model folder under /deployments/model.</p>"},{"location":"development-production/#specifying-development-resources","title":"Specifying Development Resources","text":"<p>Resources like databases and REST endpoints are critical resources when working with Dashjoin. Therefore, it is quite common to use different sets of resources for development and production. As described in the section on automatic Git checkout above, the production credentials are usually checked into the code repository. During development, you can use environment variables to specify alternative values for url, username, hostname, port, database, and password to be used for functions and databases as follows:</p> <ul> <li>dashjoin.database.NAME OF THE DATABSE.url: URL to use to connect to the database (overrides the url field in the DB's json file)</li> <li>dashjoin.function.NAME OF THE FUNCTION.url: URL to use to connect to the REST service (overrides the url field in the function's json file)</li> </ul> <p>To change the username / password, simply replace url with username / password in the examples above. Note that the development passwords are provided in plain text.</p>"},{"location":"development-production/#unit-testing","title":"Unit Testing","text":"<p>Unit tests are an important asset to ensure the quality of your app. Dashjoin leverages the JUnit framework and allows you to perform the following default tests to make sure that</p> <ul> <li>all JSON files can be parsed</li> <li>layout uses legal widget names</li> <li>all JSONata expressions are syntactically correct</li> </ul> <p>In addition to these syntactical checks, it is possible to run JSONata expressions and provide desired outputs. </p> <p>To setup unit tests in your app, follow these steps:</p> <ul> <li>Open Dashjoin Studio</li> <li>Copy this maven project file to your app's root directory</li> <li>Copy this JUnit test file to \"src/test/java/org/dashjoin/app\"</li> <li>If you would like to test a JSONata expression, create a JSON test file that describes the file containing the expression, where the expression is located, which test cases should be run, and which outputs are to be expected. The file is structured as follows:</li> </ul> <pre><code>{\n    \"test\": {\n        \"file\": path to the file containing the expression to be checked\n        \"expression\": JSONata expression that selects the expression to be checked\n    },\n    \"basedata\": optional common test data for the test cases\n    \"cases\": {\n        \"name\": {\n            \"data\": test data (will be merged with the base data)\n            \"expected\": expected JSONata output\n        }\n        ...\n    }\n}\n</code></pre> <p>To run the unit test:</p> <ul> <li>Via the VS Code extensions tab, install the Debugger for Java and the Test Runner for Java plugins</li> <li>Press run in the new JUnit tab to run all the tests</li> </ul>"},{"location":"faq/","title":"FAQ","text":"<ul> <li> <p>How can I edit a fullscreen page? Usually, you toggle the edit mode via the widget in the toolbar. If you are viewing a page in full mode (under the URL /#/full/Pagename), this element in the toolbar is not available. Simply view the page in normal mode (under /#/page/Pagename), and enter edit mode there.</p> </li> <li> <p>The Dashjoin Demo Application contains some interesting examples. How can I apply them to my application? You can either locate your application on the file system and copy an example page there or you can look at the page in order to see which settings to add in the layout editor dialogs (e.g. a JSONata expression).</p> </li> <li> <p>I have an object with special characters in the field names (e.g. a SQL query result). How can I access this field in JSONata? In JSONata, field names can be escaped using back-ticks (`). Click here for a live example.</p> </li> <li> <p>How can I dynamically customize the forms in the edit, button and variable widgets? In Dashjoin Studio, you have the option to compute the schema you would normally define statically in the layout via the schemaExpression widget field.</p> </li> <li> <p>Can I show a form field conditionally? Yes, using the schemaExpression mechanism described above, you can create a schema that contains the switch and case keywords as follows:</p> </li> </ul> <pre><code>{\n    \"widget\": \"button\",\n    \"print\": \"form\",\n    \"schemaExpression\": \"{'switch':'type', 'properties': {'type': {'widget': 'select', 'options':'[\\\"circle\\\"]'}, 'radius': {'case': 'circle'}}}\"\n}\n</code></pre> <p>For readability, here is the pretty-printed versino of the schemaExpression:</p> <pre><code>{\n  \"switch\": \"type\",\n  \"properties\": {\n    \"type\": {\n      \"widget\": \"select\",\n      \"options\": \"[\\\"circle\\\"]\"\n    },\n    \"radius\": {\n      \"case\": \"circle\"\n    }\n  }\n}\n</code></pre> <ul> <li>How can I use values from the database in the edit, button and variable widgets? This can be achieved by specifying an expression to compute the options array. The expression can evaluate to a simple array, or an array of objects containing the value (option value in the form) and name (UI option name) keys. </li> </ul> <pre><code>{\n    \"widget\": \"button\",\n    \"print\": \"form.field\",\n    \"schema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"field\": {\n                \"widget\": \"select\",\n                \"options\": \"$all('northwind', 'EMPLOYEES').{'value':EMPLOYEE_ID, 'name': LAST_NAME}\"\n            }\n        }\n    }\n}\n</code></pre> <ul> <li> <p>Are SQL stored procedures supported? Yes, simply use 'exec proc' or 'call proc(par)' as the query, depending on the SQL dialect used by your DB. In case a stored procedure has multiple result tables, the $query function returns them by wrapping them in a top level object.</p> </li> <li> <p>How can I access a SQL Server stored procedure output variable? This can be done on the query level as follows:</p> </li> </ul> <pre><code>DECLARE @res INT;\nexec dbo.sp @res output;\nselect @res;\n</code></pre> <ul> <li> <p>Why am I getting the error: \"User does not have the role required to read table page in database config\" after logging in? When the UI renders a page, it needs to get the page layout from the backend. Like with any other call, the user's credentials are checked. This error indicates, that the user is known to the system, but gets assigned insufficient roles to access this information in the config DB. To fix this, you can either assign the user the correct role in the IDM or you can provide read access to the config DB to the user's role (this is done on the System Configuration page).</p> </li> <li> <p>Does the platform cache results? Yes, all HTTP GET requests are cached by the browser UI. The cache is purged if 1) five minutes have passed since the last time the data was retrieved, 2) the data is changed in via the UI (e.g. by saving / updating a value), or 3) F5 / reload is pressed.</p> </li> <li> <p>How can I download data from the platform? The download happens via a JavaScript function that calls saveAs(new Blob([data]), filename). This snippet can be added as a client side expression with the // JavaScript marker:</p> </li> </ul> <pre><code>// JavaScript\nvar blob = new Blob([\"Hello, world!\"], {type: \"text/plain;charset=utf-8\"});\nsaveAs(blob, \"hello world.txt\");\n</code></pre> <p>Alternatively, the script can also be added to the HTML widget. And example can be found here.  </p> <ul> <li>How can I download binary data such as PDFs or images? This works like the regular download. You usually have a JSONata expression that loads the data in the backend. You can use $openText(url, \"BASE_64\") or $generateExcel(...) to get a base64 encoded representation. This example download a small XLS. You can test this from the Notebook.</li> </ul> <pre><code>// Javascript\nconst byteCharacters = atob(await generateExcel([{'x':1}]));\nconst byteNumbers = new Array(byteCharacters.length);\nfor (let i = 0; i &lt; byteCharacters.length; i++) {\n  byteNumbers[i] = byteCharacters.charCodeAt(i);\n}\nconst byteArray = new Uint8Array(byteNumbers);\nconst blob = new Blob([byteArray], {type: \"application/vnd.ms-excel\"});\nsaveAs(blob, 'download.xlsx')\n</code></pre> <ul> <li> <p>On the table page, my primary key column is not on the very left and I need to scroll right to get to the instance page link. How can I change this? The default layout uses the native column order defined in the database. This order is used for the overview table as well as for the forms on the instance pages. For the table, simply define a query with your desired column projection order. Note that you can also omit columns if you'd like. Enter the layout editor and use this query for the table widget. On the edit form, you can enter the layout editor and change the positioning there.</p> </li> <li> <p>How can I format dates or currency in tables? This can be done on the database query level. If you're using PostgreSQL for instance, this query will format the \"born\" and \"salary\" columns accordingly (assuming their database type is date and int): select to_char(born, 'DD-MON-YYYY'), cast(salary as money) from employee.</p> </li> <li> <p>Why does the browser not show changes performed via an expression called from a button? You need to include the clearCache function if your expression makes changes to the database. Otherwise, old values might be shown for five minutes.</p> </li> <li> <p>The display widget shows an object as a material list. Can I transpose the object such that it is displayed as a two column table with colums key and value? This can be done using the following JSONata transformation. For each object key, we create an object where key is the current key and value is the key lookup. This array of objects is then shown as a table.</p> </li> </ul> <pre><code>value.(\n    $x := $;\n    $keys($).{\"key\": $, \"value\": $lookup($x, $)}\n)\n</code></pre> <ul> <li>How can I determine whether it makes sense to define a foreign key on a given column? In some data integration scenarios, it may not be clear whether a column is a good candidate to reference a primary key. Some keys might match, others won't. You can use the following piece of JSONata code to determine to which degree the values intersect. We first get the table data and project the column. The intersection is computed using a JSONata filter which only includes the values in the other array.</li> </ul> <pre><code>(\n  $t1 := $all(\"db1\", \"table1\").column1;\n  $t2 := $all(\"db2\", \"table2\").column2;\n  {\n    \"count1\": $count($t1),\n    \"count2\": $count($t2),\n    \"intersect\": $count($t2[$ in $t1])\n  }\n)\n</code></pre> <ul> <li> <p>Can I trigger a git pull of the App in production without a restart? You can run $gitPull() as a function or on the Dashjoin Notebook.</p> </li> <li> <p>Can I call the OpenAI APIs from Dashjoin? Yes, register the following function (replace your API key accordingly) can call it:</p> </li> </ul> <pre><code>{\n    \"djClassName\": \"org.dashjoin.function.RestJson\",\n    \"ID\": \"openai\",\n    \"type\": \"read\",\n    \"method\": \"POST\",\n    \"contentType\": \"application/json\",\n    \"headers\": {\n        \"Authorization\": \"Bearer YOUR-API-KEY-HERE\"\n    },\n    \"url\": \"https://api.openai.com/v1/chat/completions\"\n}\n</code></pre> <pre><code>$call(\"openai\", {\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n  \"temperature\": 0.7\n})\n</code></pre> <ul> <li>I have a table with a unique column which is not the primary key, can I ETL into this table from a datasource which only contains this key and not the primary key? Yes, you can lookup a record using the $all function. Let's consider the following example from the northwind database, where employee names are given with an email address, but not the employee ID. We can use the $all function to retrieve the record by last name and project the id which is then merged into the original record. Note that this runs one query per row. Alternatively, you can create a lookup table (unique2key), store it in a variable, and use $lookup to get the primary key to merge.</li> </ul> <pre><code>[{\"id\": \"Davolio\", \"email\": \"davolio@example.org\"}, {\"id\": \"Fuller\", \"email\": \"fuller@acme.org\"}]\n  .$merge([\n    $, \n    {\"EMPLOYEE_ID\": $all(\"northwind\", \"EMPLOYEES\", null, null, null, false, {\"LAST_NAME\": id}).EMPLOYEE_ID}\n  ])\n</code></pre> <pre><code>(\n  $input := [{\"id\": \"Davolio\", \"email\": \"davolio@example.org\"}, {\"id\": \"Fuller\", \"email\": \"fuller@acme.org\"}];\n  $unique2key := $all(\"northwind\", \"EMPLOYEES\").{LAST_NAME: EMPLOYEE_ID};\n  $input.$merge([$, {\"EMPLOYEE_ID\": $lookup($unique2key, $.id)}])\n)\n</code></pre> <ul> <li> <p>I need to ETL from an API that has a rate limit. How can I throttle my requests? You can use the wait function in your JSONata expression: Let's assume $openJson(url) is called on several array elements. Simply change it to $wait($openJson(x), 1000) to introduce a 1 second delay after each call.</p> </li> <li> <p>How can I realize an audit log that keeps track of all changes to a table? You can define a triggers for create, update, and delete operations on the table that must be audited. Create an audit log table with the following columns: autoincrementing ID, user, timestamp, operation, and payload. The trigger <code>$create(\"db\", \"audit\", {\"timestamp\": $now(), \"user\": user, \"operation\": \"update\", \"payload\": $})</code> will log changes to the table.</p> </li> <li> <p>Can I compute the homepage based who is logged in? Yes, you can use the on-login expression and do some computation based on the email and user context values. The result can be fed into the setVariable function: <code>$setVariable(\"homepage\", some computation using user or email)</code></p> </li> <li> <p>Can I initialize a SQL database with schema and data? Yes, in Dashjoin Studio, you can add SQL scripts to your database:</p> </li> </ul> <pre><code>{\n    \"ID\": ...,\n    \"djClassName\": \"org.dashjoin.service.SQLDatabase\",\n    \"initScripts\": [\n        \"upload/init.sql\",\n    ],\n    ...\n</code></pre> <p>These scripts are run when the database is connected. To setup a DB schema, you can use:</p> <pre><code>CREATE TABLE IF NOT EXISTS MY_TABLE(ID INT PRIMARY KEY, ...)\n</code></pre> <p>Of course you can also use SQL insert statements to load data.  Furthermore, the H2 database (select it using the JDBC URL jdbc:h2:mem:...) offers a CSVREAD function. This way, you can present static data to the user via SQL while being able to have a CSV version of the data as part of the app.</p> <pre><code>DROP TABLE IF EXISTS TEST;\nCREATE TABLE TEST (ID INT PRIMARY KEY, NAME VARCHAR(255)) AS SELECT * FROM CSVREAD('dashjoin-demo/upload/test.csv');\n</code></pre> <p>Note that the CSVREAD function uses the working directory and not the app home directory. Therefore, we also append the app name, \"dashjoin-demo\" in this example.</p> <ul> <li>Can I define a JSON database column to be an array of foreign keys? Yes, using Dashjoin Studio, you can define the column metadata as follows:</li> </ul> <pre><code>\"ID\": \"dj/pg\",\n...\n\"tables\": {\n    \"test\": {\n        \"properties\": {\n            \"arr\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"ref\": \"dj/northwind/CUSTOMERS/CUSTOMER_ID\",\n                    \"type\": \"string\",\n                    \"displayWith\": \"fk\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>Using the following create table statement and insert JSONata statement, the record in the test table shows links to the customer table.</p> <pre><code>create table test (id int primary key, arr jsonb)\n$create(\"pg\", \"test\", {\"id\":1, \"arr\": ['BLAUS', 'ALFKI']})\n</code></pre> <ul> <li>On a page, can I programmatically scroll to a certain widget? Yes, you can use a JavaScript expression to do this. All widgets that specify a title, get the DOM id \"dj-\" + widget.title. Note that you can also use spaces as the title in case you do not want to display a widget title. The following expression makes sure the widget is in view:</li> </ul> <pre><code>// JavaScript\ndocument.getElementById('dj-mytitle')?.scrollIntoView( &lt;options&gt; ))\n</code></pre> <p>Make sure to use the question mark to avoid runtime errors if the DOM node is not (yet) present. If you want to use this expression in the onRender handler (i.e. to auto scroll to the widget when the page loads), you need to add a timer that makes sure the page is fully loaded and all DOM nodes are there. Add the timer (e.g. 1 second) by wrapping the call in setTimer(()=&gt;document..., 1000).</p> <p>You can control the behavior using options, please refer to the documentation here.</p> <p>In (client side) Jsonata expressions you can use <pre><code>$navigate( {\n  \"id\": \"dj-mytitle\",\n  \"options\": { &lt;scrollIntoView options&gt; } \n);\n</code></pre></p> <p>Options can be left out, the default is the browser default behavior.</p>"},{"location":"getting-started/","title":"Getting Started: 15 Minute Tour","text":"<p>This section will guide you through the various features of the Dashjoin low code development platform. We assume you are in the admin role and have the demo application installed. This application bootstraps a sample northwind database which allows us to demonstrate advanced queries.</p> <p>We will guide you through a scenario where northwind is an internal fictional enterprise resource planning (ERP) system. You a being tasked with developing an application that allows customers to interface with you via a web portal.</p>"},{"location":"getting-started/#database-management","title":"Database Management","text":"<p>To get to the data management page, click on the gear symbol in the toolbar. The table shows the databases that are available to the system so far. You should see the northwind database there.</p> <p>Since northwind is a non-persistent in memory database, we will create a new database. This can be done with the create widget on the page. Select the following values and press \"create\":</p> <pre><code>type: SQLDatabase\nname: sqlite\nurl:  jdbc:sqlite:your_database.db\n</code></pre> <p>From the database page, click on the sqlite database you just created. This brings you to the database details page. The connection information section allows you to make changes to the connection. Note that you can also simply click update in order to recollect the database metadata in case the schema was changed using another application.</p> <p>If you are in the admin role, you can expand the database management section. Using the form, create a table called \"REQUESTS\". This operation creates the table with two columns: ID is the numeric primary key and name is a string column describing the record.</p> <p>Go to the table by following the REQUESTS link in the database management table. On the page you can start entering some test data. Note that the SQL database enforces the uniqueness constraint on the ID column. If you try to create a record with an existing ID, you will get an error message: [SQLITE_CONSTRAINT] Abort due to constraint violation (UNIQUE constraint failed: <code>REQUESTS.ID</code>). By inspecting the created table, the system also automatically picks up the datatypes of the columns and requires you to provide an ID.</p> <p>Open the column metadata control and add three more columns:</p> <ul> <li>submitted: date</li> <li>customer: string</li> <li>user: string</li> </ul> <p>We can enter, edit and delete records via the user interface. Another option is to upload data. To do this, create a file called REQUESTS.csv (note that the file name must match the case sensitive table name):</p> <pre><code>ID,name,submitted,customer,user\n1,Can you please send me an offer,2021-01-01 10:20,ALFKI,user\n2,Delivery arrived,2021-01-01 10:20,ALFKI,user\n3,Delivery delayed,2021-01-07 11:32,ALFKI,user\n4,Are you out of crackers,2021-01-04 08:21,BLAUS,other\n5,Need more crackers,2021-11-06 05:20,,admin\n</code></pre> <p>To upload this file, navigate back to the sqlite database page, expand the database management control and select \"Upload Data\". In the dialog, select \"choose files\" and select the file REQUESTS.csv you just created. This brings up a table with a preview (the first 10 rows) of the table. Since the requests table already exists, you cannot select a primary key or the column data type. These options are available if the target table does not yet exist in the database.</p> <p>You have the choice of appending to or replacing the existing data. Choose \"replace\" in order to avoid further primary key clashes. Since we are permanently deleting existing data, we need to confirm this operation by entering \"delete tables\". Note that tables is plural since we can also upload multiple tables at once by selecting a Excel spreadsheet or multiple csv files.</p> <p>Since our application should not change the northwind ERP database, we created the new table in a new database. Nevertheless, there is a logical connection between the two databases, since the customer field in the requests table references the CUSTOMERS table in the northwind database. Dashjoin allows you to express this relationship even tough it links columns and records in different databases.</p> <p>Navigate to the REQUESTS table and open the column metadata control. In the table, select the customers column and click edit. In the popup, type \"CUSTOMER_ID\" in the foreign key reference field. The system suggests all known columns that contain this substring. Select \"dj/northwind/CUSTOMERS/CUSTOMER_ID\" and press ok. Since we made a change to the database metadata and the application caches this data, we need to clear the browser application cache by reloading the page.</p> <p>After the reload, you will notice that the customer column in the table now shows a hyperlink to the related record in the customer table. Likewise, if you navigate onto a request or onto a customer, the related records are displayed even though they reside in a different database. In addition, if you start typing in the request creation's customer field, you will notice that the matching northwind customer IDs are showing up.</p> <p>Navigate to the customer ALFKI (northwind/CUSTOMERS/ALFKI). The list of requests made by this customer shows up as a list of hyperlinks (1, 2, and 3). As a default, Dashjoin uses the primary key value as a link label, however we can customize this. Go to the REQUESTS table page, open the table metadata control and enter <code>${name}</code> in the dj-label field. This string is a template syntax where constant strings can be mixed with template variables referencing columns. So a person template could be <code>${LAST_NAME}, ${FIRST_NAME}</code>.</p> <p>Save this change and reload the browser. The visit the first request. You will notice that the browser window title now displays the new label. Going back to the requests table you will see that any request that was visited, now shows a nice name. Likewise, if you go back to customer ALFKI, the list also shows the readable link labels (assuming they all have been visited).</p> <p>Go back to the requests table and enter the letter 'a' in the customer field of the create form. You will see the autocomplete options with the customer IDs starting with 'a'. The customer IDs are five letter strings. This is better than a plain number, but let's also choose a display name for customers. Again, we can do this by navigating to the customer table (/northwind/CUSTOMERS), opening the table metadata control and entering the dj-label <code>${COMPANY_NAME}</code>. Reload the browser and go back to the requests table. If you type 'a' into the customers create field, you will see the list of customer display names that start with 'a'. Note that the tooltip shows the underlying five letter primary key. This feature is very useful if tables use unreadable keys.</p>"},{"location":"getting-started/#restricting-access","title":"Restricting Access","text":"<p>Dashjoin makes it very easy to secure data based on user roles. To view the roles known to the system, go to the info page linked in the toolbar. The top left widget display the following information:</p> <ul> <li>The name of the current user (should be user name 'admin')</li> <li>The roles the current user is in (should be the user role 'admin')</li> <li>A link to the role management page</li> </ul> <p>Follow the link to the roles page. On there, you can define new roles and define the home page for users in this role. In the system there are several places where you will be able to select the roles defined here. The role IDs you choose depend on the identity management system that is configured. In the Dashjoin PaaS, this is OpenID. If you are using the open source default installation, local users and their role associations are defined in the files djusers.properties and djroles.properties:</p> <p>You already have an admin user. To add a user \"authenticated\" with password djdjdj that is in the role with the same nave, edit the files as shown below:</p> <pre><code># djusers.properties\nadmin=1395a3149fee498061e6c06581a3decf\nauthenticated=4a699242c282b1180a24df1ff411001f\n</code></pre> <pre><code># djroles.properties\nadmin=admin\nauthenticated=authenticated\n</code></pre> <p>In the next step, use a different browser or an incognito window and login user user with password djdjdj. Except for the toolbar, the system looks pretty much the same. Navigate to the info page. You will need to type /page/Info into the browser, since the toolbar icon is not displayed. Verify that the page shows user in role authenticated. Click on \"system roles\" and \"admin\" and press delete. You will get the error message: \"User does not have the role required to delete table dj-role in database config\". The authenticated role has read access to the config database, but cannot create, delete or update any records.</p> <p>By default, new databases are only accessible for the admin. We can demonstrate this by searching for the term \"cracker\". In the admin browser, you get a total of seven results from both the northwind and sqlite databases.</p> <p>If you perform the same search in the user browser, you only get the five northwind results.</p> <p>The northwind database grants read only access to the authenticated role. You can check this on the page /config/dj-database/dj%2Fnorthwind.</p> <p>Now let's grant access to the sqlite database. Go to the page /config/dj-database/dj%2Fsqlite, select the authenticated role for both the read and write roles and save your change. Note that the admin role already has implicit access, therefore it is not listed in the options.</p> <p>Go back to the user browser and repeat the search. Now you'll get the same result as in the admin window. You can also navigate to a request and make a change since write access has been granted.</p>"},{"location":"getting-started/#user-layouts","title":"User Layouts","text":"<p>This section explains how we can customize the layouts and how we can display different user interfaces depending on which role the user is in.</p> <p>For our application, we'd like the users to have a page where they can see their past requests and where they can issue a new request. A request should only consist of the text. The fields ID, submitted and user should be determined by the system.</p> <p>We start with the admin browser and navigate to the \"dashboard pages\" via the toolbar. Using the \"Create a new page\" control, create a new page called \"Start\". We will use this as the homepage for authenticated users. This can be setup on the authenticated role page (config/dj-role/authenticated). Enter a new property  with the key \"homepage\" and the value \"/page/Start\" to specify the start page as the homepage for users in this role. We need to logout and back in using the user browser to pick up this setting. Clicking the home icon will now get you to the start page which at this point only shows a single tile with the text \"New page\".</p> <p>In order to create this page, we need to use the admin browser. Before we add widgets to this page, we need to create a query that filters the user's requests and that projects the request columns in a suitable way.</p> <p>This can be done using the query catalog and query editor. Navigate to the query catalog via the toolbar and in the create form, press the editor button. In the popup, select the sqlite database and the requests table. Using the dropdown, you can add the field user to the query. In the filter field, enter \"user\". Now we just need to hide the user column (select remove column from the column context menu) and drag &amp; drop the name column to the first position. The query should be:</p> <pre><code>SELECT\n  \"REQUESTS\".\"name\", \"REQUESTS\".\"submitted\"\nFROM\n  \"REQUESTS\"\nWHERE\n  REQUESTS.user = 'user'\n</code></pre> <p>Press OK to leave the query editor. Before creating the query, we need to add the ID (requests), type (read), and roles (admin, authenticated). The query needs one more argument, namely the current user. This can be specified by pressing the + symbol and adding the parameter user with type string and example \"user\". The example is used when editing a parameterized query in the editor. Finally, in the query text field, replace 'user' with <code>${user}</code>. This indicates that the query has a dynamic parameter that is inserted into the query before it is run. Now save the query by pressing \"create\". At a later point, you can always go back and make changes to the query (e.g. add a join or another projection).</p> <p>Now we navigate to the page start and enter the layout editor by pressing the pen symbol. We can now make changes to the page. The page contains one widget which currently is a text widget displaying a static text. You can delete this widget and instead add a table widget showing our query result.  After adding the table widget from the left drawer, enter the following widget proerties in the editor:</p> <pre><code>widget: table\nquery: requests\ndatabase: sqlite\ntitle: My Requests\narguments: {\"user\": $.user}\n</code></pre> <p>Press the floppy disk symbol to save the new layout. You should now see a table with one row. Go to the user browser and reload the page. You should see three requests there.</p> <p>We created a table widget that runs the requests query on the sqlite database. Now the requests query needs an argument called user. Dashjoin uses a JSON object to pass such parameters. Specifically, <code>$.user</code> reads the current username from the context. We will leave it at that, please refer to the developer guide for a full documentation of these expressions.</p> <p>Now we are missing the functionality to submit new data. We can achieve this with the button widget. Enter the edit mode again and add button widget with the following parameters:</p> <pre><code>widget: button\ntext: Submit\ntitle: New Requests\n</code></pre> <p>In the button widget, add an inout widget:</p> <pre><code>widget: inout\nname: name\n</code></pre> <p>Change the input to a textarea. If you'd like the tetarea to be wider, you can add width 400px in the CSS properties.</p> <p>Finally, let's edit the button widget again to define what happens when the button is pressed. Enter the following expression in the field \"run this when clicked and display the result\":</p> <pre><code>$create(\n  \"sqlite\", \n  \"REQUESTS\", \n  {\n    \"ID\": $ceil($random()*1000000), \n    \"user\": $.user, \n    \"name\": $.form.name, \n    \"submitted\": $now()\n  }\n)\n</code></pre> <p>Let's break down what is happening here. <code>$create</code> is a function which creates the record (3rd parameter) in the database (1st parameter) and the table (2nd parameter) specified. Database and table are static strings. The record consists of four dynamic fields:</p> <p>The ID is computed by taking a random number (between 0 and 1), multiplying it with 1 million and rounding it up. Thus the ID is a random number between 1 and 1 million, providing reasonable protection from duplicate IDs.</p> <p>The user is computed using the same construct (<code>$.user</code>) as for the table widget above.</p> <p>The name is specified as <code>$.form.name</code>. The rationale is the following: The user entries are stored in a JSON object form which hangs under the context $. In this object, we choose the name specified as the button argument.</p> <p>Finally, the submitted field is the current timestamp computed with <code>$now()</code>.</p> <p>After saving the layout, you can test the functionality. Note that you need to refresh the page after a value is submitted.</p>"},{"location":"getting-started/#admin-layout","title":"Admin Layout","text":"<p>The application administrator already has the ability to browse and search the data. However, it would be nice to add a chart to the system. To do this we first need to create another query.</p> <p>Follow the steps as before and project the columns user and name. Next, select the column user and group by this column. The resulting query should be:</p> <pre><code>SELECT\n  \"REQUESTS\".\"user\", COUNT(\"REQUESTS\".\"name\")\nFROM\n  \"REQUESTS\"\nGROUP BY\n   \"REQUESTS\".\"user\"\n</code></pre> <p>Save the query under the name \"requestsPerUser\". Next, navigate to the REQUESTS table and enter the layout editor. Add a widget to the page and choose these settings:</p> <pre><code>widget: chart\ntitle: Requests Per User\nquery: requestsPerUser\ndatabase: sqlite\nchart: doughnut\n</code></pre> <p>Finally, let's assume we'd like a notification when a new request is submitted. We can do this by creating a trigger on the request table. Open the table metadata section and enter the following expression for the field \"Trigger to call before a new record is created\":</p> <pre><code>$echo($)\n</code></pre> <p>This trigger is a simple expression that calls the echo function. Echo takes an object which is written to the system console. In this case the entire context is written. Once you save and submit another request, you should see a line like this in the console:</p> <pre><code>{database=sqlite, search=null, command=create, table=REQUESTS, object={ID=762613, user=user, name=My test entry, submitted=2020-12-31T15:50:35.755459500Z}}\n</code></pre> <p>Instead of calling the echo function, we can of course send an email or perform any other kind of action. A common use case is to automatically set the createdBy and createdOn fields. This can be achieved by setting the after create trigger to:</p> <pre><code>$update(database, table, object.ID, {\"createdBy\": $djUser(), \"createdOn\": $now()})\n</code></pre> <p>Note that triggers can invoke each other recursively. If this expression would be the update trigger,  we might end up with an endless recursion resulting in a stack overflow. This can be avoided by performing the  update only if <code>$isRecursiveTrigger()</code> is false.</p>"},{"location":"i18n/","title":"I18N","text":"<p>The Dashjoin platform uses English as its default language. You can activate other languages and also support allowing users to choose a language. Note that only the non-developer pages are internationalized. Developer pages, such as the function catalog or the query editor, support English only.</p>"},{"location":"i18n/#setting-the-locale","title":"Setting the Locale","text":"<p>The Internationalization (I18N) settings are defined in the file <code>/assets/logincfg.json</code>. This is also the place where you configure OpenID providers. Please refer to the administration section for more information on how to provide this file.</p> <p>The default locale defines which language is used by the platform initially.  It can be set to an ISO 639 two-letter code. To choose german, for instance, use the following setting:</p> <pre><code>    \"defaultLocale\": \"de\"\n</code></pre>"},{"location":"i18n/#using-the-browser-locale","title":"Using the Browser Locale","text":"<p>Browsers transmit the user's preferred locale to the web server using the accept-language header. If you would like to set the default locale to this value, set the default locale to browser:</p> <pre><code>    \"defaultLocale\": \"browser\"\n</code></pre> <p>In case no translations are available for the browser's locale, the system defaults to English.</p>"},{"location":"i18n/#allowing-users-to-switch-locales","title":"Allowing Users to Switch Locales","text":"<p>If your users speak different languages, you can specify a set of languages to be supported by the system using the locales array. To setup german and english, use the following key in the logincfg.json file:</p> <pre><code>    \"locales\": [\"en\", \"de\"]\n</code></pre> <p>Minimally, this array must contain the default language. If two or more languages are specified, the user interface shows a language picker on both the login screen and the toolbar.</p>"},{"location":"i18n/#providing-translations","title":"Providing Translations","text":"<p>If you choose to accept the browser's locale or if you allow users to change the locale, your widgets should support different languages as well. Consider the following simple text widget:</p> <pre><code>{\n    \"widget\": \"text\",\n    \"text\": \"Hello World\"\n}\n</code></pre> <p>The simples approach is to define the internationalized texts in the system configuration (/config/dj-config). There is an I18N category. If we translate the text to German, we change the \"de\" system setting to:</p> <pre><code>{\n    \"ID\": \"de\",\n    \"category\": \"i18n\",\n    \"map\": {\n        \"Hello World\": \"Hallo Welt\"\n    }\n}\n</code></pre> <p>In this case, the I18N key happens to be the English version of the text. This is ok for short, static texts. If texts are longer or likely to change over time, you should pick a generic key:</p> <pre><code>{\n    \"widget\": \"text\",\n    \"text\": \"my.app.helloworld\"\n}\n</code></pre> <p>The translations are provided as follows. Note that the dot can be used to group messages. For more information about this I18N format, visit the Polyglot JS site.</p> <pre><code>{\n    \"ID\": \"de\",\n    \"category\": \"i18n\",\n    \"map\": {\n        \"my\": {\n            \"app\": {\n                \"helloworld\": \"Hallo Welt\"\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"i18n/#translating-tablenames-columnnames-and-forms","title":"Translating Tablenames, Columnnames, and Forms","text":"<p>The same principle is also applied to table names, column names, and the labels in forms. If you would like to translate  EMPLOYEE_ID to MITARBEITER_ID, use this line in the de.json config file:</p> <pre><code>    \"EMPLOYEE_ID\": \"MITARBEITER_ID\",\n</code></pre>"},{"location":"i18n/#customizing-the-cookie-banner-and-login-screen","title":"Customizing the Cookie Banner and Login Screen","text":"<p>The login screen and the cookie banner are internationalized via the loginfgc.json file, since initially, there are no credentials available to access the platform's config database.</p> <p>The following keys are defined:</p> <pre><code>\"i18n\": {\n    \"en\": {\n        \"legal\": \"...\",\n        \"legalButtonText\": \"I understand\",\n        \"newUser\": \"New User\",\n        \"enterEmailAndPwd\": \"Enter your E-Mail and initial password\",\n        \"receiveActivation\": \"You will receive an activation link\",\n        \"email\": \"E-Mail\",\n        \"createAccount\": \"Create Account\",\n        \"resetPassword\": \"Reset Password\",\n        \"enterEmail\": \"Enter your E-Mail\",\n        \"receiveReset\": \"Password reset instructions will be sent\",\n        \"guest\": \"Login as Guest\",\n        \"continueWith\": \"Continue with\",\n        \"noPrivilege\": \"Your user lacks the required privileges to use the system. Please contact your system administrator\",\n        \"noPrivilegeURL\": (optional link URL for contacting the system administrator),\n        \"noPrivilegeButton\": (optional link label for contacting the system administrator)\n    }\n</code></pre> <p>To change a key, e.g. the legal disclaimer, add these lines to your logincfg.json:</p> <pre><code>\"i18n\": {\n    \"en\": {\n        \"legal\": \"My legal disclaimer\",\n    }\n</code></pre> <p>To add a new language, use:</p> <pre><code>\"i18n\": {\n    \"cn\": {\n        provide all keys with translations\n    }\n</code></pre>"},{"location":"i18n/#supported-languages","title":"Supported Languages","text":"<p>The language support of the platform is comprised of Dashjoin texts as well as the texts of the underlying react admin framework.  Dashjoin provides English and German, and bundles react admin languages en, de, fr, it, and es.</p>"},{"location":"i18n/#i18n-in-expressions","title":"I18N in Expressions","text":"<p>The current locale is exposed via the \"locale\" field in the expression context. In addition, you can access the language bundles via the translate function:</p> <pre><code>$translate('ra.action.search')\n</code></pre> <p>This command returns Search for the English locale, Suche for German and so on.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#platform-as-a-service","title":"Platform as a Service","text":"<p>Dashjoin offers a fully managed Platform as a Service available at https://dashjoin.com/#getstarted.</p>"},{"location":"installation/#download-and-local-setup","title":"Download and local setup","text":"<p>Installers and binaries for Windows, MacOS, and Linux are available at https://download.dashjoin.com/</p> <p>Important: These binaries run Dashjoin as a developer application, not as a service.</p> <ul> <li>windows/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Java Runtime. Unzip and start dashjoin.exe in a command prompt.</p> <ul> <li>windows/dashjoin-version.msi</li> </ul> <p>Dashjoin Windows Installer.</p> <p>Same contents as windows/dashjoin-exe.zip plus start menu icon.</p> <ul> <li>macos/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Runtime.</p> <p>Unzip and start <code>MacOS/Dashjoin</code> in a command prompt </p> <p>Note: if you get an error saying \"This Application is broken\", Apple Quarantine needs to be cleared with this command: <pre><code>xattr -cr Contents\n</code></pre></p> <ul> <li>macos/Dashjoin-version.dmg</li> </ul> <p>Dashjoin MacOS Installer</p> <p>Note: if you get an error saying \"This Application is broken\", Apple Quarantine needs to be cleared with this command: <pre><code>xattr -cr Dashjoin-*.dmg\n</code></pre></p> <ul> <li>linux/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Java Runtime.</p> <p>Unzip and start <code>bin/Dashjoin</code> in a command prompt</p> <ul> <li>linux/dashjoin-version.deb</li> </ul> <p>Dashjoin Linux Installer. Same contents as linux/dashjoin-exe.zip</p> <ul> <li>dashjoin-jar.zip</li> </ul> <p>Generic Java Archive (JAR) for all platforms</p>"},{"location":"installation/#creating-a-local-admin-user","title":"Creating a local Admin User","text":"<p>After installing Dashjoin, no user is set up in the system (a user can be defined via the environment variables - see below for more information). To set up the local development admin user, navigate to http://localhost:8080/#/setup.</p> <p>Choose a name, a username, and the password.</p> <p>Example: Name <code>Local Admin</code>, username <code>admin</code>, password <code>My.secure.pass!</code></p> <p>Note:</p> <p>this only works the very first time! After a development admin is created, no more local users can be created from the UI.</p> <p>To change or disable the local user, please edit or delete the files <code>djroles.properties</code> and <code>djusers.properties</code> in the application root directory. Here are more details on local users</p> <p>The Dashjoin authentication is configured to allow log in using social Google or Github accounts, or to allow registration of users by e-mail and password (authentication via e-mail uses the Google Firebase authentication).</p> <p>Click here for a demo video.</p>"},{"location":"installation/#local-users","title":"Local users","text":"<p>Local users are maintained in the files <code>djusers.properties</code> and <code>djroles.properties</code>.</p> <p>As the purpose for local users is for setup + dev, there is no management UI. To create / update users, or change the pwd, the corresponding entries have to be changed there.</p> <p>Passwords need to be specified as hash of <code>username:Dashjoin:password</code></p> <p>Follow these steps to add/change a local user:</p>"},{"location":"installation/#1-add-the-users-password-to-djusersproperties","title":"1. Add the user's password to <code>djusers.properties</code>","text":"<p>Important - hash the password salted with username + realm \"Dashjoin\": For user \"myuser\" and password \"mypass\", need hash of <code>myuser:Dashjoin:mypass</code></p> <p>For this example the result is <code>a3f1c2e80af79503cef46f9e198919d3</code> (see how to calculate below)</p> <p>So we need to add this line to <code>djusers.properties</code>: <pre><code>myuser=a3f1c2e80af79503cef46f9e198919d3\n</code></pre></p>"},{"location":"installation/#2-add-the-users-roles-to-djrolesproperties","title":"2. Add the user's role(s) to <code>djroles.properties</code>","text":"<p>To give \"myuser\" the \"authenticated\" role, add this line to <code>djroles.properties</code>: <pre><code>myuser=authenticated\n</code></pre> Multiple roles can be added with comma separation</p>"},{"location":"installation/#how-to-calculate-the-password-hash","title":"How to calculate the password hash","text":"<ul> <li> <p>Linux/MacOS: <pre><code>echo -n \"myuser:Dashjoin:mypass\" | md5sum -\n</code></pre></p> </li> <li> <p>Windows: <pre><code>powershell Write-Host -NoNewline \"myuser:Dashjoin:mypass\" &gt;temp.txt\npowershell (Get-FileHash -algorithm md5 temp.txt).Hash.ToLower()\ndel temp.txt\n</code></pre> need to store the string in a file temp.txt first (please delete after). Make sure there are no additional spaces and newlines</p> </li> <li> <p>Online:</p> </li> </ul> <p>For test/dev purposes you can also use an online service like https://emn178.github.io/online-tools/md5.html</p> <p>Note this might be insecure if the online service stores or re-publishes the entered strings!</p>"},{"location":"installation/#opening-the-dashjoin-application","title":"Opening the Dashjoin application","text":"<p>To access the application, navigate to http://localhost:8080</p>"},{"location":"installation/#docker","title":"Docker","text":"<p>This is the easiest and recommended way to run Dashjoin as a production service. The official container image <code>dashjoin/platform</code> is hosted on dockerhub</p> <pre><code>docker pull dashjoin/platform\ndocker run -p 8080:8080 dashjoin/platform\n</code></pre> <p>Point your browser to http://localhost:8080.</p> <p>If you would like to make the registered databases and credentials persistent, you can mount the \"model\" folder:</p> <pre><code>docker run -p 8080:8080 -v PERSISTENT_FOLDER:/deployments/model dashjoin/platform\n</code></pre>"},{"location":"installation/#run-local-dashjoin-installation-as-service","title":"Run local Dashjoin installation as service","text":"<p>If you have installed Dashjoin locally and want to run the application as a service, here are links on how to set up the service (not supported for production):</p> <ul> <li>Windows</li> <li>Linux (link to external site)</li> </ul>"},{"location":"installation/#environment","title":"Environment","text":"<p>Dashjoin uses the Quarkus configuration framework. A Dashjoin instance can be configured using the following environment variables:</p> <ul> <li>DJ_ADMIN_USER: admin user name (defaults to \"admin\")</li> <li>DJ_ADMIN_PASS: admin password (default is blank)</li> <li>DJ_ADMIN_ROLES: initial admin roles (defaults to the \"admin\" role)</li> <li>DASHJOIN_HOME: defines the dashjoin working directory (defaults to /deployments/model when using docker or the directory where the platform was launched). If you are using a platfrom executable or installer version, the working directory is set to userhome/.dashjoin and cannot be modified</li> <li>DASHJOIN_APPURL: optional git url where an app is cloned / pulled from (branches can be specified by appending #branchname)</li> <li>DJ_SID: optional system ID (contents of the file .secretid)</li> <li>WEBDEV_ENABLED: turn WebDAV on / off (required for the upload widget)</li> </ul> <p>By default, the service will be bound to 0.0.0.0 (all IP addresses) and serve HTTP on port 8080.</p> <p>For configuring HTTP ports, keystores etc. please refer to the Quarkus HTTP reference. The following example shows how to change the HTTP port using the windows executable:</p> <pre><code>&gt; set QUARKUS_HTTP_PORT=3333\n&gt; Dashjoin.exe\n</code></pre>"},{"location":"installation/#how-to-enable-https","title":"How to enable HTTPS","text":"<p>Note: in a production environment, very often a global load balancer (or other edge device) that serves HTTPS to the outside and connects to the Dashjoin service using HTTP is used.</p> <p>To enable HTTPS for the platform, the certificate file and the key file are required (usually called <code>cert.pem</code> and <code>key.pem</code>).</p> <p>Alternatively you can use a Java keystore, and you can also disable HTTP completely. Please refer to the Quarkus HTTP reference for all configuration options.</p> <p>Configure the service with the following settings: <pre><code>QUARKUS_HTTP_SSL_CERTIFICATE_FILE=/path/to/cert.pem\nQUARKUS_HTTP_SSL_CERTIFICATE_KEY_FILE=/path/to/key.pem\n</code></pre></p> <p>By default, the HTTPS port is 8443. To change it use: <pre><code>QUARKUS_HTTP_SSL_PORT=58443\n</code></pre></p>"},{"location":"installation/#self-signed-certificate","title":"Self-signed certificate","text":"<p>For test + dev, you can create a self-signed certificate with the following command <pre><code>openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n</code></pre></p>"},{"location":"installation/#import-an-ssl-certificate-to-the-java-trust-store","title":"Import an SSL certificate to the Java trust store","text":"<p>When accessing a third party system via SSL or HTTPS, the SSL certificate of the destination system needs to be trusted.</p> <p>In most cases this works \"automatically\" when the certificate was created such that an already trusted root certificate is already part of the Java trustStore. The trust store contains all major root certificates and is maintained by the Java vendor.</p> <p>When you encounter an error similar to the following:</p> <pre><code>javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.\nSunCertPathBuilderException: unable to find valid certification path to requested target\n</code></pre> <p>this means that the SSL certificate of the host being contacted is not trusted, and access was denied. This means that the certificate is either self-signed (dev or test), or by a root certificate not trusted (for example a corporate internal root certificate).</p> <p>There are 2 options to solve this situation:</p> <ul> <li>if the destination host is under your control, create and use a certificate that is trusted</li> </ul> <p>This is usually the preferred method, as it does not require to manually edit the trustStore.</p> <p>Remember that whenever the SSL certificate needs to be renewed (i.e. after expiry), the error will again show up, and another change to the trustStore is required, and the procedure needs to be repeated!</p> <ul> <li>import the SSL certificate to the Java trustStore</li> </ul> <p>The import procedure involves several steps. Please follow this detailed guide that shows how to import the certificate to the existing Java trust store called <code>cacerts</code></p> <p>Let's call the new trust store including the imported certificate(s) <code>my-cacerts</code>, now it needs to be made available to the running application in this location:</p> <p><code>&lt;java.home&gt;/lib/security/cacerts</code></p> <p>Note that the Java home is logged upon startup of the platform as <code>java.home</code>: <pre><code>Dashjoin Platform 3.1.38-e525ab3-6e8f7b6 (built 2022-12-20T17:31:57+0000)\nLinux 5.15.49-linuxkit aarch64 / OpenJDK 64-Bit Server VM 17.0.5+8-jvmci-22.3-b08 - GraalVM CE 22.3.0\navailableProcessors 4 / maxMemory (MB) 8192 / freeMemory (MB) 64 / totalMemory (MB) 80\n&gt; cwd       = /deployments\n&gt; java.home = /opt/graalvm-ce-java17-22.3.0\n\n _________         ______   ____    ____     \n  ___/ __ \\____ ______/ /_    (_)___  (_)___ \n   _/ / / / __ `/ ___/ __ \\  / / __ \\/ / __ \\\n   / /_/ / /_/ (__  ) / / / / / /_/ / / / / /\n  /_____/\\__,_/____/_/ /_/_/ /\\____/_/_/ /_/ \n                        /___/                \n\n              Powered by Quarkus 2.14.3.Final\n</code></pre></p> <p>If you have access to the file system of the installed Dashjoin platform, you can replace the file with the new version (copy my-cacerts over cacerts).</p> <p>In the containerized application, we can mount the file in the cacerts location. When using the docker CLI, use a mount option like</p> <p><code>-v /path/to/my-cacerts:/opt/&lt;java.home&gt;/lib/security/cacerts</code></p> <p>A complete Docker command using a customized <code>logincfg.json</code> and <code>my-cacerts</code> in the current directory:</p> <pre><code>docker run -p 8080:8080 \\\n  -v $(pwd)/logincfg.json:/deployments/assets/logincfg.json \\\n  -v $(pwd)/my-cacerts:/opt/graalvm-ce-java17-22.3.0/lib/security/cacerts \\\n  dashjoin/platform:latest\n</code></pre>"},{"location":"installation/#cross-origin-resource-sharing-cors","title":"Cross-origin resource sharing (CORS)","text":"<p>CORS is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from which the first resource was served. CORS is enabled by default, with standard settings.</p> <p>All configuration options are described in the CORS filter section.</p>"},{"location":"installation/#logging-levels-for-diagnostics","title":"Logging levels for diagnostics","text":"<p>Verbosity of the Dashjoin Platform is minimized for production workloads. The default level for logging is <code>INFO</code>.</p> <p>In order to increase verbosity for the whole platform, you can use <pre><code>QUARKUS_LOG_LEVEL=DEBUG\n</code></pre></p> <p>You can also change the log level of a certain category (module or file), for example to change <code>com.dashjoin.launch</code> logging to <code>DEBUG</code>: <pre><code>QUARKUS_LOG_CATEGORY__COM_DASHJOIN_LAUNCH__LEVEL=DEBUG\n</code></pre></p>"},{"location":"installation/#build-locally","title":"Build Locally","text":"<p>Prerequisites:</p> <ul> <li>Java (11 or later)</li> <li>Node (12 or later)</li> <li>Maven (3.6 or later)</li> <li>Angular CLI (11 or later)</li> <li>For Windows users: you need to create the symbolic link in \"platform\\dashjoin\\src\\main\\resources\\META-INF\": <code>mklink /D resources ..\\..\\..\\..\\..\\angular\\dist\\angular</code></li> </ul> <p>Dashjoin uses Quarkus as runtime framework (https://quarkus.io). You can run your application in dev mode using:</p> <pre><code>platform/angular$ npm install [--legacy-peer-deps # required if nvm -version &gt; 7.0!)\nplatform/angular$ ng build\nplatform$ mvn install\nplatform/dashjoin$ mvn compile quarkus:dev\n</code></pre> <p>Point your browser to http://localhost:8080.</p> <p>You can use the provided launch file to directly run from within Eclipse (right-click on the launch file, \"Run as\" or \"Debug as\" -&gt; \"Dashjoin\",  note that you need to adjust your jdk, mvn, and working directory location in the file \"Dashjoin.launch\"). This requires the Eclipse Quarkus plugin (https://quarkus.io/blog/eclipse-got-quarkused/) and the Lombok plugin (https://projectlombok.org/setup/eclipse) to be installed. Launching with \"Debug as\" will also enable live coding mode.</p> <p>The application can be packaged and installed locally using: <pre><code>platform/dashjoin$ mvn package install\n</code></pre></p> <p>It produces the <code>dashjoin-0.0.1-SNAPSHOT-runner.jar</code> file in the <code>/target</code> directory. Be aware that it\u2019s not an uber-jar as the dependencies are copied into the <code>target/lib</code> directory.</p> <p>If you want to build an uber-jar, execute the following command:</p> <pre><code>platform/dashjoin$ mvn package -Dquarkus.package.type=uber-jar\n</code></pre> <p>The application is now runnable using <code>java -jar target/dashjoin-0.0.1-SNAPSHOT-runner.jar</code>.</p>"},{"location":"installation/#eclipse","title":"Eclipse","text":"<p>The Eclipse IDE can be used to develop and debug locally. First install the Eclipse Quarkus tools.</p> <p>After cloning the Github repository, you need to import at least the following Maven projects into the Eclipse workspace:</p> <ul> <li>dashjoin</li> <li>dashjoin-core</li> </ul> <p>Optional additional modules: * dashjoin-demo * dashjoin-kafka * dashjoin-mongodb</p> <p>The Maven dependencies need to be initialized with (right click dashjoin project folder) -&gt; Maven -&gt; Update Project. The Angular UI must be built using the CLI, please refer to the previous section.</p> <p>When everything was build successfully, you can use the Dashjoin.launch configuration to run or debug the platform. The Quarkus launcher supports hot loading of resources, i.e. any changes made will be adjusted at runtime without having to restart the platform. (Note: you will have to adjust the absolute folder references in the launch file to you own workspace settings)</p>"},{"location":"installation/#version-history","title":"Version History","text":""},{"location":"installation/#10-may-2021","title":"1.0 (May 2021)","text":"<ul> <li>Launch of the platform</li> </ul>"},{"location":"installation/#20-jan-2022","title":"2.0 (Jan 2022)","text":"<ul> <li>Extended support for databases: MongoDB, ArangoDB, RDF</li> <li>Support for graph queries: database drivers can implement graph / path queries, widgets can display graph query results and the platform has basic support for OpenCypher</li> <li>Chart improvements: support for stacked bar charts, ability to configure charts with all ChartJS options</li> <li>New Function: the \"receive\" function supports streaming data / IoT use cases</li> <li>App development / lifecycle: apps can be written collaboratively on GitHub, auto-installed upon platform launch</li> <li>Functions and databases can be deployed as micro-services using the RemoteDatabase driver</li> </ul>"},{"location":"installation/#21-apr-2022","title":"2.1 (Apr 2022)","text":"<ul> <li>UI: HTML component, icons editor and display icon specification, run write queries from catalog, JSONata editor, MAP widget, PDF export</li> <li>ETL: streaming XML, YAML, transparent HTTP caching</li> <li>JSONata: 100% compatibility to JSONataJS, functions with multiple parameters</li> <li>Graph Search: PathQL integration</li> <li>Data Model: JSONb arrays can be foreign keys, allow specifying external ontology</li> </ul>"},{"location":"installation/#25-july-2022","title":"2.5 (July 2022)","text":"<ul> <li>UI</li> <li>Components can be scheduled to redraw live data</li> <li>Chart, table and tree widget support JSONata in addition to DB queries</li> <li>Page variables can be set via the URL</li> <li>Charts are clickable and navigate to the respective instance page</li> <li>Forms support document upload</li> <li>Search: Results can be restricted per database and table</li> <li>Data Model</li> <li>Databases, tables and properties can be assigned a \"title\" that is used in forms and hyperlinks</li> <li>A description can be set for databases, tables and properties, enhancing the technical metadata with semantics</li> <li>Support for SQL views</li> <li>SDK</li> <li>Monaco editor integrated for editing SQL, HTML, and CSS</li> <li>Introduced CSV parsing options</li> <li>New openText function allows web scaping</li> </ul>"},{"location":"installation/#30-oct-2022","title":"3.0 (Oct 2022)","text":"<ul> <li>UI</li> <li>Query editor preview enhanced for complex queries</li> <li>Query catalog improvements for scripts and write queries</li> <li>Display and table widgets support showing images, hyperlinks and lists</li> <li>Query processing</li> <li>Support for multiple SQL result sets</li> <li>Streaming DB copy</li> <li>Better support for stored procedures</li> <li>Access control</li> <li>Row level security</li> <li>SDK</li> <li>Ability to provide alternative development DBs and REST services</li> <li>Platform helps in identifying missing / orphaned queries / functions</li> <li>Platform offers JSON:API and ODATA interfaces</li> </ul>"},{"location":"installation/#31-dec-2022","title":"3.1 (Dec 2022)","text":"<ul> <li>UI</li> <li>Create and edit queries directly from layout editor</li> <li>Ability to block entire pages for certain user roles</li> <li>Easy customization of the toolbar for different user roles</li> <li>Query processing</li> <li>Support union queries in query preview</li> <li>SDK</li> <li>Support downloading binary data</li> </ul>"},{"location":"installation/#32-jan-2023","title":"3.2 (Jan 2023)","text":"<ul> <li>OpenAPI</li> <li>Dashjoin Apps can expose OpenAPI interface</li> <li>Implement existing OpenAPI specification via functions</li> <li>SwaggerHub integration</li> <li>Platform</li> <li>ARM support</li> <li>CORS configuration</li> <li>UI</li> <li>Optional confirmation dialog for button widget</li> <li>SDK</li> <li>Ability to include static assets in apps</li> </ul>"},{"location":"installation/#40-may-2023","title":"4.0 (May 2023)","text":"<ul> <li>AI &amp; ML</li> <li>Docker container / REST API for deploying custom models</li> <li>Image, face, and optical character recognition container</li> <li>Large language model for translation services</li> <li>Large language model for chat and instructions</li> <li>JSONata bindings for OpenAPI and Dashjoin AI &amp; ML APIs</li> <li>Automatic entity reconciliation and classification</li> <li>JSONata notebooks</li> <li>Ad hoc queries supported via JSONata</li> <li>File upload to JSONata notebooks</li> <li>Ad hoc ETL via JSONata</li> <li>Data Model</li> <li>Entity relationship schema visualization</li> <li>Table statistics</li> <li>Platform</li> <li>System exec JSONata function</li> <li>Improved SQLite insert performance</li> <li>SDK</li> <li>GIT operations available via JSONata</li> </ul>"},{"location":"installation/#50-jan-2024","title":"5.0 (Jan 2024)","text":"<ul> <li>UI</li> <li>Revamped user interface with several theme customization options</li> <li>WYSIWYG drag and drop layout editor</li> <li>Form layout integrated into the layout editor</li> <li>Edit and arrange diagrams and flow charts using the diagram widget</li> <li>Notebooks support map, table, and chart visualizations</li> <li>Platform</li> <li>Improved JSONata performance</li> <li>SDK</li> <li>Write your own widgets using any 3rd party JavaScript library and integrate them into the layout editor</li> <li>Manage your app versions and unit testing via the new Dashjoin Studio</li> <li>Dashjoin Studio bundles all required tools and makes them available right in your browser</li> </ul>"},{"location":"installation/#51-april-2024","title":"5.1 (April 2024)","text":"<ul> <li>Dashjoin AI Assistant</li> <li>Provisions a powerful large language model in a GDPR compliant way</li> <li>Allows defining document collections that the AI can use to answer questions</li> <li>Fully secured and ready to be managed by role based access control</li> <li>UI</li> <li>AI Chat Widget to interface with the AI Assistant</li> <li>Graph widget to explore the data graph - can be configured via JSONata and OpenCypher graph queries</li> <li>Platform</li> <li>New cloud offering includes ProgreSQL and flexible workloads</li> <li>Multi-tenant playground online</li> <li>SDK</li> <li>Optimized performance for JSONata openExcel</li> <li>JSONata curl command as a flexible HTTP client</li> <li>openHtml function to scrape webpages</li> </ul>"},{"location":"installation/#52-july-2024","title":"5.2 (July 2024)","text":"<ul> <li>UI</li> <li>Ability to specify redirect behavior after edit / delete</li> <li>Delete confirmation for table bulk delete</li> <li>Button form can be pre-populated</li> <li>Rows per table can be set</li> <li>Conditional rendering for all widgets</li> <li>onRender JSONata hook for all pages</li> <li>Multi file upload in forms</li> <li>Filter improvements</li> <li>Platform</li> <li>Ability to track platform users' first and last login times</li> <li>Incremental ETL from file resources</li> <li>SDK</li> <li>JSONata upsert function</li> <li>Support credential store for any kind of REST header / API key</li> </ul>"},{"location":"installation/#53-oct-2024","title":"5.3 (Oct 2024)","text":"<ul> <li>UI</li> <li>Analytics widget allows users to easily apply filters to charts and tables</li> <li>Voice (speech to text) input form element</li> <li>Support for comparators in table filters</li> <li>Enhanced JSONata support for the tree widget</li> <li>Container widget allows rendering a child for each array item</li> <li>Forms support entering arrays of foreign keys</li> <li>Platform</li> <li>Docker container / REST API for extracting text from PDF, Word, and HTML files</li> <li>Support PostgreSQL array type</li> <li>Support anonymous guest login</li> <li>SDK</li> <li>Support for externalizing JSONata into separate files</li> <li>JSONata text to speech function</li> <li>curl supports socket timeout</li> </ul>"},{"location":"installation/#54-jan-2025","title":"5.4 (Jan 2025)","text":"<ul> <li>UI</li> <li>Stepper and Tab widgets</li> <li>Support wide tables by aligning table controls to the right side of the screen</li> <li>Platform</li> <li>I18N Support</li> <li>Smart externalization of multi line JSONata</li> <li>Allow forms to be configured dynamically via data and expressions</li> <li>JavaScript as an alternative to JSONata</li> <li>SDK</li> <li>GenerateExcel function</li> <li>Functions to display progress and modal dialogs</li> </ul>"},{"location":"installation/#60-apr-2025","title":"6.0 (Apr 2025)","text":"<ul> <li>Dashjoin AI Assistant</li> <li>Write Python / AI code in an embedded Jupyter environment</li> <li>Add custom AI code to your Dashjoin app and deploy it in production</li> <li>Leverage Dashjoin functions as AI tools for agentic reasoning</li> <li>API support for RAG document collections</li> <li>Security</li> <li>Login with 2FA and Passkey</li> <li>UI</li> <li>Datagrid widget to allow excel-style editing of multiple records</li> <li>WYSIWYG editor with custom menus to run AI &amp; actions</li> <li>QR code and camera access from forms</li> <li>Mobile UI Enhancements</li> <li>Mobile / responsive table layout</li> <li>Tree widget can display a nested icon list (e.g. for use in the side bar)</li> <li>Analytics widget supports IN operator</li> <li>SDK</li> <li>Upload files widget plus platform WebDAV support</li> <li>Faster build process for custom widgets</li> <li>New functions to generate CSV, YAML, and CSV</li> <li>Row based access control supports queries and list of owners for a record</li> </ul>"},{"location":"security/","title":"Security and Access Control","text":""},{"location":"security/#security","title":"Security","text":"<p>We strongly advise to:</p> <ul> <li>Consider using read-only database credentials when registering a database with data that is managed by another application</li> <li>When adding a new database, make sure the access control settings are setup correctly</li> <li>Restrict access to the system in case you store confidential data in any of the registered databases</li> <li>All credentials that are entered into the system are encrypted using strong SHA-256 encryption. The master key resides in the file model/.secrets.id on the web server. Keep this file secured</li> <li>Add a OpenID provider in order to authenticate organization users</li> </ul> <p>In order to register new databases, the user must be in the \"admin\" role.</p>"},{"location":"security/#access-control","title":"Access Control","text":"<p>Several other sections already touched on access control and how certain functionality is only allowed for certain roles. This section explains how roles are defined and how users are assigned to be in a role.</p>"},{"location":"security/#info-page","title":"Info Page","text":"<p>The info page shows various system data. At the top of the page you find the username of the current user as well as the roles he or she is in. From there you also find a link to the roles dashboard and, on the PaaS offering, a link to the tenant users.</p>"},{"location":"security/#roles-dashboard","title":"Roles Dashboard","text":"<p>The roles dashboard allows the administrator to define system roles. The role names should correspond on the roles defined in the identity management system (IDM) you are using. Let's assume that the IDM defines a user to be in the role \"consulting\". If this role \"consulting\" is defined in Dashjoin and the user logs in,  the user also has this role when using Dashjoin. If you are using the Dashjoin Cloud, you can choose arbitrary role names and assign users to these roles using the tenant user dashboard.</p>"},{"location":"security/#tenant-user-dashboard","title":"Tenant User Dashboard","text":"<p>The previous section explained how IDM roles are carried over to Dashjoin. However, there might be situations, where an application requires a role which is not yet defined in the IDM. For instance, only some of the consultants in the IDM group \"consultant\" should be granted access to the application. One way would be to create a new Dashjoin role and a new corresponding IDM role. In some organizations, this might not be feasible though, since the IDM is usually managed by a different entity within the organization.</p> <p>The tenant user dashboard can be used in these cases. It allows the administrator of the Dashjoin instance to explicitly assign roles to IDM users without having to explicitly create and assign the role in the IDM.</p> <p>This mechanism can also be used to request access to a Dashjoin application. Let's assume a user is registered in the IDM, but has no access to Dashjoin. If he logs in, he'll get a \"permission denied\" error, however, the user will show up on this dashboard, with the \"active\" flag set to false. The administrator can then activate the user and assign the proper roles.</p> <p>If all users of a domain are to be added, the tenant user id can be set to \"@domain.org\". In this case any user id ending with this domain suffix gets the roles defined in this record.</p> <p>Finally, you can use the tenant id \"@EVERYONE\" to define roles for all users that are defined in the IDM, regardless of the roles they are assigned in the IDM.</p> <p>Note that email addresses are case sensitive in this context. For example, if a user uses both Joe@example.org and joe@example.org, both versions of the email will show up in the tenants table and both will have to be activated and assigned roles.</p>"},{"location":"security/#assigning-roles","title":"Assigning Roles","text":"<p>Roles can be assigned to the following elements:</p> <ul> <li>Container widgets and the top level page widget: In the layout editor, you can specify that a container or page is only shown if the user is in a given role. Note that this feature does not replace the backend checks listed below. Containers are simply hidden. The page shows an error message on the bottom.</li> <li>Toolbar elements: You can customize which elements are visible on the toolbar by editing the toolbar widget at /#/config/widget/dj-toolbar. Roles can be assigned to icons, the sidenav toggle, the page edit button, and the search box</li> <li>Functions: Functions can be restricted to be executable only to users in certain roles</li> <li>Queries: Queries can be restricted to be runnable only to users in certain roles</li> <li>Tables</li> <li>readRoles: Users in one of these roles get to read rows of this table</li> <li>writeRoles: Users in one of these roles get to update, delete, and create rows of this table</li> <li>Databases: defines a database wide default for any table that does not define read or write roles</li> </ul>"},{"location":"security/#row-level-security","title":"Row-Level Security","text":"<p>Row-Level Security allows restricting access to certain table rows depending on the value of a column. A common use case are portals where different tenants should only see their data. Consider the following example where the owner column is the email of the user the item belongs to:</p> id name owner 1 item 1 joe@example.com 2 item 2 mike@localhost <p>Using the table metadata editor, we can define \"owner\" to be the \"tenantColumn\", i.e. the column that defines the row-level security. If user mike logs in, he will only see item 2 on the item table.</p> <p>If the owner column contains an array of strings, the platform checks whether the current user appears in the array. This way, a row can be exposed to different users.</p> <p>Row-level security can also be defined by users being in a certain role. Consider this customer table:</p> id name region 1 customer 1 south 2 customer 2 north <p>Now, let's assume role \"sales-south\" should get access to rows where region is \"south\". This can be accomplished by defining region to be the tenantColumn in addition to defining the following role mapping:</p> <ul> <li>sales-south: south</li> <li>sales-north: north</li> </ul> <p>Row-level security is applied to the entire dashjoin platform automatically, except for queries. If a query involves a table that has row-level security defined, the query must have a parameter that is set accordingly. We show two examples for the tables defined above. A query on the item table might look as follows:</p> <ul> <li>query: select * from item where owner = ${tenant}</li> <li>query parameter expression: { \"tenant\": user }</li> </ul> <p>The role mappings on the customer are translated to a JSONata expression:</p> <ul> <li>query: select * from customer where region = ${tenant}</li> <li>query parameter expression: { \"tenant\": \"sales-south\" in roles ? \"south\" : (\"sales-north\" in roles ? \"north\") }</li> </ul> <p>When using queries, there is no guarantee that the client sends the correct user information. Rather than using { \"tenant\": user }, where \"user\" is the current user's email address, the client could also send { \"tenant\": \"other@example.org\" } to spy on another user. To prevent this, use the parameter name \"_dj_email\". This parameter is set from the caller's security context by the backend, overriding any other parameter value sent from the client.</p>"},{"location":"security/#user-dashboard","title":"User Dashboard","text":"<p>As the platform admin, the user dashboard shows all the users that have already logged into the system, along with the time of the first and last login. This information can be used by app developers to implement billing mechanisms for their users respectively.</p>"},{"location":"support-matrix/","title":"Supported Databases","text":""},{"location":"support-matrix/#relational-databases","title":"Relational Databases","text":"<p>We support all of the SQL databases out of the top 10 database engines:</p> Database Driver class Driver version Status Connection URL Notes Oracle oracle.jdbc.OracleDriver 19.6.0.0.0 beta jdbc:oracle:thin:@...:1521/ORCL MySQL org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default SQL Server com.microsoft.sqlserver.jdbc.SQLServerDriver 11.2.0 beta jdbc:sqlserver://...:1433;databaseName=db; PostgreSQL org.postgresql.Driver 42.5.0 jdbc:postgresql://...:5432/db SQLite org.sqlite.JDBC 3.31.1 jdbc:sqlite:my.db DB2 com.ibm.db2.jcc.DB2Driver 1.4.0 beta jdbc:db2://...:50000/db MS Access net.ucanaccess.jdbc.UcanaccessDriver 4.0.1 beta jdbc:ucanaccess://db.accdb MariaDB org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default H2 org.h2.Driver 2.1.214 jdbc:h2:tcp://.../db Amazon RDS Aurora PostgreSQL org.postgresql.Driver 42.5.0 beta jdbc:postgresql://...:5432/db Amazon RDS Aurora MySQL org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default"},{"location":"support-matrix/#document-databases","title":"Document Databases","text":"Database Driver class Driver version Status Firestore google-cloud-firestore 3.2.0 Available in Dashjoin PaaS MongoDB mongodb-driver-sync 4.7.2 beta"},{"location":"support-matrix/#graph-databases","title":"Graph Databases","text":"Database Driver class Driver version Status RDF4J rdf4j-runtime 3.7.4 beta / must be deployed as a remote database - see the module page for setup instructions ArangoDB arangodb-java-driver 6.14.0 beta <p>Click here for a demo video.</p>"},{"location":"user-interface/","title":"User Interface","text":"<p>This section explains all Dashjoin user interface pages in more detail.</p>"},{"location":"user-interface/#universal-database-frontend","title":"Universal Database Frontend","text":"<p>Dashjoin offers an intuitive default visualization for any kind of data.  Click here for a demo video. It features the following building blocks:</p>"},{"location":"user-interface/#default-visualization-of-tables","title":"Default Visualization of Tables","text":"<p>Unless specified otherwise using the layout editor, all table pages show two elements. First, we have a sortable and pageable table showing the database table contents. Any primary or foreign key displays a link to the corresponding record page. Secord, the page shows a form for creating a new table record. The form is configured using the table metadata the system collected from the database. In case you are a system administrator, you will see two more widgets which are explained in the section on data definition operations below.</p>"},{"location":"user-interface/#default-visualization-of-records","title":"Default Visualization of Records","text":"<p>The record page also has two elements. First, there is a form allowing to update and delete the record. The form is almost identical to the create form on the table page. The only exception is that it is not allowed to change primary key columns. If you would like to do this, you need to delete and re-create the record using the new key. Second, the page has a widget showing links to the table page and all related records. Note that records are related if a key in the record points to another record or vice versa.</p>"},{"location":"user-interface/#search-page","title":"Search Page","text":"<p>Dashjoin offers a powerful search capability of the underlying databases. When you enter a search term in the toolbar, the search is federated to all registered databases and the result page shows the combined result using the following columns:</p> <ul> <li>a link to the actual record matching the search</li> <li>the name of the table the record is located in</li> <li>the name of the column that matched the search</li> <li>the matching column value</li> </ul> <p>In order to boost performance, Dashjoin pushes down the search queries to the underlying databases if possible. Therefore, depending on the database, the search might match keywords slight differently:</p> <ul> <li>SQL databases perform a case insensitive contains operation (i.e. \"My Test String\" would match the search term \"test\")</li> <li>Firestore performs a case sensitive starts with operation (i.e. \"My Test String\" would match the search term \"My\" but not \"test\")</li> <li>The default implementation behaves like SQL</li> </ul>"},{"location":"user-interface/#data-and-database-management","title":"Data and Database Management","text":"<p>In Dashjoin, it is possible to register multiple databases. This section lists the supported management operations for these databases.</p>"},{"location":"user-interface/#database-dashboard","title":"Database Dashboard","text":"<p>The database dashboard shows the databases known to the system and allows registering new databases. The table displays some core information about each database, the connection status as well as the number of tables detected. To register a new database, first select the database type. Depending on your choice, the respective connection options appear. Once you connect, Dashjoin will collect the database metadata and immediately make the new database ready for searches, queries, and browsing. The table also provides a link to the individual database. Use this page to change connection parameters. You can also simply press update to recollect the metadata. This is useful if the underlying schema was changed by another application. Deleting the database disconnects from the database and deletes the connection information. No data is deleted in the database.</p> <p>On the page of a database instance, you can edit the connection parameters. Submitting the form will re-connect the database and pick up any schema changes that were performed by other applications.</p> <p>You can also specify the roles that are allowed to read and write to the database. Note that by default, the admin role has access to all tables.</p> <p>If you would like to exclude certain tables from being accessible via the platform, you can add their names in the excludeTables field in the database's JSON file in the model folder as follows:</p> <pre><code>  \"excludeTables\": [\"table1\", \"table2\"],\n</code></pre>"},{"location":"user-interface/#data-definition-operations","title":"Data Definition Operations","text":"<p>The database page offers a database management section. You can create a new table there. The new table will contain two columns:</p> <ul> <li>ID: a numeric primary key</li> <li>name: a generic string describing the record</li> </ul> <p>The display table shows all database tables. You can delete tables there. Attention: this is a permanent operation that you have to confirm by typing \"delete\" into the dialog. Editing a table offers several options which are explained in the following sections. You can change the table name. This change is performed on the underlying database (e.g. a rename table operation on an SQL database).</p> <p>Following the link to an individual table offers two sections in addition to the normal table display. The table metadata section simply makes the table operations (e.g. renaming a table) available from this page also. The column metadata allows creating, renaming, and deleting columns. Attention: deleting columns is a permanent operation and needs to be confirmed by typing \"delete\" in the dialog. Besides renaming columns, other options are available which are explained in the below.</p>"},{"location":"user-interface/#upload","title":"Upload","text":"<p>The database management section also allows to upload data from multiple files to the current database. The following file extensions are supported:</p> File Extension Table Name Column Name Suggested Data Type Suggested Primary Key Comma separated UFT-8 format as defined by RFC 4180 .csv File name before extension First row Guess by inspecting the data First unique column Microsoft Excel .xlsx Sheet name First row Guess by inspecting the data First unique column SQLite database .sqlite From database From database From database First unique column JSON table .json File name before extension First row Guess by inspecting the data First unique column Model folder upload to config DB - - - - - <p>The system allows you to choose multiple files and collects all tables and columns from them and displays a preview of all tables in tabs. The table above shows how the system determines table and column names as well as the primary key and column types. You cannot change the table and column names in this display. If you would like to change them, abort the process, change the source file, and repeat the upload process.</p> <p>Depending on the tables to be uploaded, there are two modes. If one of the tables exists already, we enter the append / replace mode. This mode requires the structure of all tables to match the existing tables. You cannot pick column types or primary keys in this mode. You can then decide to append the data to the existing data or to replace the existing data. Attention, replacing the data will delete the data currently stored in these tables permanently. You therefore have to confirm this operation by entering \"delete contents\".</p> <p>If none of the tables exist, we enter the create mode. The preview does allow changing the primary key and column types. The suggested values are guesses based on the data and must be double checked by the user.</p>"},{"location":"user-interface/#column-operations","title":"Column Operations","text":"<p>The operations on columns can be grouped into two categories. First, changing the name and / or datatype results in the underlying database to be changed (i.e. using an alter column command on SQL databases).</p> <p>Second, editing primary and foreign keys are changes on the metadata level only, since not all databases support these concepts. You can specify a column to be the primary key of the table. Note that the user interface does not support composite primary keys. A column can also be defined to be a foreign key by entering the corresponding linked primary key. Note that it is possible to define references not only within the same database but also to other databases. Setting foreign key references causes the foreign key column to display links to the related record and vice versa.</p>"},{"location":"user-interface/#complex-column-types","title":"Complex Column Types","text":"<p>Certain databases support storing arbitrary JSON data in a column. In this case, it is not possible to retrieve the required schema information in order to display a proper form for data entry. In this situation, you can use Dashjoin Studio to enter a complex schema via a text editor. A JSON column defaults to type \"string\". In the column editor, you can change this type to \"object\" or \"array\". Open Dashjoin Studio, and locate the change. You can enter a schema - for instance for a coordinate type - as follows:</p> <pre><code>    \"tables\": {\n        \"mytable\": {\n            \"properties\": {\n                \"mycolumn\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"x\": {\n                            \"type\": \"integer\"\n                        },\n                        \"y\": {\n                            \"type\": \"integer\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n</code></pre>"},{"location":"user-interface/#table-label","title":"Table Label","text":"<p>Besides changing the table name, you can enter a label and triggers. The label defines how the system should display a record in the following scenarios:</p> <ul> <li>the browser page title when we are on a record of that table</li> <li>in the autocomplete dropdown when editing a foreign key field</li> <li>when displaying the label of a hyperlink pointing to the record</li> </ul> <p>This feature is important when a table uses an artificial or non-descriptive primary key like a number or a UUID. By default, the system uses the key in the scenarios above, leading to unreadable and unintuitive displays. In this situation, the label can be changed to a template string with the template variable referencing other more descriptive record columns. For instance the table PERSON could define a label <code>${LAST_NAME}</code> or even <code>${LAST_NAME}, ${FIRST_NAME}</code> in order to display meaningful and user readable information rather than numbers or UUIDs.</p> <p>In case of an M:N relationship, the label can be shown depending on where the link is being displayed. I.e. the page for M looks at the M:N and will only display N, and N looking at M:N will see M (this works as intuitively expected). The syntax for labels that need dereferencing is to prepend ''. To render a M:N you could use: {M} {*N} where M and N are attributes (columns) in the relationship (table).</p> <p>Note that the user interface loads these template values in a lazy fashion whenever you visit a record page.</p>"},{"location":"user-interface/#table-triggers","title":"Table Triggers","text":"<p>Dashjoin offers create, update, and delete operations for each table. A trigger can be installed on each table that reacts before or after these operations, resulting is six trigger configurations. A trigger is an expression that is evaluated in the respective case. This following context is passed to the expression:</p> <ul> <li>command: one of create, update, or delete</li> <li>database: the database being modified</li> <li>table: the table being modified</li> <li>search: a map with the record's primary keys</li> <li>object: the record to the created or the fields to be updated</li> </ul> <p>Please see the section on expressions for more details.</p>"},{"location":"user-interface/#table-and-column-comment-and-title","title":"Table and Column Comment and Title","text":"<p>Dashjoin extracts the technical metadata from the databases. The editor allows you to add a comment for tables and columns in order to document the data model. The table title is used when displaying a link to the table. Likewise, column titles are used in CRUD forms and the show all records table columns.</p>"},{"location":"user-interface/#query-catalog-and-editor","title":"Query Catalog and Editor","text":"<p>The query catalog allows you to save queries that are used by other parts of the application. Usually, these are chart and table widgets that display query results. The catalog allows you to manage queries in a central place, reuse them across the application and define important metadata about parameters and access control. Click here for a demo video.</p>"},{"location":"user-interface/#query-catalog-page","title":"Query Catalog Page","text":"<p>The query catalog page show a list of all defined queries as well as a form for entering a new query. The form has the following fields:</p> <ul> <li>ID: this is a unique identifier to reference the query (e.g. from a chart widget)</li> <li>type: queries can have type read and write indicating whether the running the query will make changes to the underlying database</li> <li>roles: defines which roles are allowed to run the query</li> <li>database: this field can only be written from the editor as shown below and defines which database is used in the query editor (note that the application can later run a query on other database with the same schema)</li> <li>arguments: queries can be parameterized using arguments (see the section below for more details)</li> <li>query: allows making manual edits to the query and offers to open the query editor dialog</li> </ul> <p></p>"},{"location":"user-interface/#features","title":"Features","text":"<ul> <li>Graphically build queries in an Excel-like fashion</li> <li>Add columns and join tables via point and click</li> <li>Reorder columns using drag &amp; drop</li> <li>Apply where filters by simply adding them to the query result table</li> <li>Aggregate / group results right in the data table</li> <li>Rename columns</li> <li>Manual query edits are possible as well</li> <li>Download results as CSV</li> </ul>"},{"location":"user-interface/#supported-query-constructs","title":"Supported Query Constructs","text":"<p>The editor supports a wide range of features of the query language, namely any kind of table join, aggregation and filter. It is possible to add advanced constructs such as a subquery or a call to a user defined function or stored procedure to the query by making changes in the lower text field. In this case, the query editor displays the query result but no longer allows making changes to the query via the UI controls. The reason for the controls being disabled is shown in a tool tip. You can return to the last supported query via the undo button.</p>"},{"location":"user-interface/#result-size","title":"Result Size","text":"<p>During the process of writing the query, we limit the results to 1000 rows. Use the limit text field to set an explicit query limit. Once, the limit is set, it overrides the default of 1000 result rows.</p>"},{"location":"user-interface/#query-parameters","title":"Query Parameters","text":"<p>The query catalog page allows defining query parameters. Each parameter consists of the following information:</p> <ul> <li>key: this is the parameter name that allows the query to reference the parameter using <code>${key}</code></li> <li>type: defines the datatype of the parameter</li> <li>sample: this is the value that will be used in the query editor</li> </ul> <p>Consider the following example that searches for persons with a certain name older than a given age:</p> <pre><code>select * from PERSON where NAME=${p_name} and AGE&gt;${p_age}\n</code></pre> <p>This query has the string parameter p_name and the integer parameter p_age. In order to edit the query and display a result preview, we need to pluck in sample data. So we can define the samples:</p> <pre><code>p_name: Mike\np_age: 20\n</code></pre> <p>This results in the following query that is used when editing the query. So in the edit dialog, the following query is used (note that the system automatically handles quotation of strings and dates):</p> <pre><code>select * from PERSON where NAME='Mike' and AGE&gt;20\n</code></pre> <p>Once the editor is closed, the samples are replaced with the template variables again. Note that this replacement is string based, so you should choose parameter names that do not \"collide\" with other parts of the query. Hence, we choose the prefix p_.</p>"},{"location":"user-interface/#graph-queries","title":"Graph Queries","text":"<p>Apart from managing traditional queries, the Dashjoin query catalog can also be used to store graph queries. There are different flavors of graph query languages. We orient ourselves at the OpenCypher language and the upcoming GQL Standard. Like queries on document and relational database, graph queries return a table where the columns represent the projection variables and each row contains variable values that match the query pattern / path.</p> <p>The difference between the query types is that a graph query may return very different record types for a column / variable. Consider a graph query that returns all related records that are reachable with two hops from the starting record. Obviously, you will end up on very different records. In the northwind case, starting from an employee, these might be orders processed by the employee, the employee's boss's boss, and so on. Therefore, Dashjoin graph queries will make sure that apart from the raw data, the result also contains type information that can be used by the UI in order to interpret the values.</p> <p>Graph queries can be run on a specific or on all databases. Dashjoin contains a partial OpenCypher implementation. Consider the following OpenCypher  example (to learn OpenCypher, please refer to this interactive guide):</p> <pre><code>MATCH \n  path=(start:`dj/northwind/EMPLOYEES`)-[r1:REPORTS_TO]-&gt;(boss)-[r2:REPORTS_TO]-&gt;(finish) \nRETURN \n  start._dj_resource, boss.LAST_NAME, finish._dj_resource, path\"\n</code></pre> <p>This query traverses the recursive \"reports to\" relationship. The variables start, boss, and finish represent the graph nodes. As mentioned before, the engine adds the record metadata. i.e. which database and table / collection the record comes from. The path variable matches the entire traversal and contains all nodes and edges (relationships) that were traversed.</p> <p>AQL and SPARQL Property Paths are alternative graph query languages that can be pushed down to the native database query engine if the query is run on the respective ArangoDB / RDF4J database. The Dashjoin drivers make sure that the query result has the same structure as a corresponding OpenCypher query.</p> <p>Note that the graphical query editor does not yet support composing graph queries.</p>"},{"location":"user-interface/#pages-dashboard","title":"Pages Dashboard","text":"<p>While Dashjoin has a rich default page layout that is suitable for many use cases, every aspects of the display can be configured using the functionality described in this section.</p> <p>The pages dashboard provides you with an overview of the available pages in the system. The first table shows the dashboards available in the system. This is a mix of system pages, which are explained in more detail in the next section, and pages created by the user via the \"create a new page\" form.</p> <p>The page contains a link to widgets. This allows you to customize the sidebar and the toolbar.  You can edit the those by visiting the page /config/widget/dj-toolbar or /config/widget/dj-sidenav. A typical use case would be to edit the roles that are required for an icon to appear. You can also add an icon pointing to your custom dashboard page. Since the dj-toolbar is shipped with the system, you can revert back to the original version by clicking delete on this page.</p> <p>Finally, the layouts table provides an overview of all tables and whether the default layout is used or whether the user has customized the layout using the layout editor.</p> <p>Pages are located under /#/page/Pagename. Like all other UIs, they show the toolbar, the side navigation, and the main page content. If you navigate to /#/full/Pagename instead, only the main page content is rendered. This feature can be used for providing simplified UIs or simple landing pages.</p>"},{"location":"user-interface/#system-pages-and-layouts","title":"System Pages and Layouts","text":"<p>The system comes with a set of system pages (e.g. Home and Info) and some layouts for databases, tables, queries, etc. These layouts contain much of the functionality described in this reference guide.</p> <p>System pages can be changed using the editor introduced below, however, a delete operation does not delete them altogether, but rather resets them to the \"factory\" state. This ensures that you cannot accidentally damage a system permanently using the editor.</p>"},{"location":"user-interface/#layout-editor","title":"Layout Editor","text":"<p>To activate the layout and form editor, press the pen symbol in the toolbar. You will remain on the page, but several controls will pop up on the screen. The pen symbol is replaced with three icons:</p> <ul> <li>Delete: deletes the page or resets the default table or record layout</li> <li>Save: saves the changes</li> <li>Abort: leaves the editor without saving</li> </ul> <p>In the lower right screen corner you have the following controls:</p> <ul> <li>Undo / redo: undo an unwanted change</li> <li>Zoom: if you are editing a large page, you can zoom out to get a better overview or to drag elements from one end to the other</li> <li>Edit: when clicking on a widget, opens the widget editor on the bottom</li> <li>Move: displays arrows in each widget that move the mights in that direction. Alternatively, you can drag and frop widgets using the drag handle in the widget's upper right corner</li> <li>Resize: allows resizing widgets on a 12 column grid</li> </ul> <p>The plus icon is shown at the bottom of the page as well as for each container that was added to the page. This allows you to create nested layouts. Pressing the plus icon opens a drawer on the left where you can select the widget to add.</p> <p>Once you add a widget or select it for editing, the widget editor opens at the bottom of the page. You can enter texts, expressions, styles, icons etc.</p> <p>For more information on the layout editor, you can refer to the React Page documentation.</p>"},{"location":"user-interface/#expression-editor","title":"Expression Editor","text":"<p>Expressions are used in various places throughout the platform. The next sections describe the different usage scenarios in more detail. Whenever an expression is to be edited on a form, Dashjoin allows you to do this via the expression editor component which is explained in this section.</p> <p>The expression editor is a simple text field that shows context sensitive help and a result preview once you start typing.</p> <p>As an example, you can navigate to the info page, enter the page edit mode and edit the user display widget. The widget displays the result of the following expression which projects the user field from the page context (the composition of the context is explained in the next section):</p> <pre><code>{\"user\": user}\n</code></pre> <p>If you delete the closing curly bracket, the system will tell you that the expression is invalid: line 1:13: missing '}'. Now enter the following expression that calls the built-in read:</p> <pre><code>$read()\n</code></pre> <p>The system will tell you about missing parameters: Arguments required: <code>$read(database, table, pk1)</code>. Now change the expression to:</p> <pre><code>$read(\"northwind\", \"EMPLOYEES\", 2)\n</code></pre> <p>Assuming you have the demo application installed, this will show the first 10 lines of JSON that contain the respective record in the employees table of the northwind database. Finally, setting the expression to</p> <pre><code>$\n</code></pre> <p>displays the entire page context.</p>"},{"location":"user-interface/#function-page","title":"Function Page","text":"<p>The function page works a lot like the database page. It shows a table of the functions that have been created on the system. To create a new function, you first need to select the function type. Depending on your choice, you can enter the respective configuration parameters. The function type specifies whether the function is read only or whether it has side effects like sending email or writing data. Finally, the roles specify which user role is allowed to run the function. Functions define extract load transform operations that load data into one of the databases, email endpoints, or access the RESTful web services.</p> <p>Apart from creating and editing functions, you can also run the functions from the function page. Note that functions will be called without any parameters. If you would like to run functions with parameters, use the JSONata Notebook. Please refer to the developer reference chapter for a detailed listing of all supported functions.</p>"},{"location":"user-interface/#general-information-page","title":"General Information Page","text":"<p>This page contains some basic information about the platform version and installation parameters. At the top of the page, you find some important links that are grouped into the following four categories:</p>"},{"location":"user-interface/#user-information","title":"User Information","text":"<p>This section shows the user name, email, and roles. In addition, you can find links to the roles and tenant users tables. These are used for configuring roles and access control. For details, please consult the section security and access control.</p>"},{"location":"user-interface/#app","title":"App","text":"<p>The app section contains links to the following pages:</p> <ul> <li>Dashjoin Studio: this link opens Dashjoin Studio in a new window. This mode allows writing your own widgets using third party JavaScript libraries</li> <li>App API: This page allows you to use Dashjoin to implement an existing OpenAPI spec, publish schemas and paths to your OpenAPI spec, and generate an OpenAPI spec for your Dashjoin app</li> <li>Notebook: this is an area that works much like a jupyter notebook. You can conveniently experiment with JSONata there</li> <li>Git: this page provides a lightweight way to manage version control of your app. For more information please refer to the section development / production</li> </ul>"},{"location":"user-interface/#configuration","title":"Configuration","text":"<p>This section provides links to the system configuration. You can define certain user interface customizations there, configure database search parameters, and define some other system settings.</p> <p>The configuration database is a built-in database that defines queries, function, registered databases, etc.  Every role defined in the system must have read-only access to the configuration database. On this page, you can define which roles have access to which system tables and you can upload system tables (e.g. for importing users).</p>"},{"location":"user-interface/#databases","title":"Databases","text":"<p>The databases section shows a link to the query performance table. This table helps you to identify performance problems in your app. The ER diagram is a convenient way of visualizing your database schemata.</p>"}]}