{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Dashjoin Open Source &amp; Cloud Native Low Code Development Platform","text":"<p>For anyone who is planning a development project, faces a tight schedule, needs to present results quickly, or has limited development resources available. Dashjoin taps into and integrates your existing data sources and allows you to intuitively browse, search, edit, and visualize your integrated information. Add business logic to enable users and automation to act on the information. Unlike other Low Code Development Platforms, Dashjoin offers a free open source version with a commercial PaaS and bases on a unique, linked-data inspired approach to scalable data integration.</p> <p>Download: https://download.dashjoin.com/</p> <p>Live demo: https://demo.my.dashjoin.com/</p> <p>Webpage: https://dashjoin.com/</p> <p>Blog: https://medium.com/@dashjoin</p> <p>Training course slides: https://download.dashjoin.com/training/platform.pdf</p> <p>Video tutorials:</p> <p></p> <p>Features</p> <ol> <li>Universal DB Frontend: Connect to any SQL or NoSQL database, browse, search, and edit its contents. Extend the schema on the fly.</li> <li>Query Editor: Automatically collect schema information that powers an intuitive graphical query editor.</li> <li>Layout Designer: Graphically customize the layout for different types found in the database. Leverage the query editor to include meaningful charts.</li> <li>Data Integration and Federation: Visually map external data sources to your model. Load the data into a warehouse or federate the source into a virtual linked-data graph.</li> <li>Processes: Seamlessly start and integrate REST services from the application and monitor progress.</li> <li>Cloud Deployment: Deploy the apps in your private cloud or book our PaaS service. All apps scale horizontally and support state of the art cloud stacks.</li> <li>Everything JSON: Dashjoin leverages popular JSON standards like JSON Schema and JSONata and for all aspects of the system</li> <li>Artificial Intelligence: Seamlessly incorporate large language models, image classification, translation, and entity reconciliation services in your App</li> <li>Open Source: Join the Dashjoin community and avoid vendor lock-in.</li> </ol>"},{"location":"administration/","title":"Administration","text":"<p>This section describes administration and operating procedures for the Dashjoin platform.</p>"},{"location":"administration/#configuration-changes","title":"Configuration Changes","text":"<p>A system is defined by the following configurations: Dashboards, layout pages, user roles, registered databases, and functions. These settings are stored in the configuration database. For the open source version, this data is kept on the file system in the model folder. In the docker container, this folder is located under /deployments/model. For locally installed systems, this folder can be found under USER_HOME/.dashjoin/model.</p>"},{"location":"administration/#configuring-openid","title":"Configuring OpenID","text":"<p>The Dashjoin platform can be setup to delegate identity management to an OpenID provider such as Google, Microsoft Azure AD, Okta, or Keycloak.</p>"},{"location":"administration/#registering-the-dashjoin-application","title":"Registering the Dashjoin Application","text":"<p>The first step is to register the Dashjoin application in your OpenID management console. This example explains the process for Azure AD. Note that you will have to have a redirect URL such as \"https://dashjoin-app.example.com/login\" available.</p>"},{"location":"administration/#configuring-the-openid-provider-in-dashjoin","title":"Configuring the OpenID Provider in Dashjoin","text":"<p>The Dashjoin login page can be configured via a configuration file named <code>/assets/logincfg.json</code>.</p> <p>The default config is:</p> <pre><code>{\n    \"signInTabText\": \"My Dashjoin\",\n    \"signInCardTitleText\": \"Sign In\",\n    \"emailText\": \"E-Mail or Username\",\n    \"registerTabText\": \"New User\",\n    \"resetPasswordTabText\": \"Reset My Password\",\n    \"resetPasswordInputText\": \"Enter your E-Mail. Password reset instructions will be sent\",\n    \"emailLoginEnabled\": true,\n    \"registrationEnabled\": true,\n    \"guestEnabled\": false,\n    \"guestLoginEnabled\": true,\n    \"providers\": \"google\",\n    \"openIdConfigs\": []\n}\n</code></pre> <p>The information you gathered from registering your application in the previous step can be added in the openIdConfigs array as shown in the  following Azure AD example:</p> <pre><code>{\n    ...\n    \"openIdConfigs\": [\n        { \n            \"domain\": \"dashjoin.com\", \n            \"name\": \"Dashjoin Example.com\", \n            \"logo\": \"/favicon.ico\", \n            \"config\": { \n                \"issuer\": \"https://login.microsoftonline.com/.../v2.0\", \n                \"clientId\": \"...\", \n                \"redirectUri\": \"https://dashjoin-app.example.com/\", \n                \"scope\": \"openid profile email\", \n                \"requestAccessToken\": false, \n                \"strictDiscoveryDocumentValidation\": false \n            } \n        }\n    ]\n}\n</code></pre> <p>This config fields are defined as follows:</p> <ul> <li>Domain: the domain the application is running on</li> <li>Name: Application name in the IDM</li> <li>Logo: Absolute or relative URL to the IDM logo to be displayed on teh login screen</li> <li>Issuer: URL / UUID of the IDM issuing authorizations</li> <li>Client ID: ID of the registered application in the IDM</li> <li>Redirect URI: URL of the Dashjoin application Important: previously this required a link to /login, this does not work anymore. Use the root URL</li> <li>Scopes: scopes are used by an application during authentication to authorize access to a user's details</li> <li>Request Access Token: obtain an Access Token, an ID Token, and optionally a Refresh Token</li> <li>Strict Discovery Document Validation: ensure that all of the endpoints provided via the ID Provider discovery document share the same base URL as the issuer parameter</li> </ul> <p>You can configure multiple OpenID providers:</p> <p></p>"},{"location":"administration/#creating-and-assigning-application-roles","title":"Creating and Assigning Application Roles","text":"<ul> <li>After the application is registered within the IDM and the IDM made known to the application, you need to define the roles an IDM user has within the application. On Azure AD, this is the \"App roles\" dialog. Note that these roles must match the role names defined in the Dashjoin platform. The IDM must be configured to emit the groups as role claims. On Azure AD, this is done in the \"Token configuration\" dialog.</li> </ul>"},{"location":"administration/#adding-the-open-id-config-to-the-platform","title":"Adding the Open ID Config to the Platform","text":"<ul> <li>Option 1: </li> </ul> <p>The login config can be stored in the app as <code>/assets/logincfg.json</code></p> <p>This is the easiest and usually preferred method.</p> <p>But note that all app developers with write rights can make changes to this file.</p> <p>As the login config is highly relevant to security, make sure to validate its content and verify who has made changes.</p> <p>If this is not acceptable, you can also use the next option.</p> <ul> <li>Option 2:</li> </ul> <p>Alternatively, you can store the file in the installed Dashjoin platform, outside of the app.</p> <p>The Open ID configuration must be stored as  <pre><code>META-INF/resources/assets/logincfg.json\n</code></pre> relative to the current working directory of the platform.</p> <p>Note that the current working directory depends on the OS and the way the platform is installed / started.</p> <p>The next sections list the locations on different operating systems.</p>"},{"location":"administration/#installed-dashjoin-application","title":"Installed Dashjoin application","text":"<ul> <li> <p>On Windows, the default location is <pre><code>C:\\Users\\&lt;username&gt;\\AppData\\Local\\Dashjoin\\META-INF\\resources\\assets\\logincfg.json\n</code></pre></p> </li> <li> <p>On Linux and MacOS, store the file relative to the location Dashjoin is launched (current working directory). I.e. if the platform is launched from <code>/home/dashjoin</code>, store the config at <pre><code>/home/dashjoin/META-INF/resources/assets/logincfg.json\n</code></pre></p> </li> <li> <p>On MacOS, you need to launch the application manually from a terminal, otherwise the working directory is <code>/</code> which does not allow to store the config. The executable of the application is by default located at <pre><code>/Applications/Dashjoin.app/Contents/MacOS/Dashjoin\n</code></pre></p> </li> </ul>"},{"location":"administration/#dashjoin-container","title":"Dashjoin container","text":"<p>The current working directory in the container is <code>/deployments</code>. Use the Docker -v option to mount logincfg.json to <code>/deployments/META-INF/resources/assets/logincfg.json</code></p> <p>Command Line Example: <pre><code>docker run --rm -p 8080:8080 -v /my/path/to/logincfg.json:/deployments/META-INF/resources/assets/logincfg.json:ro dashjoin/platform\n</code></pre></p> <ul> <li>Dashjoin PaaS Cloud</li> </ul> <p>please send an email to request the change.</p>"},{"location":"administration/#minimalistic-logincfgjson-customization-example","title":"Minimalistic logincfg.json customization example","text":"<p>The following example disables all OpenID providers, disables password reset, and disables user registration. Also it re-defines the displayed texts.</p> <p>Note: all settings not specified will use their defaults (see above).</p> <pre><code>{\n    \"signInTabText\": \"My New Demo App\",\n    \"signInCardTitleText\": \"Enter Your Credentials\",\n    \"registrationEnabled\": false,\n    \"resetPasswordEnabled\": false,\n    \"providers\": \"\"\n}\n</code></pre> <p>With this config the login dialog will look similar to this:</p> <p></p>"},{"location":"administration/#query-performance","title":"Query Performance","text":"<p>When hooking up large databases, you might have to perform some performance tuning in order for the platform to scale. The query performance page (/table/config/dj-query-performance) is linked from the main database page and helps you with this task. It shows recent query statistics in a table. The columns are defined as follows:</p> <ul> <li>query: shows the query that was run along with the database prefixed</li> <li>type: </li> <li>key: determining possible foreign key autocomplete values</li> <li>search: the toolbar search </li> <li>query: the query editor, tables or charts</li> <li>all: the all records table view</li> <li>read: read from an instance page</li> <li>update: update from an instance page </li> <li>create: create from a table page or the upload feature</li> <li>delete: delete from an instance page or the upload feature</li> <li>lastRun: the time the query was last run</li> <li>count: how often was the query run</li> <li>errorCount: of these, how often did an error occur (e.g. a timeout)</li> <li>lastError: the last error message</li> <li>totalTimeMs: the runtime in milliseconds all query runs took combined</li> <li>lastTimeoutMs: optional timeout set for the last run</li> <li>lastLimit: optional limit set for the last run (does not include limits in the query)</li> <li>averageTimeMs: the average time a query evaluation took in milliseconds</li> </ul> <p>The table helps you to identify queries with long runtimes. Possible remedies are:</p>"},{"location":"administration/#creating-database-indices","title":"Creating Database Indices","text":"<p>All key columns should be indexed in the database in order to avoid full table sweeps when a record is accessed by its key.</p>"},{"location":"administration/#specific-search-queries","title":"Specific Search Queries","text":"<p>By default, Dashjoin will perform searches on all database tables which can be a very costly operation. If a database contains more data, you can either opt out of it being searched, or you can associate a query from the catalog to be used. For instance, you might want employees to be searchable by firstname or lastname, but other tables are not relevant for searches. In this case, you can define the following query:</p> <pre><code>select ID, NAME \nfrom EMP \nwhere NAME like concat(${search}, '%')\n</code></pre> <p>You can also use union queries to search over multiple tables. Note that in this case, the query needs to project table, id, match:</p> <pre><code>select 'EMP', ID, NAME from EMP where NAME=${search}\nunion \nselect 'PRJ', ID, NAME from PRJ where NAME=${search}\n</code></pre> <p>Note that the query must have a single parameter \"search\" in order to be used this way. The platform will run this query by replacing the search parameter with the contents of the search field.</p>"},{"location":"administration/#excluding-tables-and-databases-from-searches","title":"Excluding Tables and Databases from Searches","text":"<p>Besides custom queries, you can also entirely exclude databases and tables from searches using the system configuration page (/table/config/dj-config).</p>"},{"location":"administration/#prioritizing-results","title":"Prioritizing Results","text":"<p>Using the configuration setting \"prioritize-table-in-search\", you can instruct the system which tables are to be searched first. Results from these tables will appear further up in the search results.</p>"},{"location":"administration/#global-timeout-settings","title":"Global Timeout Settings","text":"<p>Finally, the system configuration page allows setting some global contraints that prevent \"rogue\" queries to deteriorate the overall system and database performance. Please see the descriptions on the system configuration page (/table/config/dj-config) for more details.</p>"},{"location":"administration/#ui-customizations","title":"UI Customizations","text":"<p>The system configuration page (/table/config/dj-config) allows defining some UI settings that are applied globally to all UI pages. The settings allow controlling the following aspects of the UI:</p> <ul> <li>homepage: Application home page that is displayed when home is pressed and after login</li> <li>on-login: Expression to be evaluated upon login - it typically sets session variables via setVariable</li> <li>sidenav-open: Side navigation is open initially (changes applied after next login)</li> <li>dark-theme    : Theme settings (see https://marmelab.com/react-admin/AppTheme.html#writing-a-custom-theme) - example: to change the primary color to blue, set the key palette.primary.main to #0000FF</li> <li>sidenav-width-px: Width of the side navigation bar (changes applied after next login)</li> <li>theme: Theme settings (see https://marmelab.com/react-admin/AppTheme.html#writing-a-custom-theme) - example: to change the primary color to blue, set the key palette.primary.main to #0000FF</li> <li>allow-dark-mode: Show the dark mode icon in the toolbar</li> <li>logo-url: URL of the logo to display in the toolbar</li> </ul> <p>Note that these customizations can be overwritten or applied to roles also. If you'd like to change the homepage for role authenticated only, navigate to /config/dj-role/authenticated and in the properties field, enter \"homepage\" and your desired page, e.g. /page/AuthenticatedHome.</p> <p>The customizations can also be applied to an individual OpenID user only via the tenant users table. If you'd like to change the homepage for user joe@example.org, naviage to /config/tenantusers/joe%40example.org and again use the properties field.</p>"},{"location":"administration/#adding-static-assets-to-the-app","title":"Adding static assets to the app","text":"<p>Static assets like images, logos, movies, and other files required by your application can be placed in the <code>/assets</code>folder.</p> <p>The assets are accessible in the running application as <code>http(s)://&lt;app url&gt;/assets</code></p> <p>By definition, access to static assets does not require login, so they are always readable / publically accessible. Do not place any confidential data in the assets folder.</p> <p>When working with version control tools (i.e. git), assets can be maintained along with all other app resources under revision control.</p>"},{"location":"ai-ml-integration/","title":"AI &amp; ML Integration","text":"<p>The Artificial Intelligence and Machine Learning features of the Dashjoin Platform is delivered as a set of Docker containers that package models and external runtime components as well as JSONata functions that make these features usable within any part of an application.</p> <p>The previous developer reference section already lists some of the AI &amp; ML capabilities, however, this section explains the features in more detail and provides a comprehensive overview.</p>"},{"location":"ai-ml-integration/#jsonata-notebooks","title":"JSONata Notebooks","text":"<p>Applying AI &amp; ML functionality usually requires some degree of experimentation.  The JSONata Notebooks provide this flexibility. A notebook is the combination of a page with a single notebook widget. The platform ships with a default notebook available at /page/Notebook. Note that you can create as many notebook pages as you like.</p> <p>A Notebook consists of a sequence of code blocks that can be run individually via the run icon or by pressing CTRL ENTER. The result of the call is also stored in the notebook and displayed below the code block.</p> <p>The default way of displaying data is JSON. You can display the data as a table, on a map, or as a chart using the following syntax:</p> <pre><code>{\n  \"widget\": \"table\",\n  \"data\": $query(\"northwind\", \"group\")\n}\n</code></pre> <pre><code>{\n  \"widget\": \"map\",\n  \"data\": $adHocQuery(\"northwind\", \"select distinct CITY from EMPLOYEES\").\"EMPLOYEES.CITY\"\n}\n</code></pre> <pre><code>{\n  \"widget\": \"chart\",\n  \"chart\": \"bar\",\n  \"data\": $query(\"northwind\", \"group\")\n}\n</code></pre> <p>If a code block starts with a variable assignment ($variable := ...), the variable can be used in other code blocks as $variable.</p> <p>It is possible to upload one or more files into the notebook. This creates new code block, where the variable $upload is set to a map of file name to file content. This variable can be used in other code blocks. Assume you upload a file.txt, then the contents of the file is avaiable as $upload.file_txt. Note that dot is replaced with underscore to avoid having to escape the field name.</p> <p>The code block and its result is saved to the browser session, which is lost if the browser is closed. You can save the current state of the notebook with the save button. This writes the code blocks to the notebook's page and makes the notebook available to other users.</p>"},{"location":"ai-ml-integration/#optical-character-recognition","title":"Optical Character Recognition","text":"<p>The optical character recognition (OCR) functionality is available in the dashjoin/ai-image Docker container. It exposes a REST API on port 8080 where you provide an image URL such as this picture: </p> <p></p> <p>To start the container, run the following command (we use the host port 8083 to avoid  clashing with the platform port):</p> <pre><code>docker run -p 8083:8080 dashjoin/ai-image\n</code></pre> <p>The URL is passed in a GET request https://.../image-ocr?url=... and returns the extracted text:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-ocr?url=https://d207ibygpg2z1x.cloudfront.net/image/upload/v1540973697/articles_upload/content/ibttqvywe6gihhcu1zzf.jpg\")\n)\n</code></pre> <pre><code>\"HEY YOU YES YOU\\n\\nYOU CANDO IT\\n\"\n</code></pre>"},{"location":"ai-ml-integration/#image-classification","title":"Image Classification","text":"<p>The image classification functionality is also available in the dashjoin/ai-image Docker container. It exposes a REST API where you provide an image URL such as this picture of a bird (https://mein-vogelhaus.com/wp-content/uploads/2020/04/Einheimische-Vogelarten-Stieglitz.jpg).</p> <p></p> <p>The URL is passed in a GET request https://.../image-classify?url=... and returns an array of classifications and probabilities:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-classify?url=https://mein-vogelhaus.com/wp-content/uploads/2020/04/Einheimische-Vogelarten-Stieglitz.jpg\")\n).{\"type\": $[1], \"prob\": $[2]}\n</code></pre> <pre><code>[\n  {\n    \"type\": \"goldfinch\",\n    \"prob\": 0.9761154055595398\n  },\n  {\n    \"type\": \"bulbul\",\n    \"prob\": 0.017567412927746773\n  },\n  {\n    \"type\": \"coucal\",\n    \"prob\": 0.0015972057590261102\n  }\n]\n</code></pre>"},{"location":"ai-ml-integration/#face-recognition","title":"Face Recognition","text":"<p>The optical character recognition (OCR) functionality is also available in the dashjoin/ai-image Docker container. It exposes a REST API where you provide an image URL such as this picture:</p> <p></p> <p>The URL is passed in a GET request https://.../image-face?url=... and returns the extracted text along with the coordinates of the face within the image:</p> <pre><code>$parseJson(\n  $openJson(\"http://.../image-face?url=https://media-cldnry.s-nbcnews.com/image/upload/newscms/2020_02/1521975/kristen-welker-today-191221-main-01.jpg\")\n)\n</code></pre> <pre><code>[\n  {\n    \"faceid\": \"Kristen Welker\",\n    \"top\": 206,\n    \"left\": 705,\n    \"bottom\": 527,\n    \"right\": 1026\n  }\n]\n</code></pre>"},{"location":"ai-ml-integration/#text-translation","title":"Text Translation","text":"<p>The translation services base on a large language model and are available via REST API in the dashjoin/ai-translation container. You can start the container using the following command (the REST service runs on port 8080, we use 8084 to avoid port collisions):</p> <pre><code>docker run -p 8084:8080 dashjoin/ai-translation\n</code></pre> <p>The OpenAPI specification can be accessed at  http://.../docs. It offers a number of services, which the most important ones being \"translate\" and \"language_detection\".  Translate takes the following parameters:</p> <ul> <li>target_lang: the code of the language, the text is supposed to be translated to</li> <li>text: an array of strings with the original text to be translated</li> <li>source_lang: code of the language, text is written in</li> <li>beam_size: can be used to trade-off translation time and search accuracy</li> <li>perform_sentence_splitting: determines whether the sentences are split into a string array</li> </ul> <pre><code>$openJson(\"http://.../translate?target_lang=de&amp;text=This%20is%20an%20awesome%20translation%20service\")\n</code></pre> <pre><code>{\n  \"target_lang\": \"de\",\n  \"source_lang\": null,\n  \"detected_langs\": [\n    \"en\"\n  ],\n  \"translated\": [\n    \"Das ist ein toller \u00dcbersetzungsdienst\"\n  ],\n  \"translation_time\": 3.5702028274536133\n}\n</code></pre> <p>Language detection takes a single text parameter with the sample text and works as follows:</p> <pre><code>$openJson(\"http://.../language_detection?text=example\")\n</code></pre> <pre><code>\"en\"\n</code></pre>"},{"location":"ai-ml-integration/#large-language-model","title":"Large Language Model","text":"<p>The chat and instruction functionality is available in the dashjoin/ai-llm container. To start it, you need to mount your language model (e.g. the popular llama model)  and a configuration into the container as follows. The file ts_server.cfg determines important parameters:</p> <pre><code>{\n  log_filename: \"ts_server.log\",\n  /* if true, enable GPU usage */\n  //  cuda: true,\n  /* cuda device index, use it if multiple GPUs */\n  //  device_index: 0,\n\n  /* maximum number of threads, only matters when running on CPU */\n  n_threads: 1,\n\n  /* models to load. 'name' is the identifier used in the JSON\n     request. 'filename' is the file containing the model description\n   */\n  models: [\n    { name: \"djmodel\",  filename: \"/opt/dashjoin/ai/model.bin\" },\n  ],\n  local_port: 8080, /* port on which the server listen to */\n  log_start: true, /* print \"Started.\" when the server is ready */\n  gui: true, /* start a simple GUI when exploring the root path\n               (e.g. http://localhost:8080 here) (default = false) */\n}\n</code></pre> <p>Start the docker container as follows:</p> <pre><code>docker run \n    -p 8080:8080 \n    -v $PWD/ts_server.cfg:/opt/dashjoin/ai/ts_server.cfg\n    -v $PWD/my_model.bin:/opt/dashjoin/ai/model.bin \\\n    dashjoin/ai-llm\n</code></pre> <p>To test the language model, create the following JSONata function (note that /model/ in the URL selects the  model key in the config file, also note that you can deploy multiple models into the container):</p> <pre><code>{\n    \"djClassName\": \"org.dashjoin.function.RestJson\",\n    \"ID\": \"dashjoin-llm\",\n    \"type\": \"read\",\n    \"method\": \"POST\",\n    \"contentType\": \"application/json\",\n    \"url\": \"http://.../v1/engines/djmodel/completions\",\n    \"returnText\": true\n}\n</code></pre> <p>To call the function use:</p> <pre><code>$parseJson(\"[\" &amp; $replace($call(\"dashjoin-llm\", {\n  \"prompt\": \"Game of Thrones is\",\n  \"temperature\": 1,\n  \"top_k\": 40,\n  \"top_p\": 0.9,\n  \"max_tokens\": 200,\n  \"stream\": true,\n  \"stop\": null\n}), /\\}\\s*\\{/, \"},{\") &amp; \"]\")\n</code></pre> <p>The result is a stream of concatenated JSON. $call returns this stream as a string. The example uses JSONata regular expressions to convert this into a proper JSON array of objects before parsing it via $parseJson.</p> <pre><code>[\n  ...\n  {\"text\":\" the things I liked about the show and thought\",\"reached_end\":false},\n  {\"text\":\" everyone else should be able to see. But\",\"reached_end\":false},\n  {\"text\":\" it\u2019s also, in many\",\"reached_end\":false},\n  {\"text\":\" ways, kind of\",\"reached_end\":true,\"input_tokens\":4,\"output_tokens\":200},\n]\n</code></pre>"},{"location":"ai-ml-integration/#entity-reconciliation","title":"Entity Reconciliation","text":"<p>When integrating data from different sources, entity reconciliation describes the process of aligning different identifiers for the same entity that are used across the various sources.</p> <p>There are various approaches that can be applied. In this section, we describe the reconcileEntity JSONata function. It uses the Wikidata search API in order to reconcile a text with a standardized Wikidata ID. Wikidata is the database equivalent of Wikipedia, i.e. it is a crowd-sourced database of entites that can also be found in wikipedia. Consequently this function should not be used if the texts are very specific or if the texts are unsuitable to be sent to a 3rd party service.</p> <p>The function takes three parameters:</p> <ul> <li>entity: the entity string</li> <li>entity-language: the optional language of the entity string (default is en)</li> <li>limit: the number of ranked search results (default is 1)</li> </ul> <p>Consider the reconciliation results for \"Apple\". The term is ambiguous since it can refer to Apple the fruit and Apple, the tech company.</p> <pre><code>$reconcileEntity(\"Apple\", \"en\", 2)\n</code></pre> <pre><code>[\n  {\n    \"id\": \"Q89\",\n    \"label\": \"apple\",\n    \"description\": \"fruit of the apple tree\"\n  },\n  {\n    \"id\": \"Q312\",\n    \"label\": \"Apple\",\n    \"description\": \"American multinational technology company\"\n  }\n]\n</code></pre> <p>Note that the most likely match comes first. If the call is repeated with \"Apple Inc.\", the Wikidata ID Q312 is the first result.</p>"},{"location":"ai-ml-integration/#entity-classification","title":"Entity Classification","text":"<p>When examining an unknown datasource, it is useful to generate a classification of the values found in a column. This functionality is offered by the classifyEntities function.</p> <p>This function extends reconcileEntity by also querying the Wikidata categories. Given a list of entities, this function retrieves the Wikidata types and returns all types that are common for all entities. This function has the following parameters:</p> <ul> <li>entities: the list of entity strings</li> <li>entity-language: the optional language of the entity string (default is en)</li> <li>limit: the number of ranked search results (default is 1)</li> <li>subclass-depth: this number indicates whether superclasses of Wikidata classes should be included (default is 1). Given depth 1, \"Gone with the wind\" would be classified as a movie. A movie is also a piece of art. Therefore, piece of art would be another potential classification tested with the other entities.</li> </ul> <p>Consider this example. This call tries to find a common classification for \"Unicef\" and \"Apple\". The search limit must be set to 2 in order to get Apple the company and the fruit. Both of these are classified as organizations.</p> <pre><code>$classifyEntities([\"Apple\", \"Unicef\"], null, 2, 0)\n</code></pre> <pre><code>[\n  \"organization\"\n]\n</code></pre> <p>If the call is repeated with IBM instead of Unicef, the results are business, enterprise, public company, and technology company.</p>"},{"location":"ai-ml-integration/#text-distance-and-soundex-similarity","title":"Text Distance and Soundex Similarity","text":"<p>When matching entities, text similarity and distance metrics can also be useful. Consider an example where many different sources include company names. When matching these names, typical problems arise from simple typos and different spellings (\"Apple\" vs. \"Apple Inc.\").</p> <p>Similarity and distance metrics can be useful in these circumstances. Given two sets of strings, the synonym function allows applying these metrics. It returns a list of matches that can be used as a synonym lookup table. Hence the name. It takes the following parameters:</p> <ul> <li>algorithms: A map of algorithm name to limit determining whether to include a term / variant pair. The algorithm names can be chosen from this list. Alternatively, you can use \"SoundexSimilarity\"</li> <li>terms: A list of names to test against all variants</li> <li>variants: A list of names to test against all terms</li> <li>ignoreCase: ignore case when computing the distance (defaults to false)</li> <li>ignoreEquality: include term / variant pairs that are equal in the result</li> </ul> <p>The soundex similarity is higher for a pair of strings that sound similar in the english language:</p> <pre><code>$synonym({\"SoundexSimilarity\":2}, [\"roast\"], [\"ghost\", \"boast\", \"hello\"])\n</code></pre> <pre><code>[\n  {\n    \"synonym\": \"ghost\",\n    \"term\": \"roast\",\n    \"algotithm\": \"SoundexSimilarity\",\n    \"value\": 3\n  },\n  {\n    \"synonym\": \"boast\",\n    \"term\": \"roast\",\n    \"algotithm\": \"SoundexSimilarity\",\n    \"value\": 3\n  }\n]\n</code></pre> <p>Note that the pair \"roast\" and \"hello\" do not sound alike and, therefore, is not included.</p> <p>The Levenshtein Distance calculates the minimal number of edits that is required to transform one string into the other. The smaller this number, the more similar the strings are. This is a good metric to match strings despite typos. Compared to apple, apples is included with a limit of 1, appl is too different and is not included.</p> <pre><code>$synonym({\"LevenshteinDistance\": 1}, [\"apple\"], [\"apples\", \"appl\"])\n</code></pre> <pre><code>[\n  {\n    \"synonym\": \"apples\",\n    \"term\": \"apple\",\n    \"algotithm\": \"LevenshteinDistance\",\n    \"value\": 1\n  },\n  {\n    \"synonym\": \"appl\",\n    \"term\": \"apple\",\n    \"algotithm\": \"LevenshteinDistance\",\n    \"value\": 1\n  }\n]\n</code></pre>"},{"location":"api/","title":"API","text":"<p>This section is comprised of two parts. First, we look at the API that ships with the Dashjoin platform. Second, we highlight how you can build APIs as part of your app.</p>"},{"location":"api/#platform-api","title":"Platform API","text":"<p>The Dashjoin architecture features an Angular Single Page Application (SPA) that is driven by RESTful APIs. The APIs support the OpenAPI standard. The OpenAPI description is available at https://demo.my.dashjoin.com/openapi. Dashjoin also ships the Swagger GUI at https://demo.my.dashjoin.com/swagger-ui. Please note that the API is subject to change.</p>"},{"location":"api/#authentication","title":"Authentication","text":"<p>The API requires any request using a local admin user to be authenticated with HTTP basic authentication:</p> <pre><code>curl -u admin:djdjdj http://localhost:8080/rest/manage/version\n</code></pre> <p>In order to login using an OpenID user, you need to specify a bearer token as follows:</p> <pre><code>curl -H \"Authorization: Bearer ...\" https://demo.my.dashjoin.com/rest/manage/version\n</code></pre> <p>The easiest way to obtain a bearer token is to login using a browser and copying the token via the browser development tools. Depending on your OpenID provider, a bearer token can also be obtained via a seperate login call.</p> <p>In addition to the API, it is possible to create custom function and database microservices and use them via the RestJson function and RemoteDatabase clients. For more information, please refer to the dashjoin-sdk module documentation.</p>"},{"location":"api/#jsonapi","title":"JSON:API","text":"<p>Dashjoin supports JSON:API for read operations.  JSON:API describes how clients should request or edit data from a server, and how the server should respond to said requests. The endpoint is available under /rest/jsonapi.</p>"},{"location":"api/#odata","title":"OData","text":"<p>Dashjoin also supports OData for read operations.  OData (Open Data Protocol) is an ISO/IEC approved, OASIS standard that defines a set of best practices for building and consuming RESTful APIs. The endpoint is available under /rest/odata.</p>"},{"location":"api/#pdf-export","title":"PDF Export","text":"<p>Any platform page can be exported to PDF using the puppeteer framework. For your convenience, we deployed a cloud function to do this for any installation available on the web. Please note that your credentials and the PDF content are sent via this third party if you use this function:</p> <pre><code>curl -X POST https://europe-west1-djfire-1946d.cloudfunctions.net/exportPdf --output cloudfunction.pdf -H \"Content-Type:application/json\" -d '{\n    \"url\": \"https://demo.my.dashjoin.com/#/page/html-Dashboard2\",\n    \"username\": \"...\",\n    \"password\": \"...\",\n    \"pdfOptions\": {\n        \"format\": \"a4\",\n        \"landscape\": true\n    },\n    \"toggleNavBar\": true\n}'\n</code></pre> <p>Alternatively, you can use a bearer token in the \"authentication\" field instead of user name and password.</p>"},{"location":"api/#app-api","title":"App API","text":"<p>Apart from building user interfaces, the Dashjoin platform can also be used to develop, document, and deploy APIs based on the OpenAPI standard. The platform provides generic APIs to read and write tables, run queries, and execute functions. In this context, generic means that a new function \"myfunction\" does not show up in the API definition. Its name can rather can be used as parameter in the execute function API. Using the App API concept, this pattern can be changed and \"myfunction\" can be exposed as an individual API. This makes it easier for developers to document APIs and expose them to clients.</p>"},{"location":"api/#documenting-an-existing-app","title":"Documenting an Existing App","text":"<p>In the first use case, we assume that there already is an existing Dashjoin App. It works using the UI and the developer would now like to expose parts of this app via OpenAPI.</p> <p>Consider the following example. The app contains a simple invoke function that computes \"{\"result\": x+y}\" and this function should be exposed as an OpenAPI REST service.</p> <p>First, you need to create an OpenAPI skeleton description and place it into the app's upload folder, e.g. at upload/openapi.yaml:</p> <pre><code>openapi: \"3.0.3\"\ninfo:\n  version: \"1\"\n  title: \"test\"\nx-dashjoin:\n  functions:\n  - add\nsecurity:\n- Basic_Auth: []\ncomponents:\n  securitySchemes:\n    Basic_Auth:\n      type: \"http\"\n      scheme: \"basic\"\n</code></pre> <p>This specification is written in YAML and contains some basic metadata about the API version and description. It also specifies that clients can connect using HTTP basic authentication. Please note that you can author these specifications using this online editor. The SwaggerHub offering also allows you to save the specs in the cloud. See the dashjoin repository and the raw YAML spec.</p> <p>In the \"x-dashjoin\" section, we specify that the function \"add\" is to be added to the API. Normally, the API path, schema, response types, etc. would have to be added. In our case, the Dashjoin platform generates that into this template.</p> <p>Once this file is saved, follow these steps:</p> <ul> <li>Connect the template with the platform, by adding \"url\": \"file:upload/openapi.yaml\" to the \"openapi\" system configuration setting (/#/resource/config/dj-config/openapi)</li> <li>Open the platform Swagger-UI (/swagger-ui/)</li> <li>In the text field at the top, change \"/openapi\" to \"/rest/manage/openapi\"</li> <li>Authorize using your credentials</li> <li>Test the service by sending this JSON payload: {\"x\":1, \"y\": 2}</li> </ul> <p>Apart from functions, you can also publish queries and schemas. Queries work just like functions. Schemas can be derived from tables known to the system. To include these in the App API, you can use these keywords in the OpenAPI template:</p> <pre><code>x-dashjoin:\n  functions:\n  - add\n  queries:\n  - group\n  schemas:\n  - dj/northwind/US_STATES\n</code></pre> <p>Unfortunately, it might not be clear to clients, that the request is expected to be an object containing the keys x and y. In order to make this clear, we can either provide a more description JSON Schema for the request object or we can provide a descriptive example. You can add the following fragment to the OpenAPI description:</p> <pre><code>paths:\n  /rest/function/add:\n    post:\n      operationId: \"add\"\n      requestBody:\n        content:\n          application/json:\n            schema:\n              example:\n                x: 1\n                y: 2\n</code></pre> <p>This YAML tree structure will be merged with the one generated by the Dashjoin platform. Specifically, the example key will be merged providing clear documentation on how to call the service.</p> <p>The OpenAPI specification can be accessed without credentials. If credentials are provided (e.g. via curl http://admin:djdjdj@localhost:8080/rest/manage/openapi), the platform also generates result set metadata for the queries. For instance, if the group query in the Dashjoin Demo App is included, the following OpenAPI path response is generated:</p> <pre><code>  responses:\n    \"200\":\n      content:\n        application/json:\n          schema:\n            type: \"array\"\n            items:\n              type: \"object\"\n              properties:\n                COUNTRY:\n                  type: \"string\"\n                  x-dbType: \"CHARACTER VARYING\"\n                Number of Customers:\n                  x-dbType: \"BIGINT\"\n      description: \"group response\"\n</code></pre>"},{"location":"api/#implementing-an-existing-openapi-specification","title":"Implementing an existing OpenAPI Specification","text":"<p>The second use case highlights a scenario where we work in an API centric fashion. This means that the OpenAPI spec is designed first instead of being generated from existing code.</p> <p>As an example, we will implement the Petstore example that is featured in the Swagger Editor. Simply select \"Save as YAML\" and place the file in \"upload/petstore.yaml\". Then, change the openapi config (/#/resource/config/dj-config/openapi) to \"url\": \"file:upload/petstore.yaml\".</p>"},{"location":"api/#creating-tables","title":"Creating Tables","text":"<p>The Petstore API defines several data structures such as Pet, User, etc. Not all of them necessarily need to be mapped to tables. The Address structure for example, merely defines a complex column in the table customer. Since OpenAPI schemas usually contain nested types and arrays, we should choose a database that supports these datatypes. For this example, we'll use a Postgres DB that is registered under the name \"postgres\".</p> <p>The platform offers an API that allows creating a table directly from the OpenAPI spec. Note that the first property is assumed to be the primary key. We'll create the Pet table using this curl command:</p> <pre><code>curl -X 'POST' \\\n  'http://localhost:8080/rest/manage/createTable/postgres' \\\n  -H 'accept: */*' \\\n  -H 'Authorization: Basic YWRtaW46ZGpkamRq' \\\n  -H 'Content-Type: text/plain' \\\n  -d 'Pet'\n</code></pre> <p>Once you update the database to trigger the table scan, the Pet table shows up. Note that nested types and arrays get converted to jsonb columns.</p>"},{"location":"api/#creating-function-stubs","title":"Creating Function Stubs","text":"<p>Next, we'll create function stubs from the OpenAPI spec. This functionality is also available on the platform API:</p> <pre><code>curl http://admin:djdjdj@localhost:8080/rest/manage/createStubs\n</code></pre> <p>This creates an invoke function that simply echos the input for each operation in the spec. The name of the function is the  value of the OpenAPI operationId.</p>"},{"location":"api/#testing-a-stub","title":"Testing a Stub","text":"<p>Before we can test a generated function stub, we need to change the value of the server field. This field provides options for the  APIs to be tested from the Swagger UI. We set this value to:</p> <pre><code>servers:\n  - url: /rest/app\n</code></pre> <p>The endpoint /rest/app is a generic API handler that delegates incoming calls to the appropriate function.</p> <p>The Petstore example comes with open authentication and API key authentication. For simplicity, we'll add basic authentication:</p> <pre><code>  securitySchemes:\n    Basic_Auth:\n      type: \"http\"\n      scheme: \"basic\"\n</code></pre> <p>We'll implement the addPet and getPetById calls. So you'll have to allow basic authentication with these calls by adding:</p> <pre><code>  /pet/{petId}:\n      ...\n      security:\n        - Basic_Auth: []\n        - api_key: []\n        - petstore_auth:\n            - write:pets\n            - read:pets\n</code></pre> <pre><code>  /pet:\n    put:\n      ...\n    post:\n      ...\n      security:\n        - Basic_Auth: []\n        - petstore_auth:\n            - write:pets\n            - read:pets\n</code></pre> <p>Now you can reload the Swagger UI with the OpenAPI spec at /rest/manage/openapi, login using basic authentication, and test the find pet by ID call with petId 123. The resulting JSON is:</p> <pre><code>{\n  \"parameters\": {\n    \"petId\": \"123\"\n  },\n  \"body\": null\n}\n</code></pre> <p>Likewise, the result of the addPet call - using the sample parameters provided - is:</p> <pre><code>{\n  \"parameters\": null,\n  \"body\": {\n    \"id\": 10,\n    \"name\": \"doggie\",\n    \"category\": {\n      \"id\": 1,\n      \"name\": \"Dogs\"\n    },\n    \"photoUrls\": [\n      \"string\"\n    ],\n    \"tags\": [\n      {\n        \"id\": 0,\n        \"name\": \"string\"\n      }\n    ],\n    \"status\": \"available\"\n  }\n}\n</code></pre> <p>You can see that the generic API handler always passes an object to the function. This object contains the keys parameters and body. Parameters contains all path, query, cookie, and header parameters defined. The body optionally contains the JSON payload.</p>"},{"location":"api/#implementing-the-functions","title":"Implementing the Functions","text":"<p>Using the JSONata functions, we can now implement the functions. AddPet can be handled with this expression:</p> <pre><code>(\n  $echo($);\n  $create(\"postgres\", \"Pet\", body);\n  body;\n)\n</code></pre> <p>First we echo the object passed to the function so we can trace the call on the log. Since the structure of the body matches the JSON schema that was used to generate the table, we can pass it one to one. Finally, we return the body since that is expected by the OpenAPI specification.</p> <p>The find pet by ID call is also very simple:</p> <pre><code>$read(\"postgres\", \"Pet\", parameters.petId)\n</code></pre>"},{"location":"api/#contributing-to-an-existing-openapi-specification","title":"Contributing to an existing OpenAPI Specification","text":"<p>The third use case extends both the first and second use case. We assume you're working in an API centric fashion, however,  parts of the spec should be derived from existing systems. Typically, there's a strong correlation between schemas and existing databases, so we'll extend the petstore example with a schema generated from the northwind sample database.</p> <p>First, we'll need to indicate that a certain table should be added to the OpenAPI spec:</p> <pre><code>x-dashjoin:\n  schemas:\n  - dj/northwind/US_STATES\n</code></pre> <p>This makes the schema for US_STATES appear in the spec. Note that the schema is marked with the flag x-generated=true. Currently, the extended spec is only available via the platform. Therefore, we can export it using another API call:</p> <pre><code>http://admin:djdjdj@localhost:8080/rest/manage/saveapi\n</code></pre> <p>Since we configured the OpenAPI spec to be read from a file URL, the system updates the file to include the new schema, making it available for other tooling. In case the database schema is updated, e.g. another column is added, this process can be repeated. The x-generated flag makes sure that updates on the database are reflected, despite the schema already being present in the file.</p>"},{"location":"api/#swaggerhub-integration","title":"SwaggerHub Integration","text":"<p>SwaggerHub is a popular tool for authoring and managing your APIs. Consequently, instead of using a file URL, we allow using a SwaggerHub URL. In order to have the platform authenticate against the SwaggerHub API, you must generated an API key and provide it in the openapi system configuration:</p> <pre><code>{\n    \"ID\": \"openapi\",\n    \"map\": {\n        \"url\": \"https://api.swaggerhub.com/apis/[ORG-NAME]/[API-NAME]/[VERSION]/swagger.yaml\",\n        \"apiKey\": \"...\"\n    }\n}\n</code></pre> <p>In this case the save operation adds generated fragments to this specific API version.</p>"},{"location":"concepts/","title":"Concepts","text":"<p>Before we dive into the user guide for the platform, this section explains a couple of key concepts.</p>"},{"location":"concepts/#data-model","title":"Data Model","text":"<p>The Dashjoin low code platform sits on top of one or more databases. These databases can be empty, ready to store application data, or they can contain an existing schema and data, possibly under the control of other software and systems. Dashjoin connects to these databases and maps the data using coordinates for each data record:</p>"},{"location":"concepts/#record-coordinates","title":"Record Coordinates","text":"<ol> <li>Dashjoin: The first coordinate is the ID of the Dashjoin installation that accesses the database.</li> <li>Database: The unique name of the database containing the record.</li> <li>Table: The table name (unique within the database) of the table containing the record.</li> <li>Record key(s): The unique ID of the record within its table. This might be a list of keys if we are dealing with composite keys, for instance in a relational database.</li> </ol> <p>These coordinates (DJ, DB, TABLE, PK) translate to RESTful URLs:</p> <ul> <li>Visualizing a record: <code>https://dashjoin.host.name/#/resource/DB/TABLE/PK</code></li> <li>API access to the record: <code>https://dashjoin.host.name/rest/database/crud/DB/TABLE/PK</code></li> </ul>"},{"location":"concepts/#tables-and-columns","title":"Tables and Columns","text":"<p>Dashjoin organizes data in tables and columns. Columns can be of simple types such as strings, integers, etc., but they can also be complex JSON documents. Therefore, Dashjoin is able to connect to multiple kinds of databases. Each of these drivers aligns the database specific nomenclature to the common data model. Therefore a document database's collections become tables, the documents become records and the document fields become columns.</p>"},{"location":"concepts/#primary-and-foreign-keys","title":"Primary and Foreign Keys","text":"<p>Each table usually defines one or more primary key columns that uniquely define each record in the table. In addition, there can be foreign keys in a table that reference another table. This information is crucial for Dashjoin, since it is used to automatically display hyperlinks between records.</p> <p>Usually the key information is extracted from the databases by the drivers. However, some databases do not allow for expressing foreign key information. In this case, the information can be added to the Dashjoin metadata by the user. This mechanism even allows setting foreign key relationships between databases and even from one Dashjoin system to another. This does not enable you to run a federated query like you would within a single SQL database. However, Dashjoin uses this metadata to hyperlink records between databases and logical Dashjoin installations.</p>"},{"location":"concepts/#table-and-instance-layout-and-navigation","title":"Table and Instance Layout and Navigation","text":"<p>The Dashjoin user interface concept is inspired by the Semantic MediaWiki. The database is thought of as a large linked data cloud. Dashjoin user interface pages can be one of the following types:</p> <ol> <li>Record page: Assume the user navigates to the page /resource/DB/TABLE/PK. The system displays a page that corresponds to this record.</li> <li>Table page: Assume the user navigates to the page /table/DB/TABLE. The system displays a page that corresponds to this concept / table.</li> <li>Dashboard page: Assume the user navigates to the page /page/Page. The system displays this page which has no direct related context in the database.</li> </ol> <p>Unless the low code developer specifies otherwise, table and record pages are displayed as follows:</p>"},{"location":"concepts/#default-table-layout","title":"Default Table Layout","text":"<p>Table pages show</p> <ul> <li>a pageable and sortable data table</li> <li>a form to create a new record</li> <li>if you are in the admin role, controls to edit the table schema and metadata</li> </ul> <p>Within the data table, any primary or foreign key field links to the corresponding record page,</p>"},{"location":"concepts/#default-record-layout","title":"Default Record Layout","text":"<p>Record pages show</p> <ul> <li>a form to edit the record</li> <li>a delete button</li> <li>a link back to the table page</li> <li>links to any related record (this can either a foreign key field of the record or records in other tables containing foreign key references to this record's primary key)</li> </ul> <p>The default layout allows the user to easily navigate the data regardless of which specific database it is located in.</p>"},{"location":"concepts/#widgets-and-custom-layouts","title":"Widgets and Custom Layouts","text":"<p>For each table, the default table and instance layout can be adapted. A layout is a hierarchy of widgets. Widgets that contain other widgets are called containers. Every widget has a couple of properties. The chart widget for example, defines which query to visualize.</p>"},{"location":"concepts/#schema-metadata","title":"Schema Metadata","text":"<p>We already mentioned that a developer can define foreign key relationships, even if the underlying database does not support this concept. Dashjoin allows a number of information to be entered about databases, tables, and columns. This data is usually called metadata. Dashjoin stores this metadata in the built-in configuration database, but this database behaves just like any other database. Therefore, each database and table are records and their pages behave just like any other page in the system.</p>"},{"location":"concepts/#interacting-with-the-system","title":"Interacting with the System","text":"<p>So far, we mostly looked at the way Dashjoin organizes and especially how it visualizes information. This section describes how an application interacts and changes the underlying systems in other ways.</p>"},{"location":"concepts/#create-read-update-delete-crud","title":"Create, Read, Update, Delete (CRUD)","text":"<p>A database driver usually exposes CRUD operations to the platform. These operations are used to display data but also to make changes from the forms displayed in the default layout. Note that, unless configured otherwise, the form shows an edit element for all columns.</p>"},{"location":"concepts/#running-queries","title":"Running Queries","text":"<p>Besides simple read and browse operations, the underlying databases usually have the ability to run powerful queries. Dashjoin allows the developer to design such queries and save them in the query catalog consumption. These queries usually drive table and chart displays on customized layout pages and dashboards. Note that queries can also be used to run delete or update operations nd that they can also be parameterized.</p>"},{"location":"concepts/#executing-functions","title":"Executing Functions","text":"<p>Apart from changing data in databases, Dashjoin can call functions on the backend. You can think of a function as a small pre-built and configurable service. Examples for function types are sending email or making a REST call. These can be instantiated in a system as \"sendGmail\" and \"getStockPrice\" by using the function type and providing the required configuration. These functions can then be used by active page elements such as buttons.</p>"},{"location":"concepts/#evaluating-expressions","title":"Evaluating Expressions","text":"<p>Expressions are small programs that can be used to configure widgets on a page. The display widget for instance can display texts on the UI. The text to display is computed by an expression. This expression can for instance call the stock market function on the backend, and do some additional JSON transformation on the results before displaying the data.</p> <p>You can think of the expressions being the glue between widgets on the top and queries, CRUD and functions on the backend:</p> Widget Expression CRUDFunctionQuery"},{"location":"concepts/#expressions","title":"Expressions","text":"<p>Expressions are small programs that can be used to:</p> <ul> <li>configure widgets on a page (the most common case)</li> <li>save an expression with an Invoke function</li> <li>attach triggers to database tables</li> </ul> <p>This section describes the expression language's syntax and semantics are well as the built-in Dashjoin keywords.</p>"},{"location":"concepts/#jsonata","title":"JSONata","text":"<p>Expressions use the well established JSON query and transformation language JSONata. The JSONata exerciser shows three sections:</p> <ul> <li>the context data (this usually is the record you are browsing on the user interface)</li> <li>the expression</li> <li>the expression result</li> </ul> <p>The JSONata documentation explains the language, the operators, as well as which built-ins are available.</p>"},{"location":"concepts/#jsonata-in-widgets","title":"JSONata in Widgets","text":"<p>Expressions are provided as widget parameters via the layout editor. The result is used depending on the widget and the expression field. The if parameter, for instance, expects a Boolean value in order to determine whether to show the widget or not. The display widget simply displays the expression result. Consult the widget reference for information about your use case.</p> <p>Every time an expression is evaluated (e.g. by pressing a button or in order to render a display widget), a context is passed to this expression for processing. This section describes what this context looks like under different circumstances.</p>"},{"location":"concepts/#record-page-context","title":"Record Page Context","text":"<p>If expressions are run on a record page, the context is structured as follows:</p> <pre><code>{\n  database: the database the record is in\n  table: the table the record is in\n  pk1, ..., pk4: the (composite) key(s) of the record\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  href: the current URL\n  value: the current record\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below) \n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#table-page-context","title":"Table Page Context","text":"<p>On table pages, the context looks like this:</p> <pre><code>{\n  database: the database the record is in\n  table: the table the record is in\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  href: the current URL\n  value: schema information of the current table in JSON Schema format\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below)\n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#dashboard-page-context","title":"Dashboard Page Context","text":"<p>Dashboard pages provide the following context:</p> <pre><code>{\n  loc: location information about the current page\n  user: the ID of the user that's currently logged in\n  roles: the roles the user is in\n  email: the user's email address (not set for local users)\n  href: the current URL\n  variable: the session variables (see below)\n  form: data entered via a form (see below)\n  selected: selected table rows if used in an action table (see below) \n  context: result of the expression in the map / markdown widgets (see below)\n}\n</code></pre>"},{"location":"concepts/#session-variable-context","title":"Session Variable Context","text":"<p>The user interface can store variables per browser tab. Note that these variables are lost once the tab is closed or the user logs out of Dashjoin. A variable can be set from any expression using the \"setVariable\" JSONata function. Therefore, calling setVariable(\"x\", 1) will cause the expression context to be:</p> <pre><code>{\n  ...\n  \"variable\": {\n    \"x\": 1\n  }\n}\n</code></pre>"},{"location":"concepts/#form-context","title":"Form Context","text":"<p>Several widgets allow adding form elements (see section \"Form Widgets\" in the next chapter). If a number form element with name \"y\" has the value 2 and the form is submitted, the context is:</p> <pre><code>{\n  ...\n  \"form\": {\n    \"y\": 2\n  }\n}\n</code></pre>"},{"location":"concepts/#action-table-context","title":"Action Table Context","text":"<p>The action table allows selecting rows from a table. If a table action us run, these rows are added to the context as follows:</p> <pre><code>{\n  ...\n  \"selected\": [\n    selected row 1,\n    ...\n    selected row n\n  ]\n}\n</code></pre>"},{"location":"concepts/#html-and-markdown-context","title":"HTML and Markdown Context","text":"<p>The markdown and HTML widgets allow using string template syntax like <code>${a.b}</code> to include values from the context. These widgets allow adding the result of a custom expression to the context which is then passed as:</p> <pre><code>{\n  ...\n  \"context\": result of the expression in the map / markdown widgets\n}\n</code></pre>"},{"location":"concepts/#jsonata-in-invoke-functions","title":"JSONata in Invoke Functions","text":"<p>The Invoke function allows you to wrap an expression as a function. The context is passed as the function parameter and the result is returned to the function caller. Consider the following example of a Invoke function \"geturl\":</p> <pre><code>{\n  \"ID\": \"geturl\",\n  \"djClassName\": \"org.dashjoin.function.Invoke\",\n  \"expression\": \"$openJson($).parse.some.value\"\n}\n</code></pre> <p>This function opens JSON from a URL, performs some computation with the file contents and returns the result. The URL is passed via the context and is referenced via dollar being the parameter of openJson.</p> <p>Now we can call this function as follows:</p> <pre><code>$call(\"geturl\", \"http://example.org/test.json\")\n</code></pre> <p>In this case dollar evaluates to the string \"http://example.org/test.json\".</p>"},{"location":"concepts/#jsonata-in-triggers","title":"JSONata in Triggers","text":"<p>Triggers allow evaluating expression before or after a write operation on a table.</p> <p>In this case, the context is defined as follows:</p> <pre><code>{\n  command: create, update or delete\n  database: CRUD on this DB\n  table: CRUD on this table\n  search: primary keys of the record, set for delete and update\n  object: object to create or fields to update, set for update and create\n}\n</code></pre> <p>The expression is defined with the table.</p> <p>The result is ignored, unless the trigger function extends the AbstractDatabaseTrigger Java interface. In this case, we expect a Boolean value that aborts the write operation in case the value false is returned.</p>"},{"location":"contribute/","title":"Contribute","text":"<p>We welcome contributions. If you are interested in contributing to Dashjoin, let us know! You'll get to know an open-minded and motivated team working together to build the next generation platform.</p> <ul> <li>Join our Slack and say hello</li> <li>Follow us on Twitter</li> <li>Submit your ideas by opening an issue with the enhancement label</li> <li>Help out by fixing \"a good first issue\"</li> </ul>"},{"location":"developer-reference/","title":"Developer Reference","text":""},{"location":"developer-reference/#widget-reference","title":"Widget Reference","text":"<p>The following sections describe the platform widgets and which configuration options are available for them. You can create custom widgets and use them just like platform widgets. Please refer to the section Development / Production. Note that all widgets have the title option:</p> <ul> <li>title: when the widget is a direct child of the page container, the widget is placed in a card with this title</li> </ul> <p>Widgets can be grouped into the following three categories.</p>"},{"location":"developer-reference/#container-widgets","title":"Container Widgets","text":"<p>Container widgets can contain other widgets. All container widgets have features that control under which conditions content is shown or hidden. Please note that these features are enforced on the client and thus can be manipulated by malicious users. Specifically, do not rely on these features to implement security and data privacy. You can safely restrict access on the server side by applying access control to functions, databases, tables, and queries.</p>"},{"location":"developer-reference/#card","title":"card","text":"<p>Layout card with a title and nested widgets:</p> <ul> <li>text: card title</li> <li>roles: show container only if user is in one of these roles</li> </ul>"},{"location":"developer-reference/#container","title":"container","text":"<p>Container with a plain layout</p> <ul> <li>roles: show container only if user is in one of these roles</li> <li>if: show the widget if the expression is true</li> <li>redrawInterval: redraw interval (seconds). Periodically refreshes the container and all contained content.</li> </ul>"},{"location":"developer-reference/#expansion","title":"expansion","text":"<p>Collapsible container with nested widgets</p> <ul> <li>text: card title</li> <li>roles: show container only if user is in one of these roles</li> </ul>"},{"location":"developer-reference/#form-widgets","title":"Form Widgets","text":"<p>Like containers, form widgets allow adding input elements. Every input widget must use a unique name which is in turn used as the key in the resulting JSON structure. Inputs can be of the following type:</p> <ul> <li>boolean: displays an on/off toggle and returns a boolean value</li> <li>string; a regular text box that returns a string</li> <li>number: a number input returning a number</li> <li>auto complete: an input field with auto-complete options (which are generated by a JSONata expression)</li> <li>select: like auto complete, but uses a select widget instead of a text field</li> <li>multi select: like select but allows multiple selections, returns an array</li> <li>key value: allows entering any key value pairs, returns an object</li> <li>password: like string but hides the input</li> <li>textarea: like string but uses a multi-line input</li> <li>date: like string but uses a date picker</li> <li>time: like string but uses a time picker</li> <li>datetime: like string but uses a datetime picker</li> <li>file: like string but uses the content of an uploaded file are the value</li> <li>binary file: like file, but uses base64 encoding</li> <li>file with metadata: like file but includes file metadata</li> <li>binary file with metadata: like binary file but includes file metadata</li> </ul>"},{"location":"developer-reference/#button","title":"button","text":"<p>Runs / evaluates an expression when clicked.</p> <ul> <li>text: text shown for the run button (default is \"Run\")</li> <li>print: evaluates this expression when clicked</li> <li>deleteConfirmation: optional confirmation message before performing the action</li> </ul> <p>The form content (if a form is present), is added to the context using the key \"form\".</p>"},{"location":"developer-reference/#create","title":"create","text":"<p>Creates new database records:</p> <ul> <li>text: text shown for the create button (default is \"Create\")</li> <li>database: optional database to create the record in (defaults to the database of the table you are currently displaying)</li> <li>table: optional table to create the record in (defaults to the table you are currently displaying)</li> </ul>"},{"location":"developer-reference/#edit","title":"edit","text":"<p>allows editing a database record. Note that the form layout can be customized in the layout editor. Please also refer to the FAQ for information on how to further customize the input form.</p> <ul> <li>deleteConfirmation: optional confirmation message before deleting the record</li> </ul>"},{"location":"developer-reference/#variable","title":"variable","text":"<p>Displays a form that allows setting session variables. If a variable \"x\" is defined and set, it can be referenced in other widgets using \"variable.x\". A variable can be set via a URL query parameter. Appending ?a=1&amp;b=test to the URL will set variable.a to \"1\" and variable.b to \"test\". Note that only string variables can be set this way, so you might have to use $number(variable.a) when using the variable.</p> <ul> <li>text: text shown for the apply button (default is \"Apply\")</li> </ul>"},{"location":"developer-reference/#regular-widgets","title":"Regular Widgets","text":""},{"location":"developer-reference/#actiontable","title":"actionTable","text":"<p>The Action table widget works like the table widget. In addition, it allows selecting several rows in the table. If rows are selected, action buttons become visible. The actions are configured via a set of key value pairs. The key specifies the action button's label, the value contains the expression that is run if the button is pressed.</p> <ul> <li>expression: allows configuring the widget data via JSONata which must evaluate to an array of objects. Note that the table is able to display links, images, and lists thereof. Please refer to the display widget for information on how the JSON data must be structured. If omitted, the widget uses $query(database, query, arguments)</li> <li>properties: a set of key value pairs. For every key, an action button with the key used as its label is displayed. When the button is pressed, the JSONata expression specified in the value is run  </li> </ul>"},{"location":"developer-reference/#chart","title":"chart","text":"<p>Chart for visualizing query results.</p> <ul> <li>database: database to run the query on</li> <li>query: query to run; the query is expected to project the following column structure:<ul> <li>label followed by a value column: in this case, a chart with a single series is shown. The first column is used as the series axis label and the second column is used as the value range</li> <li>two label columns followed by a value column: in this case, a chart with a multiple series is shown. The first column identifies which series the row belongs to. From there, the process described above is repeated</li> </ul> </li> <li>arguments: optional expression resulting in query arguments</li> <li>chart: chart type</li> <li>style: key value pairs that construct chart option object - for instance, scales.y.min = 0 makes sure the y-axis starts at 0. By default, the chart limits the number of data points to 1000. This can be overridden by setting \"limit\" to the desired value</li> <li>graph: specifies whether the query is a graph query</li> <li>expression: allows configuring the widget via JSONata. If omitted, the widget uses $query(database, query, arguments)</li> </ul> <p>Examples: * chart-stacked-bar * chart-timeline</p>"},{"location":"developer-reference/#diagram","title":"diagram","text":"<p>Allows displaying and editing data as a graph of nodes and edges.</p> <p>Nodes are represented by the following JSON structure:</p> <pre><code>{\n  id: node id\n  database: database name\n  table: table name\n  position?: {\n    x: coordindate\n    y: coordindate\n  },\n  data?: {\n    label: display label\n  }\n}\n</code></pre> <p>Edges are represented by the following JSON structure:</p> <pre><code>{\n  source: id of the edge source node\n  target: id of the edge target node\n}\n</code></pre> <ul> <li>style: CSS widget styles (e.g. width and height of the widget)</li> <li>nodes: JSONata that generates a list of nodes</li> <li>edges: JSONata that generates a list of edges</li> <li>moveNode: optional JSONata to persist new coordinates (e.g. $update(\"northwind\", \"EMPLOYEES\", node.id, {\"Y\": node.position.y}))</li> <li>addNode: optional JSONata to persist new node that was added via SHIFT click (e.g. ($x := {\"id\": node.name, \"x\": node.position.x, \"y\": node.position.y}; $create(\"db\", \"table\", $x); $x) )</li> <li>removeNode: optional JSONata to remove node in the DB (passed via node.id)</li> <li>addEdge: optional JSONata to create a relationship (passed via edge.source, edge.target)</li> <li>removeEdge: optional JSONata to remove a relationship (passed via edge.source, edge.target)</li> </ul>"},{"location":"developer-reference/#display","title":"display","text":"<p>Displays the result of an expression:</p> <ul> <li>display: expression to display</li> <li>icons: if display evaluates to an object, icons maps the object keys to material icons</li> </ul> <p>Depending on the result of the evaluation, one of the following cases applies:</p> <ul> <li>a single result value is displayed as is</li> <li>an object is displayed as a key-value list</li> <li>if the object has exactly the keys \"database\", \"table\", and \"pk1\", the result is displayed as a link to the record identified by these values</li> <li>if the object has exactly the keys \"database\", \"table\", \"pk1\", and \"page\", the result is displayed as a link to the record identified by these values and uses the specified page to visualize the record</li> <li>an array of objects is displayed as a table</li> <li>if the object has exactly the key \"img\" (with optional width and height), the result is displayed as an HTML image with the value of the img field being used as the image src attribute</li> <li>if the object has exactly the key \"href\" or the keys \"href\" and \"label\", the object is displayed as a hyperlink </li> </ul> <p>Example: <pre><code>  \"display\": {\n    \"item one\": \"this item's value\",\n    \"item two\": \"another value\",\n    \"item three\": \"last value\",\n  },\n  \"icons\": {\n    \"item one\": \"traffic\",\n    \"item two\": \"turn_left\"\n  }\n</code></pre></p> <p></p> <p>Item one will be displayed with the \"traffic\" icon, item two with the \"turn_left\" icon. When no item is specified for a key, the default item is used. In the above example, \"item three\" will display the default icon.</p> <p>When icons is \"*\": \"icon\", all icons will be mapped to that same specified icon.</p>"},{"location":"developer-reference/#editrelated","title":"editRelated","text":"<p>Allows editing related records of a database record:</p> <ul> <li>prop: foreign key column on the related table</li> <li>columns: columns\u00a0to\u00a0display\u00a0in\u00a0the\u00a0editRelated\u00a0table\u00a0display</li> </ul>"},{"location":"developer-reference/#html","title":"html","text":"<p>Displays custom HTML</p> <ul> <li>html: HTML to display</li> <li>context: an expression that allows setting additional context variables that can be referenced via <code>${context.VARIABLE}</code></li> </ul>"},{"location":"developer-reference/#icon","title":"icon","text":"<p>Displays a hyperlink icon with tooltip</p> <ul> <li>href: optional link target</li> <li>icon: icon to display (see https://material.io/resources/icons/?style=baseline)</li> <li>tooltip: icon tooltip</li> <li>roles: show container only if user is in one of these roles</li> </ul>"},{"location":"developer-reference/#links","title":"links","text":"<p>Displays links to related records</p>"},{"location":"developer-reference/#map","title":"map","text":"<p>Displays a map for a given location. </p> <ul> <li>display: expression that results in a location - this value is resolved using the q query parameter of the Open Streetmap API service. The result can be a single value or an array. One marker is shown for each array element.</li> <li>css: CSS code to apply to the map</li> <li>card: determines if the map is shown on a card (paper background)</li> </ul>"},{"location":"developer-reference/#markdown","title":"markdown","text":"<p>Displays markdown</p> <ul> <li>markdown: markdown to display</li> <li>context: an expression that allows setting additional context variables that can be referenced via <code>${context.VARIABLE}</code></li> <li>card: determines if the markdown is shown on a card (paper background)</li> </ul> <p>Note that the HTML generated by the markdown engine is sanitized in order to avoid XSS vulnerabilities. Specifically, if you are using HTML tags, style attributes are filtered. A common task is to add margins to images. You can achieve this by adding a class attribute to the element and setting the value to a predefined material class like mat-elevation-z8. Alternatively, the markdown widget defines the styles margin1 to margin5 which set the element margin to 1em to 5em.</p>"},{"location":"developer-reference/#notebook","title":"notebook","text":"<p>This widget is the JSONata equivalent of a Jupyter notebook. It allows composing and running several expressions. The result of every expression is stored in the browser session. You can also assign variables and use them in other expressions. </p> <p>The widget offers a save function at the bottom. This saves the entire page and the expressions contained within. Please note that the notebook widget should only be used as the sole widget on the page, since saving the notebook will delete other widgets you might place on the page.</p>"},{"location":"developer-reference/#table","title":"table","text":"<p>Displays query results as a table</p> <ul> <li>database: database to run the query on</li> <li>query: query to run</li> <li>arguments: optional expression resulting in query arguments</li> <li>graph: specifies whether the query is a graph query</li> <li>expression: allows configuring the widget data via JSONata which must evaluate to an array of objects. Note that the table is able to display links, images, and lists thereof. Please refer to the display widget for information on how the JSON data must be structured. If omitted, the widget uses $query(database, query, arguments)</li> </ul> <p>Database and table can be omitted on table pages. In this case, the widget displays the equivalent of a select all from the respective table.</p>"},{"location":"developer-reference/#text","title":"text","text":"<p>Displays a simple text</p> <ul> <li>href: optional link target</li> <li>text: text to display</li> <li>icon: optional icon to display in front of the text</li> </ul>"},{"location":"developer-reference/#tree","title":"tree","text":"<p>Displays a tree based on a recursive query</p> <ul> <li>database: database to run the query on</li> <li>query: query that projects a single column with the keys of the current node's children</li> <li>arguments: expression that passes the current node's primary key as a query argument</li> <li>expression: allows configuring the widget via JSONata. If omitted, the widget uses $query(database, query, arguments)</li> </ul>"},{"location":"developer-reference/#functions","title":"Functions","text":"<p>Apart from changing data in databases, Dashjoin can call functions on the backend. Functions come in two flavors: First, there are functions that simply extend the functionality you can use in expressions. An example would be a simple toUpperCase function that transforms a string to upper case. These functions are introduced further later in the section on expressions. Second, there are configurable functions. These work very much like their counterpart, however, they require additional configuration parameters. An example would be a function to send an email. The actual function call requires you to specify subject, sender, receiver, and the body. But you would not want to have to repeat the email server address and credentials every time. So you can register an instance of email service with specific parameters and call it email-service-1. This section describes the latter configurable functions.</p> <p>Click here for a demo video.</p>"},{"location":"developer-reference/#function-reference","title":"Function Reference","text":"<p>The system supports the following functions. Each section lists the function configuration parameters that are constant any time this function is called as well as the parameters that are specific for each invocation.</p>"},{"location":"developer-reference/#restjson","title":"RestJson","text":"<p>Calls an external REST service.</p> <p>Configuration</p> <ul> <li>url: the URL of the REST service to call (the URL may contain template variables <code>${var}</code> which are replaced with the respective argument field)</li> <li>username: optional HTTP basic authentication user name</li> <li>password: optional HTTP basic authentication password</li> </ul> <p>Invocation parameter</p> <ul> <li>object: If object is specified, POSTs the object serialized as JSON. If object is null, GETs the result</li> </ul> <p>Return value</p> <ul> <li>JSON result returned by the service</li> </ul>"},{"location":"developer-reference/#email","title":"Email","text":"<p>Sends an email.</p> <p>Configuration</p> <ul> <li>username: username to log into the email service</li> <li>password: password to log into the email service</li> <li>properties: SMTP server configuration</li> </ul> <p>Invocation parameter</p> <ul> <li>from: email sender in RFC822 syntax</li> <li>to: email recipient in RFC822 syntax</li> <li>subject: email subject line</li> <li>text: email text</li> </ul> <p>Return value</p> <ul> <li>none</li> </ul>"},{"location":"developer-reference/#invoke","title":"Invoke","text":"<p>Allows saving an expression on the server. When run, we evaluate / apply the expression with the data context passed as an argument.</p> <p>Configuration</p> <ul> <li>expression: The expression to save and run when invoked</li> </ul> <p>Invocation parameter</p> <ul> <li>object: the expression evaluation context (see next chapter)</li> </ul> <p>Return value</p> <ul> <li>expression result</li> </ul>"},{"location":"developer-reference/#mapping-functions","title":"Mapping Functions","text":"<p>Mapping functions are specialized functions that have no invocation parameters and outputs. They are used to write data into a database and can be run in a scheduled fashion. All mapping functions perform the following three steps.</p> <p>Click here for a demo video.</p>"},{"location":"developer-reference/#gathering-data","title":"Gathering Data","text":"<p>It is up to the mapping function how this task is achieved. The only requirement is that the function gathers a set of tables. </p>"},{"location":"developer-reference/#the-mapping-step","title":"The Mapping Step","text":"<p>This step is common to all mapping functions and is supported by a specialized mapping editor. The mapping step transforms the gathered set of tables into another set of tables. The mapping step supports the following operations:</p> <ul> <li>remove table: a table from the initial step can be removed / ignored</li> <li>remove column: drops a column from a table</li> <li>rename table: a table from the initial step can be renamed</li> <li>rename column: renames a column in a table</li> <li>add table: a table can be added by providing the name of an initial table</li> <li>add column: a column can be added to a table</li> <li>modify column: sets the column to a new expression (the default simply copies the original value 1:1 using <code>$.columnname</code>; please see the next section for more details on expressions)</li> <li>extract table: if an input table contains a column with array values, extracts the union of these arrays into a new table</li> </ul>"},{"location":"developer-reference/#the-save-step","title":"The Save Step","text":"<p>The save step writes the output of the mapping step into the database. The following modes are supported:</p> <p>Ignore</p> <p>Simply add the data (update in case the record already is in the DB, insert if not). We follow the \"normal\" update semantics meaning that key=null actually deletes the value in the DB, whereas missing keys remain untouched.</p> <p>Database</p> id _dj_source name 1 Joe 2 Mike <p>Extracted Data from ETL \"ignore\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 John 2 Mike 3 ignore Nate <p>Row 1 is updated. Row 2 remains unchanged. Row 3 is added and thus gets marked as having source e.</p> <p>Extracted Data from ETL \"ignore\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 John 2 Mike 3 ignore Nate 4 ignore Jane <p>Row 4 gets added. Row 3 remains even though it is no longer in the extraction result.</p> <p>Refresh</p> <p>All records from the target tables that have the _dj_source column matching the ID of this function are updated. If a key is no longer present in the new data, the record is deleted.</p> <p>Database</p> id _dj_source name 1 Joe 2 Mike <p>Extracted Data from ETL \"refresh\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 John 2 Mike 3 refresh Nate <p>The first run of \"refresh\" has the same effect as \"ignore\".</p> <p>Extracted Data from ETL \"refresh\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 John 2 Mike 4 refresh Jane <p>The third row, which was added by \"refresh\" previously, is deleted and row 4 is added.</p> <p>Delete All</p> <p>All records from the target tables are deleted, if createSchema is true, the tables are also dropped in case columns are no longer needed or previously had another datatype.</p> <p>Database</p> id _dj_source name age 1 Joe 33 2 Mike 44 <p>Extracted Data from ETL \"delete-all\"</p> id name 1 John 3 Nate <p>Result</p> id _dj_source name 1 delete-all John 3 delete-all Nate <p>The table content is deleted. If create schema is specified, the age column is also deleted. Rows 1 and 3 get added with the respective source.</p> <p>Extracted Data from ETL \"delete-all\"</p> id name 1 John 4 Jane <p>Result</p> id _dj_source name 1 delete-all John 4 delete-all Jane <p>The table content is deleted and rows 1 and 4 are added.</p>"},{"location":"developer-reference/#mapping-function-reference","title":"Mapping Function Reference","text":""},{"location":"developer-reference/#etl","title":"ETL","text":"<p>The ETL function uses an expression as input into the mapping process. The expression result can be a map of table names to an array of rows (JSON objects). If the expression result has a simpler structure (for instance only a single table), the ETL function wraps this in a default table called \"table\".</p> <p>If you want to load a large amount of data, you can use the \"foreach\" expression to specify how to split the loading process into smaller parts. Assume you have a directory with thousands of files to load. The foreach expression can list the files using <code>$ls(\"url\")</code>. The expression then specifies how each file is handled. Its <code>$</code> context is set to each individual URL and the expression and subsequent ETL are called for each URL individually.</p> <p>Note that you can also stream large JSON, XML, or CSV files via the streamJson, streamXml, and streamCsv functions. In this case, these functions split a large file into smaller chunks which are then passed to the mapping expression.</p> <p>Consider the following example expressions: <pre><code>$openExcel(\"https://download.microsoft.com/download/1/4/E/14EDED28-6C58-4055-A65C-23B4DA81C4DE/Financial%20Sample.xlsx\")\n</code></pre></p> <p>Note that you have the full power of JSONata available for this operation. Consider the following example. We'd like to incrementally load files that are placed in an upload folder. Only files that have been added since the last run should be considered: <pre><code>$ls(\"file:upload/delta\")[modified &gt; $jobStatus().start].url.$openJson($);\n</code></pre></p> <p>The ls function returns an array containing objects with the modified file timestamp as well as the url of the file. The jobStatus function returns information about the last job run. Therefore, we can filter the files to only include the ones that have a modified timestamp after the job ran last.</p> <p>The setting \"ETL worker threads\" can be used to achieve parallel writes to the database. This setting is only applicable if a foreach expression is specified. In this case, the setting \"ignore ETL errors and continue process\" specifies that any error that occurs when streaming a large file (e.g. a formatting error towards the end of the file) or when workers map and write the contents to the database (e.g. due a malformatted date string) are ignored and do not stop the other workers.</p>"},{"location":"developer-reference/#receive","title":"Receive","text":"<p>The receive function allows handling cases, where the platform is being sent data that is to be processed and saved into a database. This use case is common in IoT scenarios where a stream of sensor data is passed via the REST API. The Receive function can be configured like the ETL function and allows mapping the data into the desired structure. The create schema parameter works like in the ETL case and optionally adapts the underlying schema to accommodate new fields and tables. Receive defines a parameter called sample where a stream data sample can be added. This sample data is used to edit the mapping. Note that Receive always appends the new data like the Ignore mode in the ETL case. The difference is that there is no expression that fetches data. Instead, the data is passed via the API call.</p>"},{"location":"developer-reference/#dashjoin-expression-reference","title":"Dashjoin Expression Reference","text":"<p>In addition to the default JSONata built-in functions (see Function Library), the following Dashjoin functions are added (some internal functions are omitted - you can refer to the platform's info page for a full list):</p> <p>These functions can be classified as frontend and backend functions. Frontend functions run in the browser and can be used to trigger a screen popup or to set a browser session variable. Backend functions typically access backend data. You can mix both kinds in a single JSONata expression tree. </p>"},{"location":"developer-reference/#frontend-expressions","title":"Frontend Expressions","text":"Function Syntax Returns confirm $confirm(message) Opens a confirm dialog. Returns true if confirmation was given, false otherwise setVariable $setVariable(key, value) Sets variable key to value. The key value pair then becomes accessible via the context by other expressions prompt $prompt(message) Prompts the user for an input. Returns the input or undefined if the prompt is cancelled alert $alert(message) Shows a modal alert message notify $notify(message) Shows the message at the bottom of the screen refresh $refresh() refreshes the screen just (just like hitting the refresh icon in the toolbar) reload $reload() reloads the browser page log $log(value) logs value to the developer console navigate $navigate(url) points the browser to the URL"},{"location":"developer-reference/#backend-expressions","title":"Backend Expressions","text":"Function Syntax Returns create $create(database, table, pk1) ID of the new record all $all(database, table) array of all table records all $all(database, table, offset, limit, sort, descending, filter) array of all table records whose columns match the filter key's values read $read(database, table, pk1) The record traverse $traverse(database, table, pk1, fk) Record(s) related to the current record via the property fk. If fk is a simple column name, fk is an outgoing foreign key and the single related record is returned. If fk is a full property ID like dj/database/table/column, then a list of records from that table that have a fk pointing to the current record are returned update $update(database, table, pk1, object) delete $delete(database, table, pk1) call $call(function, argument) Dashjoin function result query $query(database, queryId, arguments) Query result table queryGraph $queryGraph(database, queryId, arguments) Graph query result, specifying the database as * runs an OpenCypher query over all DBs adHocQuery $adHocQuery(database, query, limit?) Runs as ad hoc select / read query search $search(term, limit?, database?, table?) Searches the databases(s) incoming $incoming(database, table, pk1) [{id: ID of the record where the link originates, pk: ID of the pk column, fk: ID of the fk column}, ...] echo $echo(any) Prints the parameter to the log index $index() Generates a unique row index ID djVersion $djVersion() Returns the platform version information djRoles $djRoles() Returns the roles of the current user djUser $djUser() Returns the current user's name isRecursiveTrigger $isRecursiveTrigger() true if the current expression is called from a trigger expression (trigger calls trigger) jobStatus $jobStatus() if evaluated within a function, start and stop timestamps (millis since 1970) and job status moveField $moveField(object, 'from', 'to') Moves the object's from key into the to key, where to must be an object or array ls $ls(url, preview-limit) Lists all URLs found at url (the URL can also contain filter wildcards like *.txt). preview limit determines how many results are returned in preview mode (defaults to 10) streamJson $streamJson(url, jsonPointer) Parses JSON at the url and splits it at the json pointer location streamXml $streamXml(url, jsonPointer) Parses XML at the url, converts it to JSON, and splits it at the json pointer location streamCsv $streamCsv(url, options) Parses CSV at the url and splits it at the record boundaries. By default, CSV is parsed as RFC4180. Options can be provided, where the key is a \"with\" method like withDelimiter and the value is the argument. Please see the documentation for more details. streamDb $streamDb(database, table) Streams records from the database table specified openJson $openJson(url) Parses JSON at the url openCsv $openCsv(url, options) Parses CSV at the url and converts it to JSON. By default, CSV is parsed as RFC4180. Options can be provided, where the key is a \"with\" method like withDelimiter and the value is the argument. Please see the documentation for more details. openXml $openXml(url, arrays) Parses XML at the url and converts it to JSON. In this process, openXml guesses which XML tags need to be converted to arrays and which become simple fields. This process might produce inconsistent results when the XML tree contains lists with single entries. To avoid this, you can optionally pass a list of tag names that must be arrays. openYaml $openYaml(url) Parses YAML at the url and converts it to JSON openExcel $openExcel(url) Parses Excel at the url and converts it to JSON openText $openText(url, encoding) Parses the url and converts it to a string parseJson $parseJson(json) Parses JSON (see openJson) parseCsv $parseCsv(css, options) Parses CSV and converts it to JSON (see openCsv) parseXml $parseXml(xml, arrays) Parses XML at converts it to JSON (see openXml) parseYaml $parseYaml(yaml) Parses YAML and converts it to JSON (see openYaml) parseExcel $parseExcel(base64) Parses Excel and converts it to JSON (see openExcel). The parameter must be a base64 encoded data URL (RFC 2397) uuid $uuid() Generates a random UUID exec $exec(executable, arguments, [json, xml, csv, yaml]) runs the script or executable located in the app's bin folder and optionally parses the output to JSON, XML, or CSV erDiagram $erDiagram(database?) Generate an ER diagram for https://dbdiagram.io/d stats $stats(database, table, limit?) Generate statistics for a database table (type, min, max, count, distinct values, etc.) gitStatus $gitStatus() Run git status gitPull $gitPull() Run git pull gitRestore $gitRestore(path) Revert a change gitCommit $gitCommit(message, [paths]) Run git commit and push saveTable $saveTable(Ignore Refresh reconcileEntity $reconcileEntity(entity, entity-language?, limit?) Uses the wikidata query service to reconcile a string to a wikidata id. The entity is a simple string. The entity language is the language the entity is expressed in (defaults to en). The limit (default 1) determines the number of results returned (see chapter AI &amp; ML) classifyEntities $classifyEntities([entities], entity-language?, limit?, subclass-depth?) Reconciles entities and finds common classifications that all entities are an instance of. The parameters are similar to the reconcileEntity function. The subclass depth (default 1) describes the number of superclasses that are included in the results (see chapter AI &amp; ML) synonym $synonym({algorithm: threshold}, [terms], [variants], ignoreCase?, ignoreEquality?) Allows generating synonym table to match keys despite small typos etc. (see chapter AI &amp; ML) wait $wait(object, millisecs) Wait millisecs provided before returning object"},{"location":"development-production/","title":"Development / Production","text":"<p>If you use a Dashjoin system in production, we do not recommend making configuration changes like defining new queries or registering new user roles using the editors on the production system. Instead, you can setup multiple development systems where these changes are developed and tested.</p>"},{"location":"development-production/#dashjoin-studio","title":"Dashjoin Studio","text":"<p>The most convenient way to setup a development system is by using the Dashjoin Studio container. This container includes all the required tools and setup. To start the container, run:</p> <pre><code>docker run -p 3000:3000 -p 8080:8080 -p 8081:8081 -e DJ_ADMIN_PASS=djdjdj dashjoin/studio\n</code></pre> <p>If you would like to work on an existing app that is located on a Git repository, also specify the DASHJOIN_HOME and DASHJOIN_APPURL parameters (see section automatic Git checkout below)</p> <pre><code>docker run -p 3000:3000 -p 8080:8080 -p 8081:8081 -e DJ_ADMIN_PASS=djdjdj -e DASHJOIN_HOME=dashjoin-demo -e DASHJOIN_APPURL=https://github.com/dashjoin/dashjoin-demo dashjoin/studio\n</code></pre> <p>Dashjoin Studio works like the platform container, but offers two additional services. On port 8081, it allows connecting a browser based integrated development environment (expert mode) to the container. On port 3000 an additional web service provides access to the user interface that includes custom widgets you add to the app.</p>"},{"location":"development-production/#expert-mode","title":"Expert Mode","text":"<p>To open the expert mode, open the general information page and follow the expert mode link under \"App\". To log in, please use the password you specified for the admin user (djdjdj in our examples). This opens VS Code in your browser. For more information about VS Code, please refer to this documentation.</p> <p>The project that is open in VS Code represents the app you are writing. Adding a query in the query catalog, for example, will create a JSON file in model/dj-query-catalog. If you change the file in VS Code, the change will be visible immediately in the query catalog as well.</p>"},{"location":"development-production/#app-folder-structure","title":"App Folder Structure","text":"<p>The contains the following folders:</p> <ul> <li>assets: any media that should be available via http(s):///assets <li>model</li> <li>dj-config: Contains any system configuration</li> <li>dj-database: All connected databases and any table and record page layouts. If a database JSON file is open in the editor, you can test connecting to it via the \"Connect to this database\" button at the top of the file</li> <li>dj-function: All functions defined on the functions page. Also offers the ability to \"Run this function\". Note that passing parameters to the function is not supported. You can use the JSONata notebook for this.</li> <li>dj-query-catalog: All queries in the catalog. Offers the \"Run this query\" and \"Run this query metadata\" commands. Note that passing query parameters is not supported. You can use the JSONata notebook for this.</li> <li>dj-role: All roles defined in the system</li> <li>page: All app dashboard pages. Offers the \"Open this page in the browser\" button.</li> <li>tenantusers: All tenant users</li> <li>widget: Custom toolbar and sidebar are located here</li> <li>upload: this folder can contain files that can be accessed from JSONata functions like openJson(\"file:upload/...\")</li>"},{"location":"development-production/#source-control","title":"Source Control","text":"<p>If you would like to commit and publish your changes to the production system, you can switch to the source control tab on the left. The usual workflow is to:</p> <ul> <li>review your changes in the diff editor</li> <li>stage your change by adding the file via the + icon</li> <li>entering a message describing your change and committing the change</li> <li>publishing your change to the remote Git repository</li> </ul> <p>For more details, please refer to this guide.</p>"},{"location":"development-production/#developing-a-custom-widget","title":"Developing a Custom Widget","text":"<p>One of the most powerful features of the expert mode is the ability to write your own widgets. Let's assume we have a database containing chemical molecules. One of the columns contains the SMILES string. We're going to write a widget, that draws a 2D representation of the molecule based off this information.</p>"},{"location":"development-production/#adding-a-3rd-party-library","title":"Adding a 3rd Party Library","text":"<p>The first step is to find a 3rd party library that is suitable for the task. The Dashjoin UI is written in React, therefore, keep this in mind when selecting a library. For this example, we'll use smilesDrawer.</p> <p>In VS Code, open a terminal (on the top left, click the menu, then terminal, and finally new terminal) and enter:</p> <pre><code>yarn add smiles-drawer\n</code></pre> <p>Yarn is a JavaScript package manager, that will retrieve the latest version of the library and all other required components. Depending on your internet connection speed, this command might take a while to complete. Now we can start the development webserver that will run on port 3000:</p> <pre><code>yarn dev\n</code></pre>"},{"location":"development-production/#adding-a-new-widget","title":"Adding a new Widget","text":"<p>Adding a new widget requires three changes: First, create the file Smiles.tsx in src/widgets:</p> <pre><code>import { Icon } from \"@mui/material\"\nimport { Widget } from \"../model/widget\"\nimport { text, title } from \"../api/Const\"\nimport { useEffect, useRef } from \"react\"\nconst SmilesDrawer = require('smiles-drawer')\n\nexport const Smiles = ({ widget }: { widget: Widget }) =&gt; {\n\n    const imgRef = useRef&lt;HTMLImageElement&gt;(null);\n    const drawer = new SmilesDrawer.SmiDrawer();\n\n    useEffect(() =&gt; {\n        drawer.draw(widget.text ? widget.text : 'C', imgRef.current, 'light');\n    });\n\n    return (\n        &lt;div&gt;\n            &lt;img ref={imgRef} width={300}&gt;&lt;/img&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport const config = {\n    id: 'smiles',\n    title: 'Smiles',\n    description: 'Renders a SMILES string as a 3D molecule',\n    version: 1,\n    icon: &lt;Icon&gt;science&lt;/Icon&gt;,\n    controls: {\n        type: 'autoform',\n        schema: {\n            properties: {\n                title: title,\n                text: text\n            }\n        }\n    }\n}\n</code></pre> <p>This code contains two blocks. The first block is the actual widget. It gets the parameter \"widget\", which is a JSON structure to configure the widget. The rest of the code is taken from the  library's documentation. The key point is in line 13, where widget.text is passed as the parameter to the draw function. This parameter contains the SMILES string passed to the widget.</p> <p>The second part defines how the widget edit dialog looks like. It contains an icon, some description, and a list of controls. In this case, we allow editing the widget title (this is a property shared by all widgets) and the text to contain the SMILES string. You could add other properties. For instance, the width of the generated image is fixed at 300 pixels. This could be replaced with a widget parameter.</p> <p>Now edit the file CustomWidgets.tsx in src and add the following lines:</p> <pre><code>import { config } from \"./widgets/Smiles\";\nimport { Smiles } from \"./widgets/Smiles\";\n\nexport const customWidgets = [\n    {\n        widget: Smiles,\n        config: config\n    }\n]\n</code></pre> <p>Custom widgets is an array. Therefore, you can add other custom widgets as well. Now we're all set. We can create a test page and add the widget with the following parameters in order to see the molecule in all its glory:</p> <pre><code>{\n    \"widget\": \"smiles\",\n    \"title\": \"Glucose\",\n    \"text\": \"OC[C@@H](O1)[C@@H](O)[C@H](O)[C@@H](O)[C@H](O)1\"\n}\n</code></pre>"},{"location":"development-production/#packaging-the-widget-and-deploying-it-to-production","title":"Packaging the Widget and Deploying it to Production","text":"<p>Once you are done with your widget development, you can start the build process via the terminal and deploy the result to your app: <pre><code>yarn build\nyarn deploy\n</code></pre></p> <p>This command will create a folder with the compiled user interface in the folder of your app. You can commit these assets along with the query catalog and the other files in your app. If the app is deployed onto a production system, the user interface containing the new widget will be active.</p>"},{"location":"development-production/#making-changes-to-the-platform","title":"Making Changes to the Platform","text":"<p>Dashjoin Studio gives you full access to the entire user interface.  Therefore, you can not only add widgets, but also make changes to the core UI. For instance, you can make changes to the login screen or the legal cookie and data privacy disclaimer presented to new users.</p> <p>Any of these changes are picked up by the build and deploy process described in the previous section. Please note however, that changes to the core platform must be re-applied manually once a new version of Dashjoin is released.</p>"},{"location":"development-production/#multi-line-json","title":"Multi Line JSON","text":"<p>Markdown, queries, and JSONata expressions can be hard to read if they are stored in JSON files. You can externalize strings in separate text files which are linked from the JSON data as follows:</p> <p>test.json:</p> <pre><code>{\n  \"ID\": \"test\",\n  \"query-pointer\": \"0.sql\"\n}\n</code></pre> <p>test.0.sql:</p> <pre><code>select * from test\n  where id=4\n</code></pre> <p>These two files are equivalent to:</p> <p>test.json:</p> <pre><code>{\n  \"ID\": \"test\",\n  \"query\": \"select * from test\\n  where id=4\"\n}\n</code></pre> <p>You can use this mechanism anytime when you're editing the files manually. When making changes via the platform, by default, only the query strings of the query catalog are externalized.</p> <p>This is controlled by the \"externalize-config-strings\" setting. If you'd like to also externalize widget markdown for instance, simply add \"page: markdown\" to \"externalize-config-strings\". This specifies the table and the (possibly nested) key containing the string to be externalized.</p> <p>On the production system, there are three ways of deploying an application:</p>"},{"location":"development-production/#upload-to-the-configuration-database","title":"Upload to the Configuration Database","text":"<p>You can upload an entire model folder to the config DB. On the database page, select \"Configuration Database\". Open the \"Database Management\" tab and select \"Upload\". Select the model folder there and either append or replace the contents of the config database.</p>"},{"location":"development-production/#automatic-git-checkout","title":"Automatic Git Checkout","text":"<p>You can specify the DASHJOIN_APPURL environment variable and have it point to your app repository. Upon startup, the system will perform a git clone if the model folder is empty or a git pull if the model has content already. Note that you can specify credentials via the URL (http://user:password@domain.com/). Please refer to the demo application for an example of how to run Dashjoin with the demo application installed. If the git operation fails (e.g. due to incorrect credentials or illegal filenames), the platform will log the error and resume the startup process.</p>"},{"location":"development-production/#manual-app-installation","title":"Manual App Installation","text":"<p>Last but not least, you can also copy the app into the Dashoin working directory using other means before starting the platform.  If you are using containers, you can mount the model folder under /deployments/model.</p>"},{"location":"development-production/#specifying-development-resources","title":"Specifying Development Resources","text":"<p>Resources like databases and REST endpoints are critical resources when working with Dashjoin. Therefore, it is quite common to use different sets of resources for development and production. As described in the section on automatic Git checkout above, the production credentials are usually checked into the code repository. During development, you can use environment variables to specify alternative values for url, username, hostname, port, database, and password to be used for functions and databases as follows:</p> <ul> <li>dashjoin.database.NAME OF THE DATABSE.url: URL to use to connect to the database (overrides the url field in the DB's json file)</li> <li>dashjoin.function.NAME OF THE FUNCTION.url: URL to use to connect to the REST service (overrides the url field in the function's json file)</li> </ul> <p>To change the username, simply replace url with username in the examples above. Note that the development passwords are provided in plain text.</p>"},{"location":"development-production/#unit-testing","title":"Unit Testing","text":"<p>Unit tests are an important asset to ensure the quality of your app. Dashjoin leverages the JUnit framework and allows you to perform the following default tests to make sure that</p> <ul> <li>all JSON files can be parsed</li> <li>layout uses legal widget names</li> <li>all JSONata expressions are syntactically correct</li> </ul> <p>In addition to these syntactical checks, it is possible to run JSONata expressions and provide desired outputs. </p> <p>To setup unit tests in your app, follow these steps:</p> <ul> <li>Install Maven</li> <li>Copy this maven project file to your app's root directory</li> <li>Copy this JUnit test file to \"src/test/java/org/dashjoin/app\"</li> <li>If you would like to test a JSONata expression, create a JSON test file that describes the file containing the expression, where the expression is located, which test cases should be run, and which outputs are to be expected. The file is structured as follows:</li> </ul> <pre><code>{\n    \"test\": {\n        \"file\": path to the file containing the expression to be checked\n        \"expression\": JSONata expression that selects the expression to be checked\n    },\n    \"basedata\": optional common test data for the test cases\n    \"cases\": {\n        \"name\": {\n            \"data\": test data (will be merged with the base data)\n            \"expected\": expected JSONata output\n        }\n        ...\n    }\n}\n</code></pre> <p>To run the unit test:</p> <pre><code>dashjoin-demo&gt;mvn test\n</code></pre>"},{"location":"faq/","title":"FAQ","text":"<ul> <li> <p>How can I edit a fullscreen page? Usually, you toggle the edit mode via the widget in the toolbar. If you're creating a page without the toolbar, you have two options: 1) If you're working with docker or the installer, you can edit the dashboard page in the respective file on the file system. 2) You can navigate to any \"normal\" page, enter edit mode, navigate to the fullscreen page, make changes via the edit context menu, navigate back to the \"normal\" page and save there.</p> </li> <li> <p>The Dashjoin Demo Application contains some interesting examples. How can I apply them to my application? You can either locate your application on the file system and copy an example page there or you can look at the page in order to see which settings to add in the layout editor dialogs (e.g. a JSONata expression).</p> </li> <li> <p>I have an object with special characters in the field names (e.g. a SQL query result). How can I access this field in JSONata? In JSONata, field names can be escaped using back-ticks (`). Click here for a live example.</p> </li> <li> <p>I have an object with special characters in the field names (e.g. a SQL query result). How can I access this field in the HTML widget? The HTML widget uses EJS, which allows embedding JavaScript templates in HTML. In Javascript, you can access non-alphanummeric field names as follows: <code>object[\"field.name\"]</code>. Click here for a live example.</p> </li> <li> <p>How can I customize the forms in the edit, button and variable widgets? These widgets use the JSON Schema Form component. This online playground lets you experiment with the various features. This component comes with a WYSIWYG editor which is available in edit mode by clicking the three vertical dot icon. Note that not all features of the component are exposed in the WYSIWYG editor. You can leverage the advanced features by editing the underlying JSON directly. The demo application shows two examples. The \"createSchema\" of the customer page section shows the form of the email button, which displays the email body input field with a larger text box. The city instance page shows a similar layout for the edit widget. The variable example shows how a select widget with display names and values can be rendered.</p> </li> <li> <p>How can I use values from the database in the edit, button and variable widgets? This can be achieved by combining the JSON Schema Form extension mechanism described in the section above with the API. In the example below, all values from the table test in the DB sql are retrieved. The jsonata expression projects the column id to be used as the auto-complete choices in the input field.</p> </li> </ul> <pre><code>{\n    \"widget\": \"button\",\n    \"properties\": {\n        \"test\": \"string\"\n    },\n    \"createSchema\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"test\": {\n                \"type\": \"string\",\n                \"choicesUrl\": \"/rest/database/all/sql/test\",\n                \"jsonata\": \"id\",\n                \"choicesVerb\": \"POST\"\n            }\n        }\n    },\n},\n</code></pre> <ul> <li> <p>Are SQL stored procedures supported? Yes, simply use 'exec proc' or 'call proc(par)' as the query, depending on the SQL dialect used by your DB. In case a stored procedure has multiple result tables, the $query function returns them by wrapping them in a top level object.</p> </li> <li> <p>How can I access a SQL Server stored procedure output variable? This can be done on the query level as follows:</p> </li> </ul> <pre><code>DECLARE @res INT;\nexec dbo.sp @res output;\nselect @res;\n</code></pre> <ul> <li> <p>Why am I getting the error: \"User does not have the role required to read table page in database config\" after logging in? When the UI renders a page, it needs to get the page layout from the backend. Like with any other call, the user's credentials are checked. This error indicates, that the user is known to the system, but gets assigned insufficient roles to access this information in the config DB. To fix this, you can either assign the user the correct role in the IDM or you can provide read access to the config DB to the user's role (this is done on the System Configuration page).</p> </li> <li> <p>Does the platform cache results? Yes, all HTTP GET requests are cached by the browser UI. The cache is purged if 1) five minutes have passed since the last time the data was retrieved, 2) the data is changed in via the UI (e.g. by saving / updating a value), or 3) SHIFT F5 / reload is pressed.</p> </li> <li> <p>How can I download data from the platform? This can be achieved via the HTML widget. And example can be found here. The download happens via a JavaScript function that calls saveAs(new Blob([data]), filename).</p> </li> <li> <p>How can I download binary data such as PDFs or images? This works like the regular download. You usually have a JSONata expression that loads the data in the backend. You can use $openText(url, \"BASE_64\") to get a base64 encoded representation. In the HTML widget, you can use this code to have the browser download the data:</p> </li> </ul> <pre><code>function go() {\n  const byteCharacters = atob(context);\n  const byteNumbers = new Array(byteCharacters.length);\n  for (let i = 0; i &lt; byteCharacters.length; i++) {\n    byteNumbers[i] = byteCharacters.charCodeAt(i);\n  }\n  const byteArray = new Uint8Array(byteNumbers);\n  const blob = new Blob([byteArray], {type: \"application/pdf\"});\n  saveAs(blob, 'download.pdf')\n}\n</code></pre> <ul> <li> <p>On the table page, my primary key column is not on the very left and I need to scroll right to get to the instance page link. How can I change this? The default layout uses the native column order defined in the database. This order is used for the overview table as well as for the forms on the instance pages. For the table, simply define a query with your desired column projection order. Note that you can also omit columns if you'd like. Enter the layout editor and use this query for the table widget. On the edit form, you can enter the layout editor and open the form element's context menu via the three dots and change the positioning there.</p> </li> <li> <p>How can I format dates or currency in tables? This can be done on the database query level. If you're using PostgreSQL for instance, this query will format the \"born\" and \"salary\" columns accordingly (assuming their database type is date and int): select to_char(born, 'DD-MON-YYYY'), cast(salary as money) from employee.</p> </li> <li> <p>Why does the browser not show changes performed via an expression called from a button? You need to check the button option \"clearCache\" if your expression makes changes to the database. Otherwise, old values might be shown for five minutes.</p> </li> <li> <p>The display widget shows an object as a material list. Can I transpose the object such that it is displayed as a two column table with colums key and value? This can be done using the following JSONata transformation. For each object key, we create an object where key is the current key and value is the key lookup. This array of objects is then shown as a table.</p> </li> </ul> <pre><code>value.(\n    $x := $;\n    $keys($).{\"key\": $, \"value\": $lookup($x, $)}\n)\n</code></pre> <ul> <li>How can I determine whether it makes sense to define a foreign key on a given column? In some data integration scenarios, it may not be clear whether a column is a good candidate to reference a primary key. Some keys might match, others won't. You can use the following piece of JSONata code to determine to which degree the values intersect. We first get the table data and project the column. The intersection is computed using a JSONata filter which only includes the values in the other array.</li> </ul> <pre><code>(\n  $t1 := $all(\"db1\", \"table1\").column1;\n  $t2 := $all(\"db2\", \"table2\").column2;\n  {\n    \"count1\": $count($t1),\n    \"count2\": $count($t2),\n    \"intersect\": $count($t2[$ in $t1])\n  }\n)\n</code></pre> <ul> <li> <p>Can I trigger a git pull of the App in production without a restart? You can run $gitPull() as a function or on the Dashjoin Notebook.</p> </li> <li> <p>Can I call the OpenAI APIs from Dashjoin? Yes, register the following function (replace your API key accordingly) can call it:</p> </li> </ul> <pre><code>{\n    \"djClassName\": \"org.dashjoin.function.RestJson\",\n    \"ID\": \"openai\",\n    \"type\": \"read\",\n    \"method\": \"POST\",\n    \"contentType\": \"application/json\",\n    \"headers\": {\n        \"Authorization\": \"Bearer YOUR-API-KEY-HERE\"\n    },\n    \"url\": \"https://api.openai.com/v1/chat/completions\"\n}\n</code></pre> <pre><code>$call(\"openai\", {\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],\n  \"temperature\": 0.7\n})\n</code></pre> <ul> <li>I have a table with a unique column which is not the primary key, can I ETL into this table from a datasource which only contains this key and not the primary key? Yes, you can lookup a record using the $all function. Let's consider the following example from the northwind database, where employee names are given with an email address, but not the employee ID. We can use the $all function to retrieve the record by last name and project the id which is then merged into the original record. Note that this runs one query per row. Alternatively, you can create a lookup table (unique2key), store it in a variable, and use $lookup to get the primary key to merge.</li> </ul> <pre><code>[{\"id\": \"Davolio\", \"email\": \"davolio@example.org\"}, {\"id\": \"Fuller\", \"email\": \"fuller@acme.org\"}]\n  .$merge([\n    $, \n    {\"EMPLOYEE_ID\": $all(\"northwind\", \"EMPLOYEES\", null, null, null, false, {\"LAST_NAME\": id}).EMPLOYEE_ID}\n  ])\n</code></pre> <pre><code>(\n  $input := [{\"id\": \"Davolio\", \"email\": \"davolio@example.org\"}, {\"id\": \"Fuller\", \"email\": \"fuller@acme.org\"}];\n  $unique2key := $all(\"northwind\", \"EMPLOYEES\").{LAST_NAME: EMPLOYEE_ID};\n  $input.$merge([$, {\"EMPLOYEE_ID\": $lookup($unique2key, $.id)}])\n)\n</code></pre> <ul> <li> <p>I need to ETL from an API that has a rate limit. How can I throttle my requests? You can use the wait function in your JSONata expression: Let's assume $openJson(url) is called on several array elements. Simply change it to $wait($openJson(x), 1000) to introduce a 1 second delay after each call.</p> </li> <li> <p>How can I realize an audit log that keeps track of all changes to a table? You can define a triggers for create, update, and delete operations on the table that must be audited. Create an audit log table with the following columns: autoincrementing ID, user, timestamp, operation, and payload. The trigger <code>$create(\"db\", \"audit\", {\"timestamp\": $now(), \"user\", user, \"operation\": \"update\", \"payload\": $})</code> will log changes to the table.</p> </li> </ul>"},{"location":"getting-started/","title":"Getting Started: 15 Minute Tour","text":"<p>This section will guide you through the various features of the Dashjoin low code development platform. We assume you are in the admin role and have the demo application installed. This application bootstraps a sample northwind database which allows us to demonstrate advanced queries.</p> <p>We will guide you through a scenario where northwind is an internal fictional enterprise resource planning (ERP) system. You a being tasked with developing an application that allows customers to interface with you via a web portal.</p>"},{"location":"getting-started/#database-management","title":"Database Management","text":"<p>To get to the data management page, click on the gear symbol in the toolbar. The table shows the databases that are available to the system so far. You should see the northwind database there.</p> <p>Since northwind is a non-persistent in memory database, we will create a new database. This can be done with the create widget on the page. Select the following values and press \"create\":</p> <pre><code>type: SQLDatabase\nname: sqlite\nurl:  jdbc:sqlite:your_database.db\n</code></pre> <p>From the database page, click on the sqlite database you just created. This brings you to the database details page. The connection information section allows you to make changes to the connection. Note that you can also simply click update in order to recollect the database metadata in case the schema was changed using another application.</p> <p>If you are in the admin role, you can expand the database management section. Using the form, create a table called \"REQUESTS\". This operation creates the table with two columns: ID is the numeric primary key and name is a string column describing the record.</p> <p>Go to the table by following the REQUESTS link in the database management table. On the page you can start entering some test data. Note that the SQL database enforces the uniqueness constraint on the ID column. If you try to create a record with an existing ID, you will get an error message: [SQLITE_CONSTRAINT] Abort due to constraint violation (UNIQUE constraint failed: <code>REQUESTS.ID</code>). By inspecting the created table, the system also automatically picks up the datatypes of the columns and requires you to provide an ID.</p> <p>Open the column metadata control and add three more columns:</p> <ul> <li>submitted: date</li> <li>customer: string</li> <li>user: string</li> </ul> <p>We can enter, edit and delete records via the user interface. Another option is to upload data. To do this, create a file called REQUESTS.csv (note that the file name must match the case sensitive table name):</p> <pre><code>ID,name,submitted,customer,user\n1,Can you please send me an offer,2021-01-01 10:20,ALFKI,user\n2,Delivery arrived,2021-01-01 10:20,ALFKI,user\n3,Delivery delayed,2021-01-07 11:32,ALFKI,user\n4,Are you out of crackers,2021-01-04 08:21,BLAUS,other\n5,Need more crackers,2021-11-06 05:20,,admin\n</code></pre> <p>To upload this file, navigate back to the sqlite database page, expand the database management control and select \"Upload Data\". In the dialog, select \"choose files\" and select the file REQUESTS.csv you just created. This brings up a table with a preview (the first 10 rows) of the table. Since the requests table already exists, you cannot select a primary key or the column data type. These options are available if the target table does not yet exist in the database.</p> <p>You have the choice of appending to or replacing the existing data. Choose \"replace\" in order to avoid further primary key clashes. Since we are permanently deleting existing data, we need to confirm this operation by entering \"delete tables\". Note that tables is plural since we can also upload multiple tables at once by selecting a Excel spreadsheet or multiple csv files.</p> <p>Since our application should not change the northwind ERP database, we created the new table in a new database. Nevertheless, there is a logical connection between the two databases, since the customer field in the requests table references the CUSTOMERS table in the northwind database. Dashjoin allows you to express this relationship even tough it links columns and records in different databases.</p> <p>Navigate to the REQUESTS table and open the column metadata control. In the table, select the customers column and click edit. In the popup, type \"CUSTOMER_ID\" in the foreign key reference field. The system suggests all known columns that contain this substring. Select \"dj/northwind/CUSTOMERS/CUSTOMER_ID\" and press ok. Since we made a change to the database metadata and the application caches this data, we need to clear the browser application cache by reloading the page.</p> <p>After the reload, you will notice that the customer column in the table now shows a hyperlink to the related record in the customer table. Likewise, if you navigate onto a request or onto a customer, the related records are displayed even though they reside in a different database. In addition, if you start typing in the request creation's customer field, you will notice that the matching northwind customer IDs are showing up.</p> <p>Navigate to the customer ALFKI (northwind/CUSTOMERS/ALFKI). The list of requests made by this customer shows up as a list of hyperlinks (1, 2, and 3). As a default, Dashjoin uses the primary key value as a link label, however we can customize this. Go to the REQUESTS table page, open the table metadata control and enter <code>${name}</code> in the dj-label field. This string is a template syntax where constant strings can be mixed with template variables referencing columns. So a person template could be <code>${LAST_NAME}, ${FIRST_NAME}</code>.</p> <p>Save this change and reload the browser. The visit the first request. You will notice that the browser window title now displays the new label. Going back to the requests table you will see that any request that was visited, now shows a nice name. Likewise, if you go back to customer ALFKI, the list also shows the readable link labels (assuming they all have been visited).</p> <p>Go back to the requests table and enter the letter 'a' in the customer field of the create form. You will see the autocomplete options with the customer IDs starting with 'a'. The customer IDs are five letter strings. This is better than a plain number, but let's also choose a display name for customers. Again, we can do this by navigating to the customer table (/table/northwind/CUSTOMERS), opening the table metadata control and entering the dj-label <code>${COMPANY_NAME}</code>. Reload the browser and go back to the requests table. If you type 'a' into the customers create field, you will see the list of customer display names that start with 'a'. Note that the tooltip shows the underlying five letter primary key. This feature is very useful if tables use unreadable keys.</p>"},{"location":"getting-started/#restricting-access","title":"Restricting Access","text":"<p>Dashjoin makes it very easy to secure data based on user roles. To view the roles known to the system, go to the info page linked in the toolbar. The top left widget display the following information:</p> <ul> <li>The name of the current user (should be user name 'admin')</li> <li>The roles the current user is in (should be the user role 'admin')</li> <li>A link to the role management page</li> </ul> <p>Follow the link to the roles page. On there, you can define new roles and define the home page for users in this role. In the system there are several places where you will be able to select the roles defined here. The role IDs you choose depend on the identity management system that is configured. In the Dashjoin PaaS, this is OpenID. If you are using the open source default installation, local users and their role associations are defined in the files djusers.properties and djroles.properties:</p> <p>You already have an admin user. To add a user \"authenticated\" with password djdjdj that is in the role with the same nave, edit the files as shown below:</p> <pre><code># djusers.properties\nadmin=1395a3149fee498061e6c06581a3decf\nauthenticated=4a699242c282b1180a24df1ff411001f\n</code></pre> <pre><code># djroles.properties\nadmin=admin\nauthenticated=authenticated\n</code></pre> <p>In the next step, use a different browser or an incognito window and login user user with password djdjdj. Except for the toolbar, the system looks pretty much the same. Navigate to the info page. You will need to type /page/Info into the browser, since the toolbar icon is not displayed. Verify that the page shows user in role authenticated. Click on \"system roles\" and \"admin\" and press delete. You will get the error message: \"User does not have the role required to delete table dj-role in database config\". The authenticated role has read access to the config database, but cannot create, delete or update any records.</p> <p>By default, new databases are only accessible for the admin. We can demonstrate this by searching for the term \"cracker\". In the admin browser, you get a total of seven results from both the northwind and sqlite databases.</p> <p>If you perform the same search in the user browser, you only get the five northwind results.</p> <p>The northwind database grants read only access to the authenticated role. You can check this on the page /config/dj-database/dj%2Fnorthwind.</p> <p>Now let's grant access to the sqlite database. Go to the page /config/dj-database/dj%2Fsqlite, select the authenticated role for both the read and write roles and save your change. Note that the admin role already has implicit access, therefore it is not listed in the options.</p> <p>Go back to the user browser and repeat the search. Now you'll get the same result as in the admin window. You can also navigate to a request and make a change since write access has been granted.</p>"},{"location":"getting-started/#user-layouts","title":"User Layouts","text":"<p>This section explains how we can customize the layouts and how we can display different user interfaces depending on which role the user is in.</p> <p>For our application, we'd like the users to have a page where they can see their past requests and where they can issue a new request. A request should only consist of the text. The fields ID, submitted and user should be determined by the system.</p> <p>We start with the admin browser and navigate to the \"dashboard pages\" via the toolbar. Using the \"Create a new page\" control, create a new page called \"Start\". We will use this as the homepage for authenticated users. This can be setup on the authenticated role page (config/dj-role/authenticated). Enter a new property  with the key \"homepage\" and the value \"/page/Start\" to specify the start page as the homepage for users in this role. We need to logout and back in using the user browser to pick up this setting. Clicking the home icon will now get you to the start page which at this point only shows a single tile with the text \"New page\".</p> <p>In order to create this page, we need to use the admin browser. Before we add widgets to this page, we need to create a query that filters the user's requests and that projects the request columns in a suitable way.</p> <p>This can be done using the query catalog and query editor. Navigate to the query catalog via the toolbar and in the create form, press the editor button. In the popup, select the sqlite database and the requests table. Using the dropdown, you can add the field user to the query. In the filter field, enter \"user\". Now we just need to hide the user column (select remove column from the column context menu) and drag &amp; drop the name column to the first position. The query should be:</p> <pre><code>SELECT\n  \"REQUESTS\".\"name\", \"REQUESTS\".\"submitted\"\nFROM\n  \"REQUESTS\"\nWHERE\n  REQUESTS.user = 'user'\n</code></pre> <p>Press OK to leave the query editor. Before creating the query, we need to add the ID (requests), type (read), and roles (admin, authenticated). The query needs one more argument, namely the current user. This can be specified by pressing the + symbol and adding the parameter user with type string and example \"user\". The example is used when editing a parameterized query in the editor. Finally, in the query text field, replace 'user' with <code>${user}</code>. This indicates that the query has a dynamic parameter that is inserted into the query before it is run. Now save the query by pressing \"create\". At a later point, you can always go back and make changes to the query (e.g. add a join or another projection).</p> <p>Now we navigate to the page start and enter the layout editor by pressing the pen symbol. We can now make changes to the page. The page contains one widget which currently is a text widget displaying a static text. You can delete this widget and instead add a table widget showing our query result.  After adding the table widget from the left drawer, enter the following widget proerties in the editor:</p> <pre><code>widget: table\nquery: requests\ndatabase: sqlite\ntitle: My Requests\narguments: {\"user\": $.user}\n</code></pre> <p>Press the floppy disk symbol to save the new layout. You should now see a table with one row. Go to the user browser and reload the page. You should see three requests there.</p> <p>We created a table widget that runs the requests query on the sqlite database. Now the requests query needs an argument called user. Dashjoin uses a JSON object to pass such parameters. Specifically, <code>$.user</code> reads the current username from the context. We will leave it at that, please refer to the developer guide for a full documentation of these expressions.</p> <p>Now we are missing the functionality to submit new data. We can achieve this with the button widget. Enter the edit mode again and add button widget with the following parameters:</p> <pre><code>widget: button\ntext: Submit\ntitle: New Requests\n</code></pre> <p>In the button widget, add an inout widget:</p> <pre><code>widget: inout\nname: name\n</code></pre> <p>Change the input to a textarea. If you'd like the tetarea to be wider, you can add width 400px in the CSS properties.</p> <p>Finally, let's edit the button widget again to define what happens when the button is pressed. Enter the following expression in the field \"run this when clicked and display the result\":</p> <pre><code>$create(\n  \"sqlite\", \n  \"REQUESTS\", \n  {\n    \"ID\": $ceil($random()*1000000), \n    \"user\": $.user, \n    \"name\": $.form.name, \n    \"submitted\": $now()\n  }\n)\n</code></pre> <p>Let's break down what is happening here. <code>$create</code> is a function which creates the record (3rd parameter) in the database (1st parameter) and the table (2nd parameter) specified. Database and table are static strings. The record consists of four dynamic fields:</p> <p>The ID is computed by taking a random number (between 0 and 1), multiplying it with 1 million and rounding it up. Thus the ID is a random number between 1 and 1 million, providing reasonable protection from duplicate IDs.</p> <p>The user is computed using the same construct (<code>$.user</code>) as for the table widget above.</p> <p>The name is specified as <code>$.form.name</code>. The rationale is the following: The user entries are stored in a JSON object form which hangs under the context $. In this object, we choose the name specified as the button argument.</p> <p>Finally, the submitted field is the current timestamp computed with <code>$now()</code>.</p> <p>After saving the layout, you can test the functionality. Note that you need to refresh the page after a value is submitted.</p>"},{"location":"getting-started/#admin-layout","title":"Admin Layout","text":"<p>The application administrator already has the ability to browse and search the data. However, it would be nice to add a chart to the system. To do this we first need to create another query.</p> <p>Follow the steps as before and project the columns user and name. Next, select the column user and group by this column. The resulting query should be:</p> <pre><code>SELECT\n  \"REQUESTS\".\"user\", COUNT(\"REQUESTS\".\"name\")\nFROM\n  \"REQUESTS\"\nGROUP BY\n   \"REQUESTS\".\"user\"\n</code></pre> <p>Save the query under the name \"requestsPerUser\". Next, navigate to the REQUESTS table and enter the layout editor. Add a widget to the page and choose these settings:</p> <pre><code>widget: chart\ntitle: Requests Per User\nquery: requestsPerUser\ndatabase: sqlite\nchart: doughnut\n</code></pre> <p>Finally, let's assume we'd like a notification when a new request is submitted. We can do this by creating a trigger on the request table. Open the table metadata section and enter the following expression for the field \"Trigger to call before a new record is created\":</p> <pre><code>$echo($)\n</code></pre> <p>This trigger is a simple expression that calls the echo function. Echo takes an object which is written to the system console. In this case the entire context is written. Once you save and submit another request, you should see a line like this in the console:</p> <pre><code>{database=sqlite, search=null, command=create, table=REQUESTS, object={ID=762613, user=user, name=My test entry, submitted=2020-12-31T15:50:35.755459500Z}}\n</code></pre> <p>Instead of calling the echo function, we can of course send an email or perform any other kind of action. A common use case is to automatically set the createdBy and createdOn fields. This can be achieved by setting the after create trigger to:</p> <pre><code>$update(database, table, object.ID, {\"createdBy\": $djUser(), \"createdOn\": $now()})\n</code></pre> <p>Note that triggers can invoke each other recursively. If this expression would be the update trigger,  we might end up with an endless recursion resulting in a stack overflow. This can be avoided by performing the  update only if <code>$isRecursiveTrigger()</code> is false.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#platform-as-a-service","title":"Platform as a Service","text":"<p>Dashjoin offers a fully managed Platform as a Service available at https://my.dashjoin.com/.</p>"},{"location":"installation/#download-and-local-setup","title":"Download and local setup","text":"<p>Installers and binaries for Windows, MacOS, and Linux are available at https://download.dashjoin.com/</p> <p>Important: These binaries run Dashjoin as a developer application, not as a service.</p> <ul> <li>windows/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Java Runtime. Unzip and start dashjoin.exe in a command prompt.</p> <ul> <li>windows/dashjoin-version.msi</li> </ul> <p>Dashjoin Windows Installer.</p> <p>Same contents as windows/dashjoin-exe.zip plus start menu icon.</p> <ul> <li>macos/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Runtime.</p> <p>Unzip and start <code>MacOS/Dashjoin</code> in a command prompt </p> <p>Note: if you get an error saying \"This Application is broken\", Apple Quarantine needs to be cleared with this command: <pre><code>xattr -cr Contents\n</code></pre></p> <ul> <li>macos/Dashjoin-version.dmg</li> </ul> <p>Dashjoin MacOS Installer</p> <p>Note: if you get an error saying \"This Application is broken\", Apple Quarantine needs to be cleared with this command: <pre><code>xattr -cr Dashjoin-*.dmg\n</code></pre></p> <ul> <li>linux/dashjoin-exe.zip</li> </ul> <p>Portable Dashjoin Platform Executable including Java Runtime.</p> <p>Unzip and start <code>bin/Dashjoin</code> in a command prompt</p> <ul> <li>linux/dashjoin-version.deb</li> </ul> <p>Dashjoin Linux Installer. Same contents as linux/dashjoin-exe.zip</p> <ul> <li>dashjoin-jar.zip</li> </ul> <p>Generic Java Archive (JAR) for all platforms</p>"},{"location":"installation/#creating-a-local-admin-user","title":"Creating a local Admin User","text":"<p>After installing Dashjoin, no user is set up in the system (a user can be defined via the environment variables - see below for more information). To set up the local development admin user, navigate to http://localhost:8080/#/setup.</p> <p>Choose a name, a username, and the password.</p> <p>Example: Name <code>Local Admin</code>, username <code>admin</code>, password <code>My.secure.pass!</code></p> <p>Note:</p> <p>this only works the very first time! After a development admin is created, no more local users can be created from the UI.</p> <p>To change or disable the local user, please edit or delete the files <code>djroles.properties</code> and <code>djusers.properties</code> in the application root directory. Here are more details on local users</p> <p>The Dashjoin authentication is configured to allow log in using social Google or Github accounts, or to allow registration of users by e-mail and password (authentication via e-mail uses the Google Firebase authentication).</p> <p>Click here for a demo video.</p>"},{"location":"installation/#local-users","title":"Local users","text":"<p>Local users are maintained in the files <code>djusers.properties</code> and <code>djroles.properties</code>.</p> <p>As the purpose for local users is for setup + dev, there is no management UI. To create / update users, or change the pwd, the corresponding entries have to be changed there.</p> <p>Passwords need to be specified as hash of <code>username:Dashjoin:password</code></p> <p>Follow these steps to add/change a local user:</p>"},{"location":"installation/#1-add-the-users-password-to-djusersproperties","title":"1. Add the user's password to <code>djusers.properties</code>","text":"<p>Important - hash the password salted with username + realm \"Dashjoin\": For user \"myuser\" and password \"mypass\", need hash of <code>myuser:Dashjoin:mypass</code></p> <p>For this example the result is <code>a3f1c2e80af79503cef46f9e198919d3</code> (see how to calculate below)</p> <p>So we need to add this line to <code>djusers.properties</code>: <pre><code>myuser=a3f1c2e80af79503cef46f9e198919d3\n</code></pre></p>"},{"location":"installation/#2-add-the-users-roles-to-djrolesproperties","title":"2. Add the user's role(s) to <code>djroles.properties</code>","text":"<p>To give \"myuser\" the \"authenticated\" role, add this line to <code>djroles.properties</code>: <pre><code>myuser=authenticated\n</code></pre> Multiple roles can be added with comma separation</p>"},{"location":"installation/#how-to-calculate-the-password-hash","title":"How to calculate the password hash","text":"<ul> <li> <p>Linux/MacOS: <pre><code>echo -n \"myuser:Dashjoin:mypass\" | md5sum -\n</code></pre></p> </li> <li> <p>Windows: <pre><code>powershell Write-Host -NoNewline \"myuser:Dashjoin:mypass\" &gt;temp.txt\npowershell (Get-FileHash -algorithm md5 temp.txt).Hash.ToLower()\ndel temp.txt\n</code></pre> need to store the string in a file temp.txt first (please delete after). Make sure there are no additional spaces and newlines</p> </li> <li> <p>Online:</p> </li> </ul> <p>For test/dev purposes you can also use an online service like https://emn178.github.io/online-tools/md5.html</p> <p>Note this might be insecure if the online service stores or re-publishes the entered strings!</p>"},{"location":"installation/#opening-the-dashjoin-application","title":"Opening the Dashjoin application","text":"<p>To access the application, navigate to http://localhost:8080</p>"},{"location":"installation/#docker","title":"Docker","text":"<p>This is the easiest and recommended way to run Dashjoin as a production service. The official container image <code>dashjoin/platform</code> is hosted on dockerhub</p> <pre><code>docker pull dashjoin/platform\ndocker run -p 8080:8080 dashjoin/platform\n</code></pre> <p>Point your browser to http://localhost:8080.</p> <p>If you would like to make the registered databases and credentials persistent, you can mount the \"model\" folder:</p> <pre><code>docker run -p 8080:8080 -v PERSISTENT_FOLDER:/deployments/model dashjoin/platform\n</code></pre>"},{"location":"installation/#run-local-dashjoin-installation-as-service","title":"Run local Dashjoin installation as service","text":"<p>If you have installed Dashjoin locally and want to run the application as a service, here are links on how to set up the service (not supported for production):</p> <ul> <li>Windows</li> <li>Linux (link to external site)</li> </ul>"},{"location":"installation/#environment","title":"Environment","text":"<p>Dashjoin uses the Quarkus configuration framework. A Dashjoin instance can be configured using the following environment variables:</p> <ul> <li>DJ_ADMIN_USER: admin user name (defaults to \"admin\")</li> <li>DJ_ADMIN_PASS: admin password (default is blank)</li> <li>DJ_ADMIN_ROLES: initial admin roles (defaults to the \"admin\" role)</li> <li>DASHJOIN_HOME: defines the dashjoin working directory (defaults to /deployments/model when using docker or the directory where the platform was launched). If you are using a platfrom executable or installer version, the working directory is set to userhome/.dashjoin and cannot be modified</li> <li>DASHJOIN_APPURL: optional git url where an app is cloned / pulled from</li> </ul> <p>By default, the service will be bound to 0.0.0.0 (all IP addresses) and serve HTTP on port 8080.</p> <p>For configuring HTTP ports, keystores etc. please refer to the Quarkus HTTP reference. The following example shows how to change the HTTP port using the windows executable:</p> <pre><code>&gt; set QUARKUS_HTTP_PORT=3333\n&gt; Dashjoin.exe\n</code></pre>"},{"location":"installation/#how-to-enable-https","title":"How to enable HTTPS","text":"<p>Note: in a production environment, very often a global load balancer (or other edge device) that serves HTTPS to the outside and connects to the Dashjoin service using HTTP is used.</p> <p>To enable HTTPS for the platform, the certificate file and the key file are required (usually called <code>cert.pem</code> and <code>key.pem</code>).</p> <p>Alternatively you can use a Java keystore, and you can also disable HTTP completely. Please refer to the Quarkus HTTP reference for all configuration options.</p> <p>Configure the service with the following settings: <pre><code>QUARKUS_HTTP_SSL_CERTIFICATE_FILE=/path/to/cert.pem\nQUARKUS_HTTP_SSL_CERTIFICATE_KEY_FILE=/path/to/key.pem\n</code></pre></p> <p>By default, the HTTPS port is 8443. To change it use: <pre><code>QUARKUS_HTTP_SSL_PORT=58443\n</code></pre></p>"},{"location":"installation/#self-signed-certificate","title":"Self-signed certificate","text":"<p>For test + dev, you can create a self-signed certificate with the following command <pre><code>openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem\n</code></pre></p>"},{"location":"installation/#import-an-ssl-certificate-to-the-java-trust-store","title":"Import an SSL certificate to the Java trust store","text":"<p>When accessing a third party system via SSL or HTTPS, the SSL certificate of the destination system needs to be trusted.</p> <p>In most cases this works \"automatically\" when the certificate was created such that an already trusted root certificate is already part of the Java trustStore. The trust store contains all major root certificates and is maintained by the Java vendor.</p> <p>When you encounter an error similar to the following:</p> <pre><code>javax.net.ssl.SSLHandshakeException: PKIX path building failed: sun.security.provider.certpath.\nSunCertPathBuilderException: unable to find valid certification path to requested target\n</code></pre> <p>this means that the SSL certificate of the host being contacted is not trusted, and access was denied. This means that the certificate is either self-signed (dev or test), or by a root certificate not trusted (for example a corporate internal root certificate).</p> <p>There are 2 options to solve this situation:</p> <ul> <li>if the destination host is under your control, create and use a certificate that is trusted</li> </ul> <p>This is usually the preferred method, as it does not require to manually edit the trustStore.</p> <p>Remember that whenever the SSL certificate needs to be renewed (i.e. after expiry), the error will again show up, and another change to the trustStore is required, and the procedure needs to be repeated!</p> <ul> <li>import the SSL certificate to the Java trustStore</li> </ul> <p>The import procedure involves several steps. Please follow this detailed guide that shows how to import the certificate to the existing Java trust store called <code>cacerts</code></p> <p>Let's call the new trust store including the imported certificate(s) <code>my-cacerts</code>, now it needs to be made available to the running application in this location:</p> <p><code>&lt;java.home&gt;/lib/security/cacerts</code></p> <p>Note that the Java home is logged upon startup of the platform as <code>java.home</code>: <pre><code>Dashjoin Platform 3.1.38-e525ab3-6e8f7b6 (built 2022-12-20T17:31:57+0000)\nLinux 5.15.49-linuxkit aarch64 / OpenJDK 64-Bit Server VM 17.0.5+8-jvmci-22.3-b08 - GraalVM CE 22.3.0\navailableProcessors 4 / maxMemory (MB) 8192 / freeMemory (MB) 64 / totalMemory (MB) 80\n&gt; cwd       = /deployments\n&gt; java.home = /opt/graalvm-ce-java17-22.3.0\n\n _________         ______   ____    ____     \n  ___/ __ \\____ ______/ /_    (_)___  (_)___ \n   _/ / / / __ `/ ___/ __ \\  / / __ \\/ / __ \\\n   / /_/ / /_/ (__  ) / / / / / /_/ / / / / /\n  /_____/\\__,_/____/_/ /_/_/ /\\____/_/_/ /_/ \n                        /___/                \n\n              Powered by Quarkus 2.14.3.Final\n</code></pre></p> <p>If you have access to the file system of the installed Dashjoin platform, you can replace the file with the new version (copy my-cacerts over cacerts).</p> <p>In the containerized application, we can mount the file in the cacerts location. When using the docker CLI, use a mount option like</p> <p><code>-v /path/to/my-cacerts:/opt/&lt;java.home&gt;/lib/security/cacerts</code></p> <p>A complete Docker command using a customized <code>logincfg.json</code> and <code>my-cacerts</code> in the current directory:</p> <pre><code>docker run -p 8080:8080 \\\n  -v $(pwd)/logincfg.json:/deployments/assets/logincfg.json \\\n  -v $(pwd)/my-cacerts:/opt/graalvm-ce-java17-22.3.0/lib/security/cacerts \\\n  dashjoin/platform:latest\n</code></pre>"},{"location":"installation/#cross-origin-resource-sharing-cors","title":"Cross-origin resource sharing (CORS)","text":"<p>CORS is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from which the first resource was served. CORS is enabled by default, with standard settings.</p> <p>All configuration options are described in the CORS filter section.</p>"},{"location":"installation/#logging-levels-for-diagnostics","title":"Logging levels for diagnostics","text":"<p>Verbosity of the Dashjoin Platform is minimized for production workloads. The default level for logging is <code>INFO</code>.</p> <p>In order to increase verbosity for the whole platform, you can use <pre><code>QUARKUS_LOG_LEVEL=DEBUG\n</code></pre></p> <p>You can also change the log level of a certain category (module or file), for example to change <code>com.dashjoin.launch</code> logging to <code>DEBUG</code>: <pre><code>QUARKUS_LOG_CATEGORY__COM_DASHJOIN_LAUNCH__LEVEL=DEBUG\n</code></pre></p>"},{"location":"installation/#build-locally","title":"Build Locally","text":"<p>Prerequisites:</p> <ul> <li>Java (11 or later)</li> <li>Node (12 or later)</li> <li>Maven (3.6 or later)</li> <li>Angular CLI (11 or later)</li> <li>For Windows users: you need to create the symbolic link in \"platform\\dashjoin\\src\\main\\resources\\META-INF\": <code>mklink /D resources ..\\..\\..\\..\\..\\angular\\dist\\angular</code></li> </ul> <p>Dashjoin uses Quarkus as runtime framework (https://quarkus.io). You can run your application in dev mode using:</p> <pre><code>platform/angular$ npm install [--legacy-peer-deps # required if nvm -version &gt; 7.0!)\nplatform/angular$ ng build\nplatform$ mvn install\nplatform/dashjoin$ mvn compile quarkus:dev\n</code></pre> <p>Point your browser to http://localhost:8080.</p> <p>You can use the provided launch file to directly run from within Eclipse (right-click on the launch file, \"Run as\" or \"Debug as\" -&gt; \"Dashjoin\",  note that you need to adjust your jdk, mvn, and working directory location in the file \"Dashjoin.launch\"). This requires the Eclipse Quarkus plugin (https://quarkus.io/blog/eclipse-got-quarkused/) and the Lombok plugin (https://projectlombok.org/setup/eclipse) to be installed. Launching with \"Debug as\" will also enable live coding mode.</p> <p>The application can be packaged and installed locally using: <pre><code>platform/dashjoin$ mvn package install\n</code></pre></p> <p>It produces the <code>dashjoin-0.0.1-SNAPSHOT-runner.jar</code> file in the <code>/target</code> directory. Be aware that it\u2019s not an uber-jar as the dependencies are copied into the <code>target/lib</code> directory.</p> <p>If you want to build an uber-jar, execute the following command:</p> <pre><code>platform/dashjoin$ mvn package -Dquarkus.package.type=uber-jar\n</code></pre> <p>The application is now runnable using <code>java -jar target/dashjoin-0.0.1-SNAPSHOT-runner.jar</code>.</p>"},{"location":"installation/#eclipse","title":"Eclipse","text":"<p>The Eclipse IDE can be used to develop and debug locally. First install the Eclipse Quarkus tools.</p> <p>After cloning the Github repository, you need to import at least the following Maven projects into the Eclipse workspace:</p> <ul> <li>dashjoin</li> <li>dashjoin-core</li> </ul> <p>Optional additional modules: * dashjoin-demo * dashjoin-kafka * dashjoin-mongodb</p> <p>The Maven dependencies need to be initialized with (right click dashjoin project folder) -&gt; Maven -&gt; Update Project. The Angular UI must be built using the CLI, please refer to the previous section.</p> <p>When everything was build successfully, you can use the Dashjoin.launch configuration to run or debug the platform. The Quarkus launcher supports hot loading of resources, i.e. any changes made will be adjusted at runtime without having to restart the platform. (Note: you will have to adjust the absolute folder references in the launch file to you own workspace settings)</p>"},{"location":"installation/#version-history","title":"Version History","text":""},{"location":"installation/#10-may-2021","title":"1.0 (May 2021)","text":"<ul> <li>Launch of the platform</li> </ul>"},{"location":"installation/#20-jan-2022","title":"2.0 (Jan 2022)","text":"<ul> <li>Extended support for databases: MongoDB, ArangoDB, RDF</li> <li>Support for graph queries: database drivers can implement graph / path queries, widgets can display graph query results and the platform has basic support for OpenCypher</li> <li>Chart improvements: support for stacked bar charts, ability to configure charts with all ChartJS options</li> <li>New Function: the \"receive\" function supports streaming data / IoT use cases</li> <li>App development / lifecycle: apps can be written collaboratively on GitHub, auto-installed upon platform launch</li> <li>Functions and databases can be deployed as micro-services using the RemoteDatabase driver</li> </ul>"},{"location":"installation/#21-april-2022","title":"2.1 (April 2022)","text":"<ul> <li>UI: HTML component, icons editor and display icon specification, run write queries from catalog, JSONata editor, MAP widget, PDF export</li> <li>ETL: streaming XML, YAML, transparent HTTP caching</li> <li>JSONata: 100% compatibility to JSONataJS, functions with multiple parameters</li> <li>Graph Search: PathQL integration</li> <li>Data Model: JSONb arrays can be foreign keys, allow specifying external ontology</li> </ul>"},{"location":"installation/#25-july-2022","title":"2.5 (July 2022)","text":"<ul> <li>UI</li> <li>Components can be scheduled to redraw live data</li> <li>Chart, table and tree widget support JSONata in addition to DB queries</li> <li>Page variables can be set via the URL</li> <li>Charts are clickable and navigate to the respective instance page</li> <li>Forms support document upload</li> <li>Search: Results can be restricted per database and table</li> <li>Data Model</li> <li>Databases, tables and properties can be assigned a \"title\" that is used in forms and hyperlinks</li> <li>A description can be set for databases, tables and properties, enhancing the technical metadata with semantics</li> <li>Support for SQL views</li> <li>SDK</li> <li>Monaco editor integrated for editing SQL, HTML, and CSS</li> <li>Introduced CSV parsing options</li> <li>New openText function allows web scaping</li> </ul>"},{"location":"installation/#30-oct-2022","title":"3.0 (Oct 2022)","text":"<ul> <li>UI</li> <li>Query editor preview enhanced for complex queries</li> <li>Query catalog improvements for scripts and write queries</li> <li>Display and table widgets support showing images, hyperlinks and lists</li> <li>Query processing</li> <li>Support for multiple SQL result sets</li> <li>Streaming DB copy</li> <li>Better support for stored procedures</li> <li>Access control</li> <li>Row level security</li> <li>SDK</li> <li>Ability to provide alternative development DBs and REST services</li> <li>Platform helps in identifying missing / orphaned queries / functions</li> <li>Platform offers JSON:API and ODATA interfaces</li> </ul>"},{"location":"installation/#31-dec-2022","title":"3.1 (Dec 2022)","text":"<ul> <li>UI</li> <li>Create and edit queries directly from layout editor</li> <li>Ability to block entire pages for certain user roles</li> <li>Easy customization of the toolbar for different user roles</li> <li>Query processing</li> <li>Support union queries in query preview</li> <li>SDK</li> <li>Support downloading binary data</li> </ul>"},{"location":"installation/#32-jan-2023","title":"3.2 (Jan 2023)","text":"<ul> <li>OpenAPI</li> <li>Dashjoin Apps can expose OpenAPI interface</li> <li>Implement existing OpenAPI specification via functions</li> <li>SwaggerHub integration</li> <li>Platform</li> <li>ARM support</li> <li>CORS configuration</li> <li>UI</li> <li>Optional confirmation dialog for button widget</li> <li>SDK</li> <li>Ability to include static assets in apps</li> </ul>"},{"location":"installation/#40-may-2023","title":"4.0 (May 2023)","text":"<ul> <li>AI &amp; ML</li> <li>Docker container / REST API for deploying custom models</li> <li>Image, face, and optical character recognition container</li> <li>Large language model for translation services</li> <li>Large language model for chat and instructions</li> <li>JSONata bindings for OpenAPI and Dashjoin AI &amp; ML APIs</li> <li>Automatic entity reconciliation and classification</li> <li>JSONata notebooks</li> <li>Ad hoc queries supported via JSONata</li> <li>File upload to JSONata notebooks</li> <li>Ad hoc ETL via JSONata</li> <li>Data Model</li> <li>Entity relationship schema visualization</li> <li>Table statistics</li> <li>Platform</li> <li>System exec JSONata function</li> <li>Improved SQLite insert performance</li> <li>SDK</li> <li>GIT operations available via JSONata</li> </ul>"},{"location":"installation/#50-jan-2024","title":"5.0 (Jan 2024)","text":"<ul> <li>UI</li> <li>Revamped user interface with several theme customization options</li> <li>WYSIWYG drag and drop layout editor</li> <li>Form layout integrated into the layout editor</li> <li>Edit and arrange diagrams and flow charts using the diagram widget</li> <li>Notebooks support map, table, and chart visualizations</li> <li>Platform</li> <li>Improved JSONata performance</li> <li>SDK</li> <li>Write your own widgets using any 3rd party JavaScript library and integrate them into the layout editor</li> <li>Manage your app versions and unit testing via the new expert mode</li> <li>Development container bundles all required tools and makes them available right in your browser</li> </ul>"},{"location":"security/","title":"Security and Access Control","text":""},{"location":"security/#security","title":"Security","text":"<p>We strongly advise to:</p> <ul> <li>Consider using read-only database credentials when registering a database with data that is managed by another application</li> <li>When adding a new database, make sure the access control settings are setup correctly</li> <li>Restrict access to the system in case you store confidential data in any of the registered databases</li> <li>All credentials that are entered into the system are encrypted using strong SHA-256 encryption. The master key resides in the file model/.secrets.id on the web server. Keep this file secured</li> <li>Add a OpenID provider in order to authenticate organization users</li> </ul> <p>In order to register new databases, the user must be in the \"admin\" role.</p>"},{"location":"security/#access-control","title":"Access Control","text":"<p>Several other sections already touched on access control and how certain functionality is only allowed for certain roles. This section explains how roles are defined and how users are assigned to be in a role.</p>"},{"location":"security/#info-page","title":"Info Page","text":"<p>The info page shows various system data. At the top of the page you find the username of the current user as well as the roles he or she is in. From there you also find a link to the roles dashboard and, on the PaaS offering, a link to the tenant users.</p>"},{"location":"security/#roles-dashboard","title":"Roles Dashboard","text":"<p>The roles dashboard allows the administrator to define system roles. The role names should correspond on the roles defined in the identity management system (IDM) you are using. Let's assume that the IDM defines a user to be in the role \"consulting\". If this role \"consulting\" is defined in Dashjoin and the user logs in,  the user also has this role when using Dashjoin. If you are using the Dashjoin Cloud, you can choose arbitrary role names and assign users to these roles using the tenant user dashboard.</p>"},{"location":"security/#tenant-user-dashboard","title":"Tenant User Dashboard","text":"<p>The previous section explained how IDM roles are carried over to Dashjoin. However, there might be situations, where an application requires a role which is not yet defined in the IDM. For instance, only some of the consultants in the IDM group \"consultant\" should be granted access to the application. One way would be to create a new Dashjoin role and a new corresponding IDM role. In some organizations, this might not be feasible though, since the IDM is usually managed by a different entity within the organization.</p> <p>The tenant user dashboard can be used in these cases. It allows the administrator of the Dashjoin instance to explicitly assign roles to IDM users without having to explicitly create and assign the role in the IDM.</p> <p>This mechanism can also be used to request access to a Dashjoin application. Let's assume a user is registered in the IDM, but has no access to Dashjoin. If he logs in, he'll get a \"permission denied\" error, however, the user will show up on this dashboard, with the \"active\" flag set to false. The administrator can then activate the user and assign the proper roles.</p> <p>If all users of a domain are to be added, the tenant user id can be set to \"@domain.org\". In this case any user id ending with this domain suffix gets the roles defined in this record.</p> <p>Finally, you can use the tenant id \"@EVERYONE\" to define roles for all users that are defined in the IDM, regardless of the roles they are assigned in the IDM.</p>"},{"location":"security/#assigning-roles","title":"Assigning Roles","text":"<p>Roles can be assigned to the following elements:</p> <ul> <li>Container widgets and the top level page widget: In the layout editor, you can specify that a container or page is only shown if the user is in a given role. Note that this feature does not replace the backend checks listed below. Containers are simply hidden. The page shows an error message on the bottom.</li> <li>Toolbar elements: You can customize which elements are visible on the toolbar by editing the toolbar widget at /#/resource/config/widget/dj-toolbar. Roles can be assigned to icons, the sidenav toggle, the page edit button, and the search box</li> <li>Functions: Functions can be restricted to be executable only to users in certain roles</li> <li>Queries: Queries can be restricted to be runnable only to users in certain roles</li> <li>Tables</li> <li>readRoles: Users in one of these roles get to read rows of this table</li> <li>writeRoles: Users in one of these roles get to update, delete, and create rows of this table</li> <li>Databases: defines a database wide default for any table that does not define read or write roles</li> </ul>"},{"location":"security/#row-level-security","title":"Row-Level Security","text":"<p>Row-Level Security allows restricting access to certain table rows depending on the value of a column. A common use case are portals where different tenants should only see their data. Consider the following example where the owner column is the name of the user the item belongs to:</p> id name owner 1 item 1 joe 2 item 2 mike <p>Using the table metadata editor, we can define \"owner\" to be the \"tenantColumn\", i.e. the column that defines the row-level security. If user mike logs in, he will only see item 2 on the item table.</p> <p>Row-level security can also be defined users being in a certain role. Consider this customer table:</p> id name region 1 customer 1 south 2 customer 2 north <p>Now, let's assume role \"sales-south\" should get access to rows where region is \"south\". This can be accomplished by defining region to be the tenantColumn in addition to defining the following role mapping:</p> <ul> <li>sales-south: south</li> <li>sales-north: north</li> </ul> <p>Row-level security is applied to the entire dashjoin platform automatically, except for queries. If a query involves a table that has row-level security defined, the query must have a parameter that is set accordingly. We show two examples for the tables defined above. A query on the item table might look as follows:</p> <ul> <li>query: select * from item where owner = ${tenant}</li> <li>query parameter expression: { \"tenant\": user }</li> </ul> <p>The role mappings on the customer are translated to a JSONata expression:</p> <ul> <li>query: select * from customer where region = ${tenant}</li> <li>query parameter expression: { \"tenant\": \"sales-south\" in roles ? \"south\" : (\"sales-north\" in roles ? \"north\") }</li> </ul>"},{"location":"support-matrix/","title":"Supported Databases","text":""},{"location":"support-matrix/#relational-databases","title":"Relational Databases","text":"<p>We support all of the SQL databases out of the top 10 database engines:</p> Database Driver class Driver version Status Connection URL Notes Oracle oracle.jdbc.OracleDriver 19.6.0.0.0 beta jdbc:oracle:thin:@...:1521/ORCL MySQL org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default SQL Server com.microsoft.sqlserver.jdbc.SQLServerDriver 11.2.0 beta jdbc:sqlserver://...:1433;databaseName=db; PostgreSQL org.postgresql.Driver 42.5.0 jdbc:postgresql://...:5432/db SQLite org.sqlite.JDBC 3.31.1 jdbc:sqlite:my.db DB2 com.ibm.db2.jcc.DB2Driver 1.4.0 beta jdbc:db2://...:50000/db MS Access net.ucanaccess.jdbc.UcanaccessDriver 4.0.1 beta jdbc:ucanaccess://db.accdb MariaDB org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default H2 org.h2.Driver 2.1.214 jdbc:h2:tcp://.../db Amazon RDS Aurora PostgreSQL org.postgresql.Driver 42.5.0 beta jdbc:postgresql://...:5432/db Amazon RDS Aurora MySQL org.mariadb.jdbc.Driver 3.0.8 beta jdbc:mariadb://...:3306/db ANSI_QUOTES and allowPublicKeyRetrieval set by default"},{"location":"support-matrix/#document-databases","title":"Document Databases","text":"Database Driver class Driver version Status Firestore google-cloud-firestore 3.2.0 Available in Dashjoin PaaS MongoDB mongodb-driver-sync 4.7.2 beta"},{"location":"support-matrix/#graph-databases","title":"Graph Databases","text":"Database Driver class Driver version Status RDF4J rdf4j-runtime 3.7.4 beta / must be deployed as a remote database - see the module page for setup instructions ArangoDB arangodb-java-driver 6.14.0 beta <p>Click here for a demo video.</p>"},{"location":"user-interface/","title":"User Interface","text":"<p>This section explains all Dashjoin user interface pages in more detail.</p>"},{"location":"user-interface/#universal-database-frontend","title":"Universal Database Frontend","text":"<p>Dashjoin offers an intuitive default visualization for any kind of data.  Click here for a demo video. It features the following building blocks:</p>"},{"location":"user-interface/#default-visualization-of-tables","title":"Default Visualization of Tables","text":"<p>Unless specified otherwise using the layout editor, all table pages show two elements. First, we have a sortable and pageable table showing the database table contents. Any primary or foreign key displays a link to the corresponding record page. Secord, the page shows a form for creating a new table record. The form is configured using the table metadata the system collected from the database. In case you are a system administrator, you will see two more widgets which are explained in the section on data definition operations below.</p>"},{"location":"user-interface/#default-visualization-of-records","title":"Default Visualization of Records","text":"<p>The record page also has two elements. First, there is a form allowing to update and delete the record. The form is almost identical to the create form on the table page. The only exception is that it is not allowed to change primary key columns. If you would like to do this, you need to delete and re-create the record using the new key. Second, the page has a widget showing links to the table page and all related records. Note that records are related if a key in the record points to another record or vice versa.</p>"},{"location":"user-interface/#search-page","title":"Search Page","text":"<p>Dashjoin offers a powerful search capability of the underlying databases. When you enter a search term in the toolbar, the search is federated to all registered databases and the result page shows the combined result using the following columns:</p> <ul> <li>a link to the actual record matching the search</li> <li>the name of the table the record is located in</li> <li>the name of the column that matched the search</li> <li>the matching column value</li> </ul> <p>In order to boost performance, Dashjoin pushes down the search queries to the underlying databases if possible. Therefore, depending on the database, the search might match keywords slight differently:</p> <ul> <li>SQL databases perform a case insensitive contains operation (i.e. \"My Test String\" would match the search term \"test\")</li> <li>Firestore performs a case sensitive starts with operation (i.e. \"My Test String\" would match the search term \"My\" but not \"test\")</li> <li>The default implementation behaves like SQL</li> </ul>"},{"location":"user-interface/#data-and-database-management","title":"Data and Database Management","text":"<p>In Dashjoin, it is possible to register multiple databases. This section lists the supported management operations for these databases.</p>"},{"location":"user-interface/#database-dashboard","title":"Database Dashboard","text":"<p>The database dashboard shows the databases known to the system and allows registering new databases. The table displays some core information about each database, the connection status as well as the number of tables detected. To register a new database, first select the database type. Depending on your choice, the respective connection options appear. Once you connect, Dashjoin will collect the database metadata and immediately make the new database ready for searches, queries, and browsing. The table also provides a link to the individual database. Use this page to change connection parameters. You can also simply press update to recollect the metadata. This is useful if the underlying schema was changed by another application. Deleting the database disconnects from the database and deletes the connection information. No data is deleted in the database.</p> <p>On the page of a database instance, you can edit the connection parameters. Submitting the form will re-connect the database and pick up any schema changes that were performed by other applications.</p> <p>You can also specify the roles that are allowed to read and write to the database. Note that by default, the admin role has access to all tables.</p> <p>If you would like to exclude certain tables from being accessible via the platform, you can add their names in the excludeTables field in the database's JSON file in the model folder as follows:</p> <pre><code>  \"excludeTables\": [\"table1\", \"table2\"],\n</code></pre>"},{"location":"user-interface/#data-definition-operations","title":"Data Definition Operations","text":"<p>The database page offers a database management section. You can create a new table there. The new table will contain two columns:</p> <ul> <li>ID: a numeric primary key</li> <li>name: a generic string describing the record</li> </ul> <p>The display table shows all database tables. You can delete tables there. Attention: this is a permanent operation that you have to confirm by typing \"delete\" into the dialog. Editing a table offers several options which are explained in the following sections. You can change the table name. This change is performed on the underlying database (e.g. a rename table operation on an SQL database).</p> <p>Following the link to an individual table offers two sections in addition to the normal table display. The table metadata section simply makes the table operations (e.g. renaming a table) available from this page also. The column metadata allows creating, renaming, and deleting columns. Attention: deleting columns is a permanent operation and needs to be confirmed by typing \"delete\" in the dialog. Besides renaming columns, other options are available which are explained in the below.</p>"},{"location":"user-interface/#upload","title":"Upload","text":"<p>The database management section also allows to upload data from multiple files to the current database. The following file extensions are supported:</p> File Extension Table Name Column Name Suggested Data Type Suggested Primary Key Comma separated UFT-8 format as defined by RFC 4180 .csv File name before extension First row Guess by inspecting the data First unique column Microsoft Excel .xlsx Sheet name First row Guess by inspecting the data First unique column SQLite database .sqlite From database From database From database First unique column JSON table .json File name before extension First row Guess by inspecting the data First unique column Model folder upload to config DB - - - - - <p>The system allows you to choose multiple files and collects all tables and columns from them and displays a preview of all tables in tabs. The table above shows how the system determines table and column names as well as the primary key and column types. You cannot change the table and column names in this display. If you would like to change them, abort the process, change the source file, and repeat the upload process.</p> <p>Depending on the tables to be uploaded, there are two modes. If one of the tables exists already, we enter the append / replace mode. This mode requires the structure of all tables to match the existing tables. You cannot pick column types or primary keys in this mode. You can then decide to append the data to the existing data or to replace the existing data. Attention, replacing the data will delete the data currently stored in these tables permanently. You therefore have to confirm this operation by entering \"delete contents\".</p> <p>If none of the tables exist, we enter the create mode. The preview does allow changing the primary key and column types. The suggested values are guesses based on the data and must be double checked by the user.</p>"},{"location":"user-interface/#column-operations","title":"Column Operations","text":"<p>The operations on columns can be grouped into two categories. First, changing the name and / or datatype results in the underlying database to be changed (i.e. using an alter column command on SQL databases).</p> <p>Second, editing primary and foreign keys are changes on the metadata level only, since not all databases support these concepts. You can specify a column to be the primary key of the table. Note that the user interface does not support composite primary keys. A column can also be defined to be a foreign key by entering the corresponding linked primary key. Note that it is possible to define references not only within the same database but also to other databases. Setting foreign key references causes the foreign key column to display links to the related record and vice versa.</p>"},{"location":"user-interface/#table-label","title":"Table Label","text":"<p>Besides changing the table name, you can enter a label and triggers. The label defines how the system should display a record in the following scenarios:</p> <ul> <li>the browser page title when we are on a record of that table</li> <li>in the autocomplete dropdown when editing a foreign key field</li> <li>when displaying the label of a hyperlink pointing to the record</li> </ul> <p>This feature is important when a table uses an artificial or non-descriptive primary key like a number or a UUID. By default, the system uses the key in the scenarios above, leading to unreadable and unintuitive displays. In this situation, the label can be changed to a template string with the template variable referencing other more descriptive record columns. For instance the table PERSON could define a label <code>${LAST_NAME}</code> or even <code>${LAST_NAME}, ${FIRST_NAME}</code> in order to display meaningful and user readable information rather than numbers or UUIDs.</p> <p>In case of an M:N relationship, the label can be shown depending on where the link is being displayed. I.e. the page for M looks at the M:N and will only display N, and N looking at M:N will see M (this works as intuitively expected). The syntax for labels that need dereferencing is to prepend ''. To render a M:N you could use: {M} {*N} where M and N are attributes (columns) in the relationship (table).</p> <p>Note that the user interface loads these template values in a lazy fashion whenever you visit a record page.</p>"},{"location":"user-interface/#table-triggers","title":"Table Triggers","text":"<p>Dashjoin offers create, update, and delete operations for each table. A trigger can be installed on each table that reacts before or after these operations, resulting is six trigger configurations. A trigger is an expression that is evaluated in the respective case. This following context is passed to the expression:</p> <ul> <li>command: one of create, update, or delete</li> <li>database: the database being modified</li> <li>table: the table being modified</li> <li>search: a map with the record's primary keys</li> <li>object: the record to the created or the fields to be updated</li> </ul> <p>Please see the section on expressions for more details.</p>"},{"location":"user-interface/#table-and-column-comment-and-title","title":"Table and Column Comment and Title","text":"<p>Dashjoin extracts the technical metadata from the databases. The editor allows you to add a comment for tables and columns in order to document the data model. The table title is used when displaying a link to the table. Likewise, column titles are used in CRUD forms and the show all records table columns.</p>"},{"location":"user-interface/#query-catalog-and-editor","title":"Query Catalog and Editor","text":"<p>The query catalog allows you to save queries that are used by other parts of the application. Usually, these are chart and table widgets that display query results. The catalog allows you to manage queries in a central place, reuse them across the application and define important metadata about parameters and access control. Click here for a demo video.</p>"},{"location":"user-interface/#query-catalog-page","title":"Query Catalog Page","text":"<p>The query catalog page show a list of all defined queries as well as a form for entering a new query. The form has the following fields:</p> <ul> <li>ID: this is a unique identifier to reference the query (e.g. from a chart widget)</li> <li>type: queries can have type read and write indicating whether the running the query will make changes to the underlying database</li> <li>roles: defines which roles are allowed to run the query</li> <li>database: this field can only be written from the editor as shown below and defines which database is used in the query editor (note that the application can later run a query on other database with the same schema)</li> <li>arguments: queries can be parameterized using arguments (see the section below for more details)</li> <li>query: allows making manual edits to the query and offers to open the query editor dialog</li> </ul> <p></p>"},{"location":"user-interface/#features","title":"Features","text":"<ul> <li>Graphically build queries in an Excel-like fashion</li> <li>Add columns and join tables via point and click</li> <li>Reorder columns using drag &amp; drop</li> <li>Apply where filters by simply adding them to the query result table</li> <li>Aggregate / group results right in the data table</li> <li>Rename columns</li> <li>Manual query edits are possible as well</li> <li>Download results as CSV</li> </ul>"},{"location":"user-interface/#supported-query-constructs","title":"Supported Query Constructs","text":"<p>The editor supports a wide range of features of the query language, namely any kind of table join, aggregation and filter. It is possible to add advanced constructs such as a subquery or a call to a user defined function or stored procedure to the query by making changes in the lower text field. In this case, the query editor displays the query result but no longer allows making changes to the query via the UI controls. The reason for the controls being disabled is shown in a tool tip. You can return to the last supported query via the undo button.</p>"},{"location":"user-interface/#result-size","title":"Result Size","text":"<p>During the process of writing the query, we limit the results to 1000 rows. Use the limit text field to set an explicit query limit. Once, the limit is set, it overrides the default of 1000 result rows.</p>"},{"location":"user-interface/#query-parameters","title":"Query Parameters","text":"<p>The query catalog page allows defining query parameters. Each parameter consists of the following information:</p> <ul> <li>key: this is the parameter name that allows the query to reference the parameter using <code>${key}</code></li> <li>type: defines the datatype of the parameter</li> <li>sample: this is the value that will be used in the query editor</li> </ul> <p>Consider the following example that searches for persons with a certain name older than a given age:</p> <pre><code>select * from PERSON where NAME=${p_name} and AGE&gt;${p_age}\n</code></pre> <p>This query has the string parameter p_name and the integer parameter p_age. In order to edit the query and display a result preview, we need to pluck in sample data. So we can define the samples:</p> <pre><code>p_name: Mike\np_age: 20\n</code></pre> <p>This results in the following query that is used when editing the query. So in the edit dialog, the following query is used (note that the system automatically handles quotation of strings and dates):</p> <pre><code>select * from PERSON where NAME='Mike' and AGE&gt;20\n</code></pre> <p>Once the editor is closed, the samples are replaced with the template variables again. Note that this replacement is string based, so you should choose parameter names that do not \"collide\" with other parts of the query. Hence, we choose the prefix p_.</p>"},{"location":"user-interface/#graph-queries","title":"Graph Queries","text":"<p>Apart from managing traditional queries, the Dashjoin query catalog can also be used to store graph queries. There are different flavors of graph query languages. We orient ourselves at the OpenCypher language and the upcoming GQL Standard. Like queries on document and relational database, graph queries return a table where the columns represent the projection variables and each row contains variable values that match the query pattern / path.</p> <p>The difference between the query types is that a graph query may return very different record types for a column / variable. Consider a graph query that returns all related records that are reachable with two hops from the starting record. Obviously, you will end up on very different records. In the northwind case, starting from an employee, these might be orders processed by the employee, the employee's boss's boss, and so on. Therefore, Dashjoin graph queries will make sure that apart from the raw data, the result also contains type information that can be used by the UI in order to interpret the values.</p> <p>Graph queries can be run on a specific or on all databases. Dashjoin contains a partial OpenCypher implementation. Consider the following OpenCypher  example (to learn OpenCypher, please refer to this interactive guide):</p> <pre><code>MATCH \n  path=(start:`dj/northwind/EMPLOYEES`)-[r1:REPORTS_TO]-&gt;(boss)-[r2:REPORTS_TO]-&gt;(finish) \nRETURN \n  start._dj_resource, boss.LAST_NAME, finish._dj_resource, path\"\n</code></pre> <p>This query traverses the recursive \"reports to\" relationship. The variables start, boss, and finish represent the graph nodes. As mentioned before, the engine adds the record metadata. i.e. which database and table / collection the record comes from. The path variable matches the entire traversal and contains all nodes and edges (relationships) that were traversed.</p> <p>AQL and SPARQL Property Paths are alternative graph query languages that can be pushed down to the native database query engine if the query is run on the respective ArangoDB / RDF4J database. The Dashjoin drivers make sure that the query result has the same structure as a corresponding OpenCypher query.</p> <p>Note that the graphical query editor does not yet support composing graph queries.</p>"},{"location":"user-interface/#pages-dashboard","title":"Pages Dashboard","text":"<p>While Dashjoin has a rich default page layout that is suitable for many use cases, every aspects of the display can be configured using the functionality described in this section.</p> <p>The pages dashboard provides you with an overview of the available pages in the system. The first table shows the dashboards available in the system. This is a mix of system pages, which are explained in more detail in the next section, and pages created by the user via the \"create a new page\" form.</p> <p>The page contains a link to widgets. This allows you to customize the sidebar and the toolbar.  You can edit the those by visiting the page /config/widget/dj-toolbar or /config/widget/dj-sidenav. A typical use case would be to edit the roles that are required for an icon to appear. You can also add an icon pointing to your custom dashboard page. Since the dj-toolbar is shipped with the system, you can revert back to the original version by clicking delete on this page.</p> <p>Finally, the layouts table provides an overview of all tables and whether the default layout is used or whether the user has customized the layout using the layout editor.</p>"},{"location":"user-interface/#system-pages-and-layouts","title":"System Pages and Layouts","text":"<p>The system comes with a set of system pages (e.g. Home and Info) and some layouts for databases, tables, queries, etc. These layouts contain much of the functionality described in this reference guide.</p> <p>System pages can be changed using the editor introduced below, however, a delete operation does not delete them altogether, but rather resets them to the \"factory\" state. This ensures that you cannot accidentally damage a system permanently using the editor.</p>"},{"location":"user-interface/#layout-editor","title":"Layout Editor","text":"<p>To activate the layout and form editor, press the pen symbol in the toolbar. You will remain on the page, but several controls will pop up on the screen. The pen symbol is replaced with three icons:</p> <ul> <li>Delete: deletes the page or resets the default table or record layout</li> <li>Save: saves the changes</li> <li>Abort: leaves the editor without saving</li> </ul> <p>In the lower right screen corner you have the following controls:</p> <ul> <li>Undo / redo: undo an unwanted change</li> <li>Zoom: if you are editing a large page, you can zoom out to get a better overview or to drag elements from one end to the other</li> <li>Edit: when clicking on a widget, opens the widget editor on the bottom</li> <li>Move: displays arrows in each widget that move the mights in that direction. Alternatively, you can drag and frop widgets using the drag handle in the widget's upper right corner</li> <li>Resize: allows resizing widgets on a 12 column grid</li> </ul> <p>The plus icon is shown at the bottom of the page as well as for each container that was added to the page. This allows you to create nested layouts. Pressing the plus icon opens a drawer on the left where you can select the widget to add.</p> <p>Once you add a widget or select it for editing, the widget editor opens at the bottom of the page. You can enter texts, expressions, styles, icons etc.</p> <p>For more information on the layout editor, you can refer to the React Page documentation.</p>"},{"location":"user-interface/#expression-editor","title":"Expression Editor","text":"<p>Expressions are used in various places throughout the platform. The next sections describe the different usage scenarios in more detail. Whenever an expression is to be edited on a form, Dashjoin allows you to do this via the expression editor component which is explained in this section.</p> <p>The expression editor is a simple text field that shows context sensitive help and a result preview once you start typing.</p> <p>As an example, you can navigate to the info page, enter the page edit mode and edit the user display widget. The widget displays the result of the following expression which projects the user field from the page context (the composition of the context is explained in the next section):</p> <pre><code>{\"user\": user}\n</code></pre> <p>If you delete the closing curly bracket, the system will tell you that the expression is invalid: line 1:13: missing '}'. Now enter the following expression that calls the built-in read:</p> <pre><code>$read()\n</code></pre> <p>The system will tell you about missing parameters: Arguments required: <code>$read(database, table, pk1)</code>. Now change the expression to:</p> <pre><code>$read(\"northwind\", \"EMPLOYEES\", 2)\n</code></pre> <p>Assuming you have the demo application installed, this will show the first 10 lines of JSON that contain the respective record in the employees table of the northwind database. Finally, setting the expression to</p> <pre><code>$\n</code></pre> <p>displays the entire page context.</p>"},{"location":"user-interface/#function-page","title":"Function Page","text":"<p>The function page works a lot like the database page. It shows a table of the functions that have been created on the system. To create a new function, you first need to select the function type. Depending on your choice, you can enter the respective configuration parameters. The function type specifies whether the function is read only or whether it has side effects like sending email or writing data. Finally, the roles specify which user role is allowed to run the function. Functions define extract load transform operations that load data into one of the databases, email endpoints, or access the RESTful web services.</p> <p>Apart from creating and editing functions, you can also run the functions from the function page. Note that functions will be called without any parameters. If you would like to run functions with parameters, use the JSONata Notebook. Please refer to the developer reference chapter for a detailed listing of all supported functions.</p>"},{"location":"user-interface/#general-information-page","title":"General Information Page","text":"<p>This page contains some basic information about the platform version and installation parameters. At the top of the page, you find some important links that are grouped into the following four categories:</p>"},{"location":"user-interface/#user-information","title":"User Information","text":"<p>This section shows the user name, email, and roles. In addition, you can find links to the roles and tenant users tables. These are used for configuring roles and access control. For details, please consult the section security and access control.</p>"},{"location":"user-interface/#app","title":"App","text":"<p>The app section contains links to the following pages:</p> <ul> <li>Expert mode: this link opens the expert mode in a new window. This mode allows writing your own widgets using third party JavaScript libraries</li> <li>App API: This page allows you to use Dashjoin to implement an existing OpenAPI spec, publish schemas and paths to your OpenAPI spec, and generate an OpenAPI spec for your Dashjoin app</li> <li>Notebook: this is an area that works much like a jupyter notebook. You can conveniently experiment with JSONata there</li> <li>Git: this page provides a lightweight way to manage version control of your app. For more information please refer to the section development / production</li> </ul>"},{"location":"user-interface/#configuration","title":"Configuration","text":"<p>This section provides links to the system configuration. You can define certain user interface customizations there, configure database search parameters, and define some other system settings.</p> <p>The configuration database is a built-in database that defines queries, function, registered databases, etc.  Every role defined in the system must have read-only access to the configuration database. On this page, you can define which roles have access to which system tables and you can upload system tables (e.g. for importing users).</p>"},{"location":"user-interface/#databases","title":"Databases","text":"<p>The databases section shows a link to the query performance table. This table helps you to identify performance problems in your app. The ER diagram is a convenient way of visualizing your database schemata.</p>"}]}